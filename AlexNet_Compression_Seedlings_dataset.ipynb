{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_Compression_Seedlings_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnauldnzegha/Deep-Learning-Models-Compression-for-Agri-Plants./blob/main/AlexNet_Compression_Seedlings_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUzakkgkZCDO"
      },
      "source": [
        "# Deep learning model compression for agricultural devices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNu1tg3ZRHlx"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tempfile\n",
        "import zipfile\n",
        "from __future__ import division, print_function, absolute_import\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import SGD\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-OWt9Qde6xm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "6b3f0c0e-a855-4581-ad3d-b890ca08cd68"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yQuhZH_jpJM"
      },
      "source": [
        "#DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Quyan36mwizz"
      },
      "source": [
        "## This code load v2-plant-seedlings-dataset from googleDrinve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBeKsd-UhuO0"
      },
      "source": [
        "import zipfile, os\n",
        "zip_ref = zipfile.ZipFile('/content/drive/My Drive/DEEP IN AGRI/v2-plant-seedlings-dataset.zip', 'r')\n",
        "zip_ref.extractall('Data')\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CS8oKhyPBKr"
      },
      "source": [
        "return the content of the dataset\n",
        "\n",
        "Traning images and labels, test images and labes, and and the number of class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXBGV7haeqT1"
      },
      "source": [
        "def load_dataset(rootDir):\n",
        "    root=rootDir\n",
        "    folders = os.listdir(root)\n",
        "    nb = len(folders)\n",
        "    x_data=[]\n",
        "    y_label=[]\n",
        "    xt_data=[]\n",
        "    yt_label=[]\n",
        "    for x in range(nb):\n",
        "        label=np.zeros(nb)\n",
        "        label[x]=1\n",
        "        PlantPath=os.listdir(root+\"/\"+folders[x])\n",
        "        plants=[root+\"/\"+folders[x]+\"/\"+f for f in PlantPath if (f.endswith(\".png\") or f.endswith(\".jpg\") or f.endswith(\".JPG\"))]\n",
        "        i=0\n",
        "        for plant in plants:\n",
        "            imgs=cv2.imread(plant)\n",
        "            imgs= cv2.resize(imgs,(50,50))\n",
        "            if(i%5==0):\n",
        "                xt_data.extend([imgs])\n",
        "                yt_label.extend([label])\n",
        "            else:\n",
        "                x_data.extend([imgs])\n",
        "                y_label.extend([label])\n",
        "            i=i+1\n",
        "    return (np.asarray(x_data), np.asarray(y_label), np.asarray(xt_data), np.asarray(yt_label), nb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gi_xqKOhiqnr"
      },
      "source": [
        "#Pruning CallBack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqryqcNoiqOv"
      },
      "source": [
        "class PruningCallback(tf.keras.callbacks.Callback):\n",
        "\tdef __init__(self, init_step, end_step, init_sparsity, end_sparsity, pruning_step):\n",
        "\t\tself.init_step=init_step; self.end_step=end_step\n",
        "\t\tself.init_sparsity=init_sparsity; self.end_sparsity=end_sparsity\n",
        "\t\tself.pruning_step=pruning_step\n",
        "\t\tself.W_mask=[]\n",
        "\t\tsuper().__init__()\n",
        "\tdef on_train_begin(self, logs=None):\n",
        "\t\tfor layer in self.model.layers:\n",
        "\t\t\tif(\"filters\" in layer.get_config()):\n",
        "\t\t\t\tself.W_mask.append(np.ones(layer.get_weights()[0].shape))\n",
        "\t\t\n",
        "\tdef decayed_sparsity_level(self,step):\n",
        "\t\tstep = min(step-self.init_step, self.end_step)\n",
        "\t\treturn ((self.init_sparsity-self.end_sparsity) *\n",
        "          (1 - step / (self.end_step-self.init_step)) ** (1)\n",
        "          ) + self.end_sparsity\n",
        "\n",
        "\tdef on_epoch_end(self, epoch, logs={}):\n",
        "\t\tif((epoch)%self.pruning_step==0 and (epoch)>=self.init_step and (epoch)<=self.end_step):\n",
        "\t\t\tprint('\\n pruning [', end=' ')\n",
        "\t\ti=0\n",
        "\t\tlayers=self.model.layers\n",
        "\t\tfor l in range(len(layers)):\n",
        "\t\t\tif(\"filters\" in layers[l].get_config()):\n",
        "\t\t\t\tw_m=tf.convert_to_tensor(self.W_mask[i], dtype=tf.float32)\n",
        "\t\t\t\tw_l=tf.convert_to_tensor(self.model.layers[l].get_weights()[0], dtype=tf.float32)\n",
        "\t\t\t\tw_l2=tf.multiply(w_m,w_l).numpy()\n",
        "\t\t\t\tb=self.model.layers[l].get_weights()[1]\n",
        "\t\t\t\tself.model.layers[l].set_weights([w_l2,b])\n",
        "\t\t\t\t#Pruninf\n",
        "\t\t\t\tprint('=', end=' ')\n",
        "\t\t\t\tif((epoch)%self.pruning_step==0  and (epoch)>=self.init_step and (epoch)<=self.end_step):\n",
        "\t\t\t\t\tfilters_sum=np.abs(tf.reduce_sum(w_l2, [0, 1, 2]).numpy())\n",
        "\t\t\t\t\tWs=tf.sort(filters_sum,  axis=-1, direction='ASCENDING', name=None).numpy()\n",
        "\t\t\t\t\tstep_sparsty=self.decayed_sparsity_level(epoch)\n",
        "\t\t\t\t\tthreshold=Ws[int(len(Ws)*step_sparsty)]\n",
        "\t\t\t\t\te=np.where(filters_sum <= threshold)\n",
        "\t\t\t\t\te=np.array(e).reshape(-1)\n",
        "\t\t\t\t\tfor ex in e:\n",
        "\t\t\t\t\t\tif(len(self.W_mask[i].shape)==4):\n",
        "\t\t\t\t\t\t\tself.W_mask[i][:,:,:,ex]=0\n",
        "\t\t\t\t\t\t\tb[ex]=0\n",
        "\t\t\t\t#setting weights\n",
        "\t\t\t\tw_m=tf.convert_to_tensor(self.W_mask[i], dtype=tf.float32)\n",
        "\t\t\t\tw_l2=tf.multiply(w_m,w_l).numpy()\n",
        "\t\t\t\ti=i+1\n",
        "\t\t\t\tself.model.layers[l].set_weights([w_l2,b])\n",
        "\t\t\t\t\n",
        "\t\t\tif  isinstance(layers[l], tf.keras.layers.Dense):\n",
        "\t\t\t\tw_l=layers[l].get_weights()[0]\n",
        "\t\t\t\tbias=layers[l].get_weights()[1]\n",
        "\t\t\t\ts_mask=tf.reduce_sum(self.W_mask[-1], [0, 1, 2]).numpy()\n",
        "\t\t\t\tindx=np.where(s_mask ==0.)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tli=int(w_l.shape[0]/len(s_mask))\n",
        "\t\t\t\tind_fc=[]\n",
        "\t\t\t\tfor ind in indx:\n",
        "\t\t\t\t\tx=np.arange(li*ind, li*(ind+1))\n",
        "\t\t\t\t\tind_fc.append(x)\n",
        "\t\t\t\tind_fc=np.array(ind_fc).reshape(-1)\n",
        "\t\t\t\tfor ind_fc_ in ind_fc:\n",
        "\t\t\t\t\tw_l[ind_fc_,:]=0\n",
        "\t\t\t\tself.model.layers[l].set_weights([w_l,bias])\n",
        "\t\t\n",
        "\t\t\tif isinstance(layers[l], tf.keras.layers.BatchNormalization):\n",
        "\t\t\t\tw_l=layers[l].get_weights()\n",
        "\t\t\t\ts_mask=tf.reduce_sum(self.W_mask[i-1], [0, 1, 2]).numpy()\n",
        "\t\t\t\tindx=np.where(s_mask ==0.)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tfor ind in indx:\n",
        "\t\t\t\t\tw_l[0][ind]=0\n",
        "\t\t\t\t\tw_l[1][ind]=0\n",
        "\t\t\t\t\tw_l[2][ind]=0\n",
        "\t\t\t\t\tw_l[3][ind]=0\n",
        "\t\t\t\tself.model.layers[l].set_weights(w_l)\n",
        "\t\t\n",
        "\t\tif((epoch)%self.pruning_step==0 and (epoch)>=self.init_step and (epoch)<=self.end_step):\n",
        "\t\t\tprint(']')\n",
        "\t\n",
        "\t#Transfert create a new model without pruned filters \n",
        "\tdef get_thinner_model(self):\n",
        "\t\toriginal_model=self.model\n",
        "\t\tW_mask=self.W_mask\n",
        "\t\tself.preview=[3]\n",
        "\t\tself.mask_ind=[0]\n",
        "\t\tcompressed_model = tf.keras.models.clone_model(original_model,\tclone_function=self.build_compressed_CNN,)\n",
        "\t\tself.preview_w=[[0,1,2]]\n",
        "\t\tcompressed_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=\"sgd\", metrics=['accuracy'])\n",
        "\t\tmask_i=0\n",
        "\t\tfor l_index in range( len(original_model.layers)):\n",
        "\t\t\tlayer=original_model.layers[l_index]\n",
        "\t\t\tif isinstance(layer, tf.keras.layers.Conv2D):\n",
        "\t\t\t\tw_l=layer.get_weights()[0]\n",
        "\t\t\t\tbias=layer.get_weights()[1]\n",
        "\t\t\t\tfilters_sum=np.abs(tf.reduce_sum(w_l, [0, 1, 2]).numpy())\n",
        "\t\t\t\tindx=np.where(filters_sum !=0.)\n",
        "\t\t\t\tindxz=np.array(np.where(filters_sum ==0.)).reshape(-1)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tif (l_index!=0):\n",
        "\t\t\t\t\tw_l=w_l[:,:,self.preview_w[-1],:]\n",
        "\t\t\t\tw_l_r=w_l[:,:,:,indxz]\n",
        "\t\t\t\tw_l=w_l[:,:,:,indx]\n",
        "\t\t\t\tprint(w_l.shape)\n",
        "\t\t\t\tprint(np.sum(w_l), np.sum(w_l_r))\n",
        "\t\t\t\tself.preview_w.append(indx)\n",
        "\t\t\t\tbias=np.array([bias[i] for i in indx])\n",
        "\t\t\t\tcompressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "\t\t\t\tmask_i=mask_i+1\n",
        "\t\t\tif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "\t\t\t\tw_l=layer.get_weights()\n",
        "\t\t\t\t#print(w_l)\n",
        "\t\t\t\tw_l[0]=np.array([w_l[0][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tw_l[1]=np.array([w_l[1][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tw_l[2]=np.array([w_l[2][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tw_l[3]=np.array([w_l[3][i] for i in self.preview_w[-1]])\n",
        "\t\t\t\tcompressed_model.layers[l_index].set_weights(w_l)\n",
        "\t\t\tif isinstance(layer, tf.keras.layers.Dense):\n",
        "\t\t\t\tw_l=layer.get_weights()[0]\n",
        "\t\t\t\tbias=layer.get_weights()[1]\n",
        "\t\t\t\ts_mask=tf.reduce_sum(self.W_mask[-1], [0, 1, 2]).numpy()\n",
        "\t\t\t\tindx=np.where(s_mask !=0.)\n",
        "\t\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\t\tw_l=w_l.reshape(-1,len(s_mask),len(bias))\n",
        "\t\t\t\tw_l=w_l[:,indx,:]\n",
        "\t\t\t\tw_l=w_l.reshape(-1,len(bias))\n",
        "\t\t\t\tcompressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "\t\treturn compressed_model\n",
        "\n",
        "\t#Bluid\n",
        "\tdef build_compressed_CNN(self,layer):\n",
        "\t\tif isinstance(layer, tf.keras.layers.Conv2D):\n",
        "\t\t\tw_l=layer.get_weights()[0]\n",
        "\t\t\tfilters_sum=np.abs(tf.reduce_sum(self.W_mask[self.mask_ind[-1]], [0, 1, 2]).numpy())\n",
        "\t\t\tindx=np.where(filters_sum !=0.)\n",
        "\t\t\tindx=np.array(indx).reshape(-1)\n",
        "\t\t\tself.mask_ind.append(self.mask_ind[-1]+1)\n",
        "\t\t\tinput_shape=layer.input_shape\n",
        "\t\t\tinput_s=(input_shape[0],input_shape[1],input_shape[2], self.preview[-1])\n",
        "\t\t\tl=tf.keras.layers.Conv2D(len(indx), 3, padding='same', trainable=False, activation=layer.activation, input_shape=input_s, kernel_regularizer='l2')\n",
        "\t\t\tself.preview.append(len(indx))\n",
        "\t\t\treturn l\n",
        "\t\tif isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "\t\t\treturn tf.keras.layers.BatchNormalization()\n",
        "\t\tif isinstance(layer, tf.keras.layers.Dense):\n",
        "\t\t\treturn tf.keras.layers.Dense(nb_classes, activation='softmax', trainable=False)\n",
        "\t\tif isinstance(layer, tf.keras.layers.MaxPool2D):\n",
        "\t\t\treturn tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\t\tif isinstance(layer, tf.keras.layers.AveragePooling2D):\n",
        "\t\t\treturn tf.keras.layers.AveragePooling2D()\n",
        "\t\tif isinstance(layer, tf.keras.layers.Flatten):\n",
        "\t\t\treturn tf.keras.layers.Flatten()\n",
        "\t\treturn layer\n",
        "\t\t\t\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2m-vfLaxEHV"
      },
      "source": [
        "def build_compressed_CNN(layer):\n",
        "  if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "    w_l=layer.get_weights()[0]\n",
        "    #print(W_mask[mask_ind[-1]].shape)\n",
        "    filters_sum=np.abs(tf.reduce_sum(W_mask[mask_ind[-1]], [0, 1, 2]).numpy())\n",
        "    indx=np.where(filters_sum !=0.)\n",
        "    indx=np.array(indx).reshape(-1)\n",
        "    mask_ind.append(mask_ind[-1]+1)\n",
        "    input_shape=layer.input_shape\n",
        "    input_s=(input_shape[0],input_shape[1],input_shape[2], preview[-1])\n",
        "    l=tf.keras.layers.Conv2D(len(indx), 3, padding='same', trainable=False, activation=layer.activation, input_shape=input_s, kernel_regularizer='l2')\n",
        "    preview.append(len(indx))\n",
        "    return l\n",
        "  if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "    return tf.keras.layers.BatchNormalization()\n",
        "  if isinstance(layer, tf.keras.layers.Dense):\n",
        "    return tf.keras.layers.Dense(nb_classes, activation='softmax', trainable=False)\n",
        "  if isinstance(layer, tf.keras.layers.MaxPool2D):\n",
        "    return tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "  if isinstance(layer, tf.keras.layers.AveragePooling2D):\n",
        "    return tf.keras.layers.AveragePooling2D()\n",
        "  if isinstance(layer, tf.keras.layers.Flatten):\n",
        "    return tf.keras.layers.Flatten()\n",
        "  return layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIc4af6CqWKn"
      },
      "source": [
        "def transfert_weights(original_model, compressed_model):\n",
        "  preview_w=[[0,1,2]]\n",
        "  compressed_model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=\"sgd\", metrics=['accuracy'])\n",
        "  mask_i=0\n",
        "  for l_index in range( len(original_model.layers)):\n",
        "    layer=original_model.layers[l_index]\n",
        "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "      w_l=layer.get_weights()[0]\n",
        "      bias=layer.get_weights()[1]\n",
        "      filters_sum=np.abs(tf.reduce_sum(W_mask[mask_i], [0, 1, 2]).numpy())\n",
        "      indx=np.where(filters_sum !=0.)\n",
        "      indx=np.array(indx).reshape(-1)\n",
        "      if (l_index!=0):\n",
        "        w_l=np.array([w_l[:,:,i,:] for i in preview_w[-1]])\n",
        "      w_l=np.array([w_l[:,:,:,i] for i in indx]).T\n",
        "      preview_w.append(indx)\n",
        "      print(\"w \", w_l.shape)\n",
        "      bias=np.array([bias[i] for i in indx])\n",
        "      compressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "      mask_i=mask_i+1\n",
        "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "      w_l=layer.get_weights()\n",
        "      print(w_l)\n",
        "      w_l[0]=np.array([w_l[0][i] for i in preview_w[-1]])\n",
        "      w_l[1]=np.array([w_l[1][i] for i in preview_w[-1]])\n",
        "      w_l[2]=np.array([w_l[2][i] for i in preview_w[-1]])\n",
        "      w_l[3]=np.array([w_l[3][i] for i in preview_w[-1]])\n",
        "      compressed_model.layers[l_index].set_weights(w_l)\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "      w_l=layer.get_weights()[0]\n",
        "      bias=layer.get_weights()[1]\n",
        "      s_mask=tf.reduce_sum(W_mask[-1], [0, 1, 2]).numpy()\n",
        "      indx=np.where(s_mask !=0.)\n",
        "      indx=np.array(indx).reshape(-1)\n",
        "      li=int(w_l.shape[0]/len(s_mask))\n",
        "      ind_fc=[]\n",
        "      for ind in indx:\n",
        "        x=np.arange(li*ind, li*(ind+1))\n",
        "        ind_fc.append(x)\n",
        "      ind_fc=np.array(ind_fc).reshape(-1)\n",
        "      w_l=np.array([w_l[i] for i in ind_fc])\n",
        "      print(w_l)\n",
        "      compressed_model.layers[l_index].set_weights([w_l,bias])\n",
        "  return compressed_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2115jfi_r4O5"
      },
      "source": [
        "\n",
        "class ModelProfiler():\n",
        "  def cuntPrunedWith(self, model):\n",
        "    ind_x,ind_0=0,0\n",
        "    layers=model.layers\n",
        "    for layer in layers:\n",
        "      i1,i2=self.cuntLayerPrunedWith(layer)\n",
        "      ind_x,ind_0=ind_x+i1,ind_0+i2\n",
        "    return ind_x, ind_0\n",
        "\n",
        "  def cuntPrunedWithArry(self, model):\n",
        "    ind_x,ind_0,ind_t=[],[],[]\n",
        "    layers=model.layers\n",
        "    for layer in layers:\n",
        "      i1,i2=self.cuntLayerPrunedWith(layer)\n",
        "      ind_x.append(i1);ind_0.append(i2), ind_t.append(i1+i2)\n",
        "    return np.array(ind_t),np.array(ind_x), np.array(ind_0)\n",
        "\n",
        "  def cuntLayerPrunedWith(self, layer):\n",
        "    ind_x,ind_0=0,0\n",
        "    if(layer.get_weights()==[]):\n",
        "      return 0,0\n",
        "    w_l=layer.get_weights()\n",
        "    for w in w_l:\n",
        "      ind_x+=np.where(np.abs(w) > 0.)[0].shape[0]\n",
        "      ind_0+=np.where(w == 0.)[0].shape[0]\n",
        "    return ind_x, ind_0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tibaMVvkroPA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh-RA0Aqw6KY"
      },
      "source": [
        "##AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyMnhKIIratm"
      },
      "source": [
        "def alexnet(nb_classes=38, input_shape=[]):\n",
        "    l = tf.keras.layers\n",
        "    input_shape=(50,50,3)\n",
        "    model = tf.keras.Sequential([\n",
        "                                 l.Conv2D( 64, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "                                 \n",
        "                                 l.Conv2D( 128, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "\n",
        "                                 l.Conv2D( 192, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "\n",
        "                                 l.Conv2D( 256, 3, padding='same', activation='relu', input_shape=input_shape),\n",
        "                                 l.MaxPooling2D((2, 2), (2, 2), padding='same'),\n",
        "                                 l.BatchNormalization(),\n",
        "                                 l.AveragePooling2D(),\n",
        "                                 \n",
        "                                 l.Flatten(),\n",
        "                                 \n",
        "                                 l.Dense(nb_classes, activation='softmax')\n",
        "                                 ])\n",
        "    return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHI_dzJDZ5fX"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdrKYGQ-ixhs"
      },
      "source": [
        "#Init and train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zG86f0v4Vr5"
      },
      "source": [
        "simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev0RiuK6Oxro"
      },
      "source": [
        "img_dim=(50,50)\n",
        "(X_train_50, y_train, X_test_50, y_test, nb_classes ) =load_dataset(\"/content/Data\")\n",
        "X_train_50 = X_train_50.astype('float32')\n",
        "X_test_50 = X_test_50.astype('float32')\n",
        "X_train_50 /= 255\n",
        "X_test_50 /= 255\n",
        "epochs = 100\n",
        "batch_size=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YBLScgJO7it"
      },
      "source": [
        "dim_50=(50,50,3)\n",
        "sgd=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.001, nesterov=False, name='SGD')\n",
        "tf.random.set_seed(1234)\n",
        "model_simple = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_simple.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_0 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_0.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYP1A0aTEzfg"
      },
      "source": [
        "#sgd=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.001, nesterov=False, name='SGD')\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_1 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_1.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_2 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_2.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_3 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_3.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tf.random.set_seed(1234)\n",
        "model_to_prune_4 = alexnet(nb_classes=nb_classes,input_shape=dim_50)\n",
        "model_to_prune_4.compile(\n",
        "    loss=tf.keras.losses.categorical_crossentropy,\n",
        "    optimizer=sgd,\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qc41nM5Iiwi"
      },
      "source": [
        "##Training of the simple model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LV_QA_1elER7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "775b7340-51d9-417d-90cb-919d2f9cfdc4"
      },
      "source": [
        " tf.random.set_seed(1234)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=0,restore_best_weights=True)\n",
        "hist_s=model_simple.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     #callbacks=[early_stop],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 1.5844 - accuracy: 0.4817 - val_loss: 2.9287 - val_accuracy: 0.0458\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.9469 - accuracy: 0.6993 - val_loss: 3.7234 - val_accuracy: 0.0458\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.6949 - accuracy: 0.7960 - val_loss: 4.6698 - val_accuracy: 0.1375\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.5534 - accuracy: 0.8468 - val_loss: 5.5069 - val_accuracy: 0.1402\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.4468 - accuracy: 0.8882 - val_loss: 4.8059 - val_accuracy: 0.1941\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3601 - accuracy: 0.9193 - val_loss: 3.8540 - val_accuracy: 0.2597\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.3016 - accuracy: 0.9336 - val_loss: 2.3053 - val_accuracy: 0.3405\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2530 - accuracy: 0.9467 - val_loss: 1.0336 - val_accuracy: 0.6541\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.2117 - accuracy: 0.9636 - val_loss: 0.9321 - val_accuracy: 0.6721\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.1800 - accuracy: 0.9731 - val_loss: 0.6357 - val_accuracy: 0.7934\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.1558 - accuracy: 0.9792 - val_loss: 0.5972 - val_accuracy: 0.7996\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.1289 - accuracy: 0.9855 - val_loss: 0.6504 - val_accuracy: 0.7745\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.1199 - accuracy: 0.9864 - val_loss: 0.9609 - val_accuracy: 0.6792\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0974 - accuracy: 0.9932 - val_loss: 0.5511 - val_accuracy: 0.8185\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0823 - accuracy: 0.9962 - val_loss: 0.5175 - val_accuracy: 0.8257\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0753 - accuracy: 0.9964 - val_loss: 0.5453 - val_accuracy: 0.8212\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0662 - accuracy: 0.9973 - val_loss: 0.5589 - val_accuracy: 0.8131\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0604 - accuracy: 0.9973 - val_loss: 0.5284 - val_accuracy: 0.8329\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0527 - accuracy: 0.9989 - val_loss: 0.5033 - val_accuracy: 0.8302\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0458 - accuracy: 0.9995 - val_loss: 0.4694 - val_accuracy: 0.8500\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0461 - accuracy: 0.9989 - val_loss: 0.4681 - val_accuracy: 0.8455\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0396 - accuracy: 0.9995 - val_loss: 0.4602 - val_accuracy: 0.8553\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0370 - accuracy: 0.9998 - val_loss: 0.4826 - val_accuracy: 0.8473\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0348 - accuracy: 0.9995 - val_loss: 0.7047 - val_accuracy: 0.7727\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0295 - accuracy: 0.9998 - val_loss: 0.6956 - val_accuracy: 0.7799\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0290 - accuracy: 0.9998 - val_loss: 0.4946 - val_accuracy: 0.8329\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.8625\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.8527\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0237 - accuracy: 0.9998 - val_loss: 0.6073 - val_accuracy: 0.8077\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0220 - accuracy: 1.0000 - val_loss: 3.0686 - val_accuracy: 0.3845\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0245 - accuracy: 0.9998 - val_loss: 0.5933 - val_accuracy: 0.8194\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8598\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.8437\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0183 - accuracy: 0.9998 - val_loss: 0.6455 - val_accuracy: 0.7862\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0180 - accuracy: 0.9998 - val_loss: 0.4438 - val_accuracy: 0.8598\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.8589\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.7996\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.8544\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.8607\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8338\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8571\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.8661\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.8176\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.8535\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.8544\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.8607\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.8284\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.8544\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8616\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.8562\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8697\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8607\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.8652\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.8661\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8751\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8715\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8670\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.8706\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.8706\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.8688\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8661\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8652\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8697\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.8715\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8625\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8697\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.8724\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8742\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8670\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8751\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8652\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.8697\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.8706\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.8706\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8688\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8688\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.8724\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8751\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.8796\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8706\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8661\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.8670\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8679\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8706\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.8697\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8706\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.8715\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.8751\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.8733\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8796\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.8697\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8778\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8661\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.8769\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.8760\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8724\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.8778\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8706\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8769\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8769\n",
            "Epoch 101/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8769\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.8724\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.8778\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.8805\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.8491\n",
            "Epoch 106/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.8733\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8724\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8778\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8733\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.8796\n",
            "Epoch 111/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8760\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.8778\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8796\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.8823\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.8742\n",
            "Epoch 116/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.8733\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8760\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8823\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8769\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.8742\n",
            "Epoch 121/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8769\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.8778\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8823\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.8787\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8796\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8715\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8760\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8796\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.8778\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.8760\n",
            "Epoch 131/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8778\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.8814\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.8769\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8751\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8796\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.8778\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8841\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.8742\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.8814\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.8805\n",
            "Epoch 141/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8751\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.8805\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8742\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8823\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.8760\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8778\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8787\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.8760\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.8796\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.8805\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.8832\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.8814\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.8760\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8787\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8796\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8850\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.8832\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.8796\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.8787\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.8805\n",
            "Epoch 161/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.8805\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.8841\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.8805\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.8841\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.8778\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8814\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.8769\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.8769\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.8715\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.8787\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8760\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.8625\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8814\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.8715\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.8832\n",
            "Epoch 176/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8751\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8796\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8760\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8805\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.8805\n",
            "Epoch 181/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8805\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.8832\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.8859\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8823\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.8805\n",
            "Epoch 186/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.8805\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8868\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.8823\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.8778\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.8841\n",
            "Epoch 191/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.8823\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8796\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.8823\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.8769\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.8859\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8823\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8823\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.8814\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.8859\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8823\n",
            "Epoch 201/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.8850\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.8796\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8787\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.8832\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.8823\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.8823\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.8832\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.8948 - val_accuracy: 0.7403\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.8841\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.8832\n",
            "Epoch 211/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.8823\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.8814\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.8805\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8832\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.8814\n",
            "Epoch 216/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8796\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.8796\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8841\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.8814\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.8796\n",
            "Epoch 221/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.8796\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8814\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8805\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.8868\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8814\n",
            "Epoch 226/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.8886\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8832\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8823\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.8841\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.8832\n",
            "Epoch 231/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8805\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8859\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8859\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.8805\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8805\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8850\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.8859\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8823\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.8814\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.8841\n",
            "Epoch 241/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8841\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.8814\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8850\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8814\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8841\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8832\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.8832\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.8850\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.8832\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.8796\n",
            "Epoch 251/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8850\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.8832\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8805\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8868\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.8841\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.8868\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.8823\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8850\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.8877\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8823\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8814\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8832\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.8814\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8796\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.8823\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.8805\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8814\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8760\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.8868\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8832\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.8841\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.8868\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.8859\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.8841\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8832\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8859\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.8877\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.8841\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8850\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8769\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.8814\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8814\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.8832\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.8796\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.8814\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.8805\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8841\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.8805\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.3940e-04 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.8850\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8841\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.7156e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8823\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8814\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.7841e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.8859\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8805\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.8868\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.8868\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.3885e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8859\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.2731e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8868\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.7680e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8895\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.8174e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8868\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.7020 - val_accuracy: 0.8095\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.4577 - val_accuracy: 0.8724\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0050 - accuracy: 0.9995 - val_loss: 0.5479 - val_accuracy: 0.8598\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8787\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8823\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.8814\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8859\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.8832\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.2990e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.8796\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.9773e-04 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8814\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.2041e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8841\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.5774e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8832\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.3050e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8850\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.3590e-04 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.8823\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.5246e-04 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.8877\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.6265e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.8823\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.2951e-04 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.8850\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.8061e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8841\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.1221e-04 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8877\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.1425e-04 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8814\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.8725e-04 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.8850\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.2448e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.8841\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.7321e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.8832\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.6060e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8823\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.6103e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.8859\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.8262e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8841\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 9.0735e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.8805\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.5958e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8850\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.5251e-04 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.8805\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.5020e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8841\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.3286e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.8823\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.2440e-04 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.8850\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.3986e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8850\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.3692e-04 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.8850\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.4761e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.8850\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.2198e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.8895\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.5931e-04 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.8823\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.3661e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8850\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.4033e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8859\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.0062e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8841\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.5591e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.8832\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.8198e-04 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.8841\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.1339e-04 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.8868\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.0572e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8868\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.5012e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.8895\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.1443e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.8823\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.2662e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.8877\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.6460e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8895\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.2184e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8823\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.9843e-04 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8823\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.1135e-04 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8823\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.1369e-04 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8796\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.0641e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.8859\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.7155e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8850\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.6677e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.8868\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.0777e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.8859\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.9682e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8832\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.4749e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.8850\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.7913e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8859\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.4700e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.8868\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.3217e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8877\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.9025e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.8814\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.3837e-04 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.8886\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.6249e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8850\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.4153e-04 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8859\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.6480e-04 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.8841\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 8.1842e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.8832\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.7374e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.8859\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.8884e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.8886\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.6764e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.8895\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.3208e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.8841\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.5570e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.8841\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.5027e-04 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8859\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.8358e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.8859\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.2342e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.8814\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.4966e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.8877\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.5360e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8859\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.3292e-04 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.8814\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1819e-04 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.8850\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.9677e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8832\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.2007e-04 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.8868\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1359e-04 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8868\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1591e-04 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8832\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.7272e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8886\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6526e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.8814\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1651e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.8868\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.0081e-04 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.8868\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.3536e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8850\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6836e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.8841\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.7210e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.8823\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.0984e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.8877\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.8351e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8877\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.0017e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8877\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1651e-04 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.8769\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1906e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.8886\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.9489e-04 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.8895\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5594e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8832\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.1505e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.8859\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.9180e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.8832\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.8460e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8886\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.3158e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8877\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.0075e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.8886\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5162e-04 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.8832\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.9360e-04 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.8814\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.7096e-04 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.8859\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.9809e-04 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.8868\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6835e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8886\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.8964e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8868\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6287e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8877\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6127e-04 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.8832\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6568e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8805\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5628e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.8841\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.4395e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8832\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 7.2465e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8868\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.3599e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8895\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6560e-04 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.8895\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.4943e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8904\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5156e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8814\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.4501e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.8886\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5695e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8886\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.0583e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8850\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.2887e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8841\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5561e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8868\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.8158e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.8841\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.6179e-04 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.8859\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.2912e-04 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.8859\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.7956e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8850\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.5714e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.8886\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1643e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8886\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.2669e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8904\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9099e-04 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8832\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1464e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8877\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.0416e-04 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8904\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.4484e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.8859\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.3141e-04 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.8877\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1475e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8859\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.8560e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.8850\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.2379e-04 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.8823\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.3869e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8868\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1284e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8850\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.3617e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8877\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.8379e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8859\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.4768e-04 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.8796\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.2929e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.8859\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9697e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.8814\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1409e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.8877\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1775e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.8886\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9917e-04 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.8868\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.8744e-04 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.8814\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.6465e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8868\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.7502e-04 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.6909\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.7407e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.8850\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.3041e-04 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.8832\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9808e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.8859\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.0580e-04 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8868\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.7981e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.8904\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.6602e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8913\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9370e-04 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8877\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.5751e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8904\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.7585e-04 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.8859\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.4232e-04 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8913\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.7669e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.8904\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.6065e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.8904\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9039e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8868\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2870e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.8868\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.0325e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.8850\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.6306e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.8823\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.4729e-04 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.8859\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3375e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8895\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.0323e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8850\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.8125e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8877\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.9017e-04 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8868\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.7074e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8886\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3476e-04 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8823\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2672e-04 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8868\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.5858e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8886\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.8788e-04 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8886\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 6.1715e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.8859\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.6552e-04 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.8814\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.6086e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.8850\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.7111e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.8859\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.8322e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8850\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3204e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8895\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3612e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8904\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2742e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8868\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.4830e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.8904\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3458e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.8841\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.1630e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.8850\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.5385e-04 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.8814\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2186e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8859\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3308e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8886\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.1808e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8850\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.4443e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8868\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2741e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.8868\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 4.9986e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.8877\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2812e-04 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.8877\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.1600e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.8877\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.2785e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8868\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.3423e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8859\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 1s 9ms/step - loss: 5.1527e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.8850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGmZ-27P0mhf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9a31fd53-3cea-4e03-9b0b-6bb830d964bc"
      },
      "source": [
        "pruningcallback_0=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.75,pruning_step=10)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p=model_to_prune_0.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_0],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 1.5768 - accuracy: 0.4817 - val_loss: 2.9206 - val_accuracy: 0.0467\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9485 - accuracy: 0.6988 - val_loss: 3.8829 - val_accuracy: 0.0458\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7004 - accuracy: 0.7962 - val_loss: 4.9726 - val_accuracy: 0.1375\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5556 - accuracy: 0.8459 - val_loss: 6.4733 - val_accuracy: 0.1375\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4522 - accuracy: 0.8870 - val_loss: 5.0073 - val_accuracy: 0.1986\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3650 - accuracy: 0.9171 - val_loss: 3.5180 - val_accuracy: 0.2785\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3020 - accuracy: 0.9374 - val_loss: 2.0920 - val_accuracy: 0.3935\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2551 - accuracy: 0.9498 - val_loss: 0.9312 - val_accuracy: 0.6846\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2164 - accuracy: 0.9627 - val_loss: 0.6238 - val_accuracy: 0.7978\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1844 - accuracy: 0.9727 - val_loss: 0.9133 - val_accuracy: 0.6846\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1581 - accuracy: 0.9801 - val_loss: 0.6483 - val_accuracy: 0.7951\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1297 - accuracy: 0.9842 - val_loss: 0.6660 - val_accuracy: 0.7853\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1209 - accuracy: 0.9878 - val_loss: 2.0405 - val_accuracy: 0.4187\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1001 - accuracy: 0.9919 - val_loss: 0.5715 - val_accuracy: 0.8140\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0839 - accuracy: 0.9964 - val_loss: 0.5185 - val_accuracy: 0.8302\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0775 - accuracy: 0.9966 - val_loss: 0.5804 - val_accuracy: 0.8086\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0665 - accuracy: 0.9977 - val_loss: 0.6411 - val_accuracy: 0.7853\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0601 - accuracy: 0.9982 - val_loss: 0.5328 - val_accuracy: 0.8230\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0542 - accuracy: 0.9991 - val_loss: 0.4913 - val_accuracy: 0.8311\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0475 - accuracy: 0.9998 - val_loss: 0.4801 - val_accuracy: 0.8383\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0478 - accuracy: 0.9993 - val_loss: 0.4783 - val_accuracy: 0.8455\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0406 - accuracy: 0.9991 - val_loss: 0.5097 - val_accuracy: 0.8356\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0381 - accuracy: 0.9993 - val_loss: 0.5086 - val_accuracy: 0.8446\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0361 - accuracy: 0.9998 - val_loss: 0.5315 - val_accuracy: 0.8212\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.8392\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9998 - val_loss: 0.5877 - val_accuracy: 0.8167\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8491\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.8446\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0245 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.8212\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.6145 - val_accuracy: 0.7987\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0215 - accuracy: 0.9998 - val_loss: 0.5211 - val_accuracy: 0.8401\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.8518\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.8410\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 0.9998 - val_loss: 0.8483 - val_accuracy: 0.7269\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0189 - accuracy: 0.9998 - val_loss: 0.4669 - val_accuracy: 0.8553\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.8544\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8374\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.8562\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8553\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.8535\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.8473\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8544\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5760 - val_accuracy: 0.8122\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.8535\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8562\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.8616\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.8607\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8571\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.8562\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.8544\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.8607\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8580\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.8616\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8446\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8616\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.8598\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.8535\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.8679\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8634\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.8643\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.8598\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8607\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.8527\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8643\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8571\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.8643\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.8670\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.8607\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8661\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8661\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.8661\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8670\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8670\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8697\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8706\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.8634\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.8634\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.8625\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8571\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.8706\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.8715\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8688\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.8598\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.8652\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.8535\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.8607\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8670\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.8706\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.8652\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8661\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.8688\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8625\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.8679\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.8715\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8670\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8670\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8625\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.8625\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8670\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.8670\n",
            "Epoch 101/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.8661\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.0577 - accuracy: 0.6731 - val_loss: 2.1936 - val_accuracy: 0.3944\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6541 - accuracy: 0.8145 - val_loss: 2.1627 - val_accuracy: 0.3540\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5272 - accuracy: 0.8552 - val_loss: 2.4043 - val_accuracy: 0.3711\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4312 - accuracy: 0.8839 - val_loss: 2.0401 - val_accuracy: 0.4142\n",
            "Epoch 106/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3577 - accuracy: 0.9083 - val_loss: 2.4313 - val_accuracy: 0.3980\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3129 - accuracy: 0.9245 - val_loss: 0.6353 - val_accuracy: 0.7969\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2664 - accuracy: 0.9408 - val_loss: 1.1254 - val_accuracy: 0.6460\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2345 - accuracy: 0.9467 - val_loss: 0.5348 - val_accuracy: 0.8293\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2034 - accuracy: 0.9598 - val_loss: 0.7992 - val_accuracy: 0.7358\n",
            "Epoch 111/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9645\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1827 - accuracy: 0.9645 - val_loss: 0.8227 - val_accuracy: 0.7179\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2688 - accuracy: 0.9388 - val_loss: 0.6243 - val_accuracy: 0.8068\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2068 - accuracy: 0.9568 - val_loss: 0.6651 - val_accuracy: 0.7745\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1694 - accuracy: 0.9695 - val_loss: 0.7734 - val_accuracy: 0.7341\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1517 - accuracy: 0.9774 - val_loss: 0.6194 - val_accuracy: 0.8014\n",
            "Epoch 116/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1303 - accuracy: 0.9790 - val_loss: 1.9595 - val_accuracy: 0.5004\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1224 - accuracy: 0.9819 - val_loss: 0.6218 - val_accuracy: 0.7951\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0986 - accuracy: 0.9910 - val_loss: 0.4569 - val_accuracy: 0.8607\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0866 - accuracy: 0.9948 - val_loss: 0.8812 - val_accuracy: 0.6927\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0830 - accuracy: 0.9937 - val_loss: 0.8586 - val_accuracy: 0.7215\n",
            "Epoch 121/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0687 - accuracy: 0.9967\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0686 - accuracy: 0.9968 - val_loss: 0.6894 - val_accuracy: 0.7610\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9686 - val_loss: 0.7887 - val_accuracy: 0.7493\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1100 - accuracy: 0.9851 - val_loss: 0.4833 - val_accuracy: 0.8338\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0880 - accuracy: 0.9928 - val_loss: 0.9929 - val_accuracy: 0.6900\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.9950 - val_loss: 0.4742 - val_accuracy: 0.8392\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0665 - accuracy: 0.9982 - val_loss: 0.5059 - val_accuracy: 0.8311\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0591 - accuracy: 0.9986 - val_loss: 0.4461 - val_accuracy: 0.8589\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0551 - accuracy: 0.9977 - val_loss: 0.4484 - val_accuracy: 0.8598\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0466 - accuracy: 0.9995 - val_loss: 0.6396 - val_accuracy: 0.7880\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0453 - accuracy: 0.9982 - val_loss: 0.6679 - val_accuracy: 0.7736\n",
            "Epoch 131/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0383 - accuracy: 0.9995\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0383 - accuracy: 0.9995 - val_loss: 0.4348 - val_accuracy: 0.8580\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2826 - accuracy: 0.9200 - val_loss: 1.6816 - val_accuracy: 0.4942\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1005 - accuracy: 0.9862 - val_loss: 1.8035 - val_accuracy: 0.5283\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0769 - accuracy: 0.9962 - val_loss: 1.3368 - val_accuracy: 0.5678\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0645 - accuracy: 0.9982 - val_loss: 0.5216 - val_accuracy: 0.8266\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0556 - accuracy: 0.9982 - val_loss: 0.6230 - val_accuracy: 0.8041\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 0.9993 - val_loss: 0.4700 - val_accuracy: 0.8562\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0428 - accuracy: 0.9995 - val_loss: 0.5026 - val_accuracy: 0.8446\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0365 - accuracy: 0.9998 - val_loss: 0.4412 - val_accuracy: 0.8553\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0323 - accuracy: 0.9995 - val_loss: 0.5585 - val_accuracy: 0.8302\n",
            "Epoch 141/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0290 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8742\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0929 - accuracy: 0.9916 - val_loss: 0.6471 - val_accuracy: 0.7853\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0668 - accuracy: 0.9984 - val_loss: 1.3572 - val_accuracy: 0.6074\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0583 - accuracy: 0.9980 - val_loss: 0.5387 - val_accuracy: 0.8122\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0527 - accuracy: 0.9980 - val_loss: 0.4584 - val_accuracy: 0.8670\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0430 - accuracy: 0.9998 - val_loss: 0.5835 - val_accuracy: 0.8149\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0395 - accuracy: 1.0000 - val_loss: 0.7165 - val_accuracy: 0.7655\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0340 - accuracy: 0.9998 - val_loss: 0.4044 - val_accuracy: 0.8814\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8697\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8401\n",
            "Epoch 151/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0264 - accuracy: 0.9998\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 0.9998 - val_loss: 0.5362 - val_accuracy: 0.8464\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1679 - accuracy: 0.9596 - val_loss: 0.8370 - val_accuracy: 0.7421\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0887 - accuracy: 0.9892 - val_loss: 1.5795 - val_accuracy: 0.5804\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0673 - accuracy: 0.9950 - val_loss: 0.5387 - val_accuracy: 0.8419\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0494 - accuracy: 0.9986 - val_loss: 0.4382 - val_accuracy: 0.8688\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0463 - accuracy: 0.9986 - val_loss: 0.4917 - val_accuracy: 0.8428\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 0.9986 - val_loss: 0.4888 - val_accuracy: 0.8392\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0355 - accuracy: 0.9998 - val_loss: 0.4374 - val_accuracy: 0.8535\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.8643\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.8661\n",
            "Epoch 161/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.8697\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1824 - accuracy: 0.9564 - val_loss: 0.9655 - val_accuracy: 0.7026\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0885 - accuracy: 0.9901 - val_loss: 0.5558 - val_accuracy: 0.8284\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0642 - accuracy: 0.9966 - val_loss: 0.5354 - val_accuracy: 0.8311\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0525 - accuracy: 0.9989 - val_loss: 0.4817 - val_accuracy: 0.8464\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0459 - accuracy: 0.9989 - val_loss: 0.7697 - val_accuracy: 0.7565\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0387 - accuracy: 0.9998 - val_loss: 0.4607 - val_accuracy: 0.8643\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0355 - accuracy: 0.9998 - val_loss: 0.5942 - val_accuracy: 0.8176\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0318 - accuracy: 0.9998 - val_loss: 0.5266 - val_accuracy: 0.8329\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.8724\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.8562\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7219 - accuracy: 0.7695 - val_loss: 1.4069 - val_accuracy: 0.5499\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3055 - accuracy: 0.9198 - val_loss: 1.6599 - val_accuracy: 0.5058\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2196 - accuracy: 0.9489 - val_loss: 2.4324 - val_accuracy: 0.3819\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1825 - accuracy: 0.9600 - val_loss: 1.2363 - val_accuracy: 0.5930\n",
            "Epoch 176/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1352 - accuracy: 0.9776 - val_loss: 0.5744 - val_accuracy: 0.8374\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1079 - accuracy: 0.9871 - val_loss: 0.6900 - val_accuracy: 0.7763\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0906 - accuracy: 0.9905 - val_loss: 2.1629 - val_accuracy: 0.5166\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0820 - accuracy: 0.9932 - val_loss: 0.4930 - val_accuracy: 0.8518\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0704 - accuracy: 0.9955 - val_loss: 0.9457 - val_accuracy: 0.7197\n",
            "Epoch 181/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9993\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0562 - accuracy: 0.9993 - val_loss: 0.4925 - val_accuracy: 0.8455\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5094 - accuracy: 0.8437 - val_loss: 9.4641 - val_accuracy: 0.0854\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2236 - accuracy: 0.9478 - val_loss: 1.4182 - val_accuracy: 0.5553\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1608 - accuracy: 0.9684 - val_loss: 0.8877 - val_accuracy: 0.7385\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1232 - accuracy: 0.9801 - val_loss: 0.5056 - val_accuracy: 0.8544\n",
            "Epoch 186/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0918 - accuracy: 0.9898 - val_loss: 0.5000 - val_accuracy: 0.8221\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0808 - accuracy: 0.9930 - val_loss: 0.5698 - val_accuracy: 0.8293\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0696 - accuracy: 0.9966 - val_loss: 0.5280 - val_accuracy: 0.8338\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0590 - accuracy: 0.9959 - val_loss: 0.5959 - val_accuracy: 0.8311\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0493 - accuracy: 0.9984 - val_loss: 0.4704 - val_accuracy: 0.8527\n",
            "Epoch 191/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0426 - accuracy: 0.9998\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0428 - accuracy: 0.9998 - val_loss: 0.4509 - val_accuracy: 0.8679\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5324 - accuracy: 0.8403 - val_loss: 0.8772 - val_accuracy: 0.7071\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9442 - val_loss: 0.9681 - val_accuracy: 0.7053\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9602 - val_loss: 0.5559 - val_accuracy: 0.8248\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9812 - val_loss: 1.0650 - val_accuracy: 0.6397\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1021 - accuracy: 0.9887 - val_loss: 0.6864 - val_accuracy: 0.7691\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0829 - accuracy: 0.9946 - val_loss: 1.2723 - val_accuracy: 0.6765\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0722 - accuracy: 0.9948 - val_loss: 0.7287 - val_accuracy: 0.7475\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0594 - accuracy: 0.9968 - val_loss: 0.4813 - val_accuracy: 0.8580\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0501 - accuracy: 0.9984 - val_loss: 0.5309 - val_accuracy: 0.8239\n",
            "Epoch 201/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0428 - accuracy: 0.9988\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0422 - accuracy: 0.9989 - val_loss: 0.4632 - val_accuracy: 0.8625\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1466 - accuracy: 0.9763 - val_loss: 0.6168 - val_accuracy: 0.7996\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0956 - accuracy: 0.9939 - val_loss: 0.7728 - val_accuracy: 0.7592\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0759 - accuracy: 0.9977 - val_loss: 1.0950 - val_accuracy: 0.6586\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0641 - accuracy: 0.9975 - val_loss: 0.5004 - val_accuracy: 0.8446\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0541 - accuracy: 0.9993 - val_loss: 0.5254 - val_accuracy: 0.8473\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0497 - accuracy: 0.9984 - val_loss: 0.5070 - val_accuracy: 0.8419\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0430 - accuracy: 0.9993 - val_loss: 0.9003 - val_accuracy: 0.7305\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0427 - accuracy: 0.9991 - val_loss: 0.4825 - val_accuracy: 0.8562\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.8571\n",
            "Epoch 211/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0322 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8670\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1340 - accuracy: 0.9806 - val_loss: 0.5716 - val_accuracy: 0.8149\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0912 - accuracy: 0.9937 - val_loss: 0.8647 - val_accuracy: 0.7206\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0778 - accuracy: 0.9946 - val_loss: 0.5789 - val_accuracy: 0.8320\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0687 - accuracy: 0.9962 - val_loss: 0.6470 - val_accuracy: 0.7889\n",
            "Epoch 216/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0527 - accuracy: 0.9989 - val_loss: 0.6036 - val_accuracy: 0.8032\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0462 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8527\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0400 - accuracy: 0.9998 - val_loss: 0.9431 - val_accuracy: 0.7044\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0384 - accuracy: 0.9993 - val_loss: 0.7204 - val_accuracy: 0.8050\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0354 - accuracy: 0.9998 - val_loss: 0.6219 - val_accuracy: 0.8005\n",
            "Epoch 221/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0306 - accuracy: 0.9990\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9991 - val_loss: 0.4458 - val_accuracy: 0.8751\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2283 - accuracy: 0.9564 - val_loss: 0.6413 - val_accuracy: 0.7987\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1564 - accuracy: 0.9747 - val_loss: 0.5122 - val_accuracy: 0.8491\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1099 - accuracy: 0.9907 - val_loss: 0.5182 - val_accuracy: 0.8419\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1049 - accuracy: 0.9905 - val_loss: 0.5288 - val_accuracy: 0.8257\n",
            "Epoch 226/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0762 - accuracy: 0.9968 - val_loss: 0.6219 - val_accuracy: 0.8077\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0647 - accuracy: 0.9986 - val_loss: 0.4725 - val_accuracy: 0.8571\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0537 - accuracy: 0.9993 - val_loss: 0.4668 - val_accuracy: 0.8473\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0466 - accuracy: 0.9995 - val_loss: 0.4918 - val_accuracy: 0.8464\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0433 - accuracy: 0.9993 - val_loss: 0.5417 - val_accuracy: 0.8194\n",
            "Epoch 231/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0414 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 0.9998 - val_loss: 1.1726 - val_accuracy: 0.6397\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2280 - accuracy: 0.9496 - val_loss: 0.5550 - val_accuracy: 0.8257\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1419 - accuracy: 0.9806 - val_loss: 0.6806 - val_accuracy: 0.7763\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1042 - accuracy: 0.9910 - val_loss: 1.0333 - val_accuracy: 0.6730\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.9930 - val_loss: 0.5007 - val_accuracy: 0.8482\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0747 - accuracy: 0.9950 - val_loss: 0.8806 - val_accuracy: 0.7358\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0685 - accuracy: 0.9955 - val_loss: 0.5033 - val_accuracy: 0.8455\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0579 - accuracy: 0.9980 - val_loss: 0.5367 - val_accuracy: 0.8320\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0477 - accuracy: 0.9986 - val_loss: 0.4828 - val_accuracy: 0.8491\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 0.9995 - val_loss: 0.4635 - val_accuracy: 0.8527\n",
            "Epoch 241/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0437 - accuracy: 0.9983\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0437 - accuracy: 0.9984 - val_loss: 0.4818 - val_accuracy: 0.8535\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2334 - accuracy: 0.9446 - val_loss: 1.0802 - val_accuracy: 0.6469\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1461 - accuracy: 0.9776 - val_loss: 0.6775 - val_accuracy: 0.7817\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1068 - accuracy: 0.9873 - val_loss: 0.5465 - val_accuracy: 0.8320\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0970 - accuracy: 0.9896 - val_loss: 0.5613 - val_accuracy: 0.8221\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0803 - accuracy: 0.9937 - val_loss: 0.6269 - val_accuracy: 0.8032\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0653 - accuracy: 0.9975 - val_loss: 0.5784 - val_accuracy: 0.8248\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0533 - accuracy: 0.9986 - val_loss: 0.5702 - val_accuracy: 0.8167\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0462 - accuracy: 0.9998 - val_loss: 0.4642 - val_accuracy: 0.8518\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0505 - accuracy: 0.9977 - val_loss: 0.4572 - val_accuracy: 0.8625\n",
            "Epoch 251/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0429 - accuracy: 0.9990\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 0.9991 - val_loss: 0.4424 - val_accuracy: 0.8616\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2901 - accuracy: 0.9318 - val_loss: 1.3862 - val_accuracy: 0.5400\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2018 - accuracy: 0.9648 - val_loss: 1.2387 - val_accuracy: 0.6271\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1417 - accuracy: 0.9806 - val_loss: 0.6495 - val_accuracy: 0.8086\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1209 - accuracy: 0.9851 - val_loss: 0.5126 - val_accuracy: 0.8338\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1028 - accuracy: 0.9923 - val_loss: 0.6145 - val_accuracy: 0.7987\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0878 - accuracy: 0.9921 - val_loss: 0.6303 - val_accuracy: 0.7978\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0795 - accuracy: 0.9939 - val_loss: 0.7261 - val_accuracy: 0.7745\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0722 - accuracy: 0.9962 - val_loss: 0.5475 - val_accuracy: 0.8365\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0574 - accuracy: 0.9984 - val_loss: 0.5200 - val_accuracy: 0.8347\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0506 - accuracy: 0.9982 - val_loss: 0.5400 - val_accuracy: 0.8374\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0479 - accuracy: 0.9986 - val_loss: 0.6299 - val_accuracy: 0.8041\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0488 - accuracy: 0.9980 - val_loss: 0.5961 - val_accuracy: 0.8104\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0376 - accuracy: 0.9998 - val_loss: 0.5487 - val_accuracy: 0.8392\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0342 - accuracy: 0.9998 - val_loss: 0.4975 - val_accuracy: 0.8464\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0353 - accuracy: 0.9995 - val_loss: 0.5311 - val_accuracy: 0.8482\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0298 - accuracy: 0.9998 - val_loss: 0.5305 - val_accuracy: 0.8275\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0309 - accuracy: 0.9991 - val_loss: 0.6436 - val_accuracy: 0.8050\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.8473\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0254 - accuracy: 0.9989 - val_loss: 0.5379 - val_accuracy: 0.8553\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.8544\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.8553\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0210 - accuracy: 0.9995 - val_loss: 0.6394 - val_accuracy: 0.8077\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0231 - accuracy: 0.9995 - val_loss: 0.5017 - val_accuracy: 0.8437\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0193 - accuracy: 0.9998 - val_loss: 0.5097 - val_accuracy: 0.8518\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.8571\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9995 - val_loss: 0.5543 - val_accuracy: 0.8338\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.8544\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.8571\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.6464 - val_accuracy: 0.8266\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.8535\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.8535\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.8527\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.0517 - val_accuracy: 0.6882\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.8589\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0136 - accuracy: 0.9995 - val_loss: 0.5522 - val_accuracy: 0.8437\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.8580\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.5329 - val_accuracy: 0.8518\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.8544\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5492 - val_accuracy: 0.8401\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.8589\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.5243 - val_accuracy: 0.8544\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.8518\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.8580\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.5216 - val_accuracy: 0.8598\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.4971 - val_accuracy: 0.8562\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.8527\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.8544\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.5149 - val_accuracy: 0.8598\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.8553\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 3.3846 - val_accuracy: 0.5184\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0152 - accuracy: 0.9986 - val_loss: 0.5464 - val_accuracy: 0.8473\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.8607\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.8580\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.8562\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.8697\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.8598\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.8580\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.8571\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8562\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.8571\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8598\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.8625\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.8562\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.8544\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5230 - val_accuracy: 0.8589\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.8580\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8652\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8598\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.8598\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5203 - val_accuracy: 0.8553\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 0.9998 - val_loss: 0.5261 - val_accuracy: 0.8625\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8598\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5213 - val_accuracy: 0.8616\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8580\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5245 - val_accuracy: 0.8652\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8607\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.8634\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5186 - val_accuracy: 0.8661\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 0.8661\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.8571\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.8518\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.8679\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8607\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5367 - val_accuracy: 0.8616\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.8500\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.6175 - val_accuracy: 0.8383\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5331 - val_accuracy: 0.8607\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.8661\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.8661\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.8616\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8661\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5289 - val_accuracy: 0.8625\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.5337 - val_accuracy: 0.8661\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5338 - val_accuracy: 0.8661\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5332 - val_accuracy: 0.8607\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5445 - val_accuracy: 0.8625\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.8598\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.8598\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5414 - val_accuracy: 0.8616\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8688\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.8598\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.8616\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.7042 - val_accuracy: 0.8347\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8607\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.8652\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5361 - val_accuracy: 0.8598\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.8625\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5443 - val_accuracy: 0.8607\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.8625\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5838 - val_accuracy: 0.8589\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5475 - val_accuracy: 0.8634\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.8643\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5747 - val_accuracy: 0.8527\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.8571\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.8607\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.8616\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.8616\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5373 - val_accuracy: 0.8625\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.5253 - val_accuracy: 0.8643\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.8544\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.8661\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5360 - val_accuracy: 0.8661\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.8625\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.8634\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5917 - val_accuracy: 0.8518\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8616\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5389 - val_accuracy: 0.8688\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.8616\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8616\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5378 - val_accuracy: 0.8625\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.8634\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5306 - val_accuracy: 0.8670\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5271 - val_accuracy: 0.8643\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5479 - val_accuracy: 0.8643\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5491 - val_accuracy: 0.8616\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.8616\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8634\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.8607\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.8652\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5358 - val_accuracy: 0.8634\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.8616\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5707 - val_accuracy: 0.8562\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.8634\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5406 - val_accuracy: 0.8589\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5644 - val_accuracy: 0.8625\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.8652\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8643\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5425 - val_accuracy: 0.8598\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8562\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5450 - val_accuracy: 0.8643\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5420 - val_accuracy: 0.8652\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.8634\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8679\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.8643\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8643\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5418 - val_accuracy: 0.8688\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.8616\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5421 - val_accuracy: 0.8589\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.8598\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.8661\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5536 - val_accuracy: 0.8643\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7687 - val_accuracy: 0.8041\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1334 - accuracy: 0.9614 - val_loss: 0.6905 - val_accuracy: 0.8068\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 0.9989 - val_loss: 0.7523 - val_accuracy: 0.8212\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8652\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.8706\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.8679\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8679\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5339 - val_accuracy: 0.8670\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8670\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8661\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.8688\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8697\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.8706\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.8661\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.8670\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5261 - val_accuracy: 0.8679\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5280 - val_accuracy: 0.8661\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5321 - val_accuracy: 0.8616\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.8616\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.8724\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.8706\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8580\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.8706\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.8670\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.8688\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5506 - val_accuracy: 0.8571\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.8670\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8670\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5441 - val_accuracy: 0.8724\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5320 - val_accuracy: 0.8679\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.8634\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5480 - val_accuracy: 0.8625\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.8652\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.8724\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5350 - val_accuracy: 0.8634\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.8715\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.8688\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5605 - val_accuracy: 0.8643\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5970 - val_accuracy: 0.8491\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5550 - val_accuracy: 0.8652\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 0.8670\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.8715\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.8652\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.8679\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.8688\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.8670\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5526 - val_accuracy: 0.8598\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.8589\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8643\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.8679\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.8643\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.8697\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.8697\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.8670\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.8661\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.8643\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5503 - val_accuracy: 0.8661\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5481 - val_accuracy: 0.8652\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.8706\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.8670\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.8652\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5490 - val_accuracy: 0.8661\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.8625\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5625 - val_accuracy: 0.8562\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5465 - val_accuracy: 0.8634\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5598 - val_accuracy: 0.8607\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5895 - val_accuracy: 0.8634\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5667 - val_accuracy: 0.8589\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.8670\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5665 - val_accuracy: 0.8607\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.8661\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5703 - val_accuracy: 0.8661\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5392 - val_accuracy: 0.8679\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5487 - val_accuracy: 0.8652\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.8652\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5509 - val_accuracy: 0.8607\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.8643\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5499 - val_accuracy: 0.8670\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5569 - val_accuracy: 0.8661\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.8625\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5586 - val_accuracy: 0.8661\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5698 - val_accuracy: 0.8598\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.8643\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5539 - val_accuracy: 0.8634\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5601 - val_accuracy: 0.8625\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5497 - val_accuracy: 0.8652\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5621 - val_accuracy: 0.8643\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.5548 - val_accuracy: 0.8652\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cll-VIU1_adh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c26209c1-0cfe-441e-c2a9-be4c93534263"
      },
      "source": [
        "pruningcallback_1=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.8,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_1=model_to_prune_1.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_1],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 1.5855 - accuracy: 0.4702 - val_loss: 2.9552 - val_accuracy: 0.0458\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9563 - accuracy: 0.6975 - val_loss: 3.9122 - val_accuracy: 0.0458\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7057 - accuracy: 0.7955 - val_loss: 4.9842 - val_accuracy: 0.1366\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5616 - accuracy: 0.8464 - val_loss: 5.7556 - val_accuracy: 0.1375\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4574 - accuracy: 0.8841 - val_loss: 4.8152 - val_accuracy: 0.1923\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3700 - accuracy: 0.9137 - val_loss: 3.3287 - val_accuracy: 0.2633\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3096 - accuracy: 0.9324 - val_loss: 2.5937 - val_accuracy: 0.3432\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2576 - accuracy: 0.9471 - val_loss: 1.0272 - val_accuracy: 0.6325\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2174 - accuracy: 0.9620 - val_loss: 0.6360 - val_accuracy: 0.7960\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1876 - accuracy: 0.9711 - val_loss: 0.6976 - val_accuracy: 0.7556\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1617 - accuracy: 0.9797 - val_loss: 0.7342 - val_accuracy: 0.7457\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1319 - accuracy: 0.9860 - val_loss: 0.7540 - val_accuracy: 0.7421\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1232 - accuracy: 0.9858 - val_loss: 1.7735 - val_accuracy: 0.4879\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1015 - accuracy: 0.9930 - val_loss: 0.5809 - val_accuracy: 0.8140\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0852 - accuracy: 0.9971 - val_loss: 0.4809 - val_accuracy: 0.8401\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0787 - accuracy: 0.9941 - val_loss: 0.5910 - val_accuracy: 0.8095\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0677 - accuracy: 0.9975 - val_loss: 0.5656 - val_accuracy: 0.8059\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0605 - accuracy: 0.9984 - val_loss: 0.5149 - val_accuracy: 0.8266\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0548 - accuracy: 0.9991 - val_loss: 0.4827 - val_accuracy: 0.8401\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0479 - accuracy: 0.9993 - val_loss: 0.5567 - val_accuracy: 0.8113\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0471 - accuracy: 0.9995 - val_loss: 0.5031 - val_accuracy: 0.8311\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0411 - accuracy: 0.9993 - val_loss: 0.4804 - val_accuracy: 0.8392\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0380 - accuracy: 0.9998 - val_loss: 0.5442 - val_accuracy: 0.8194\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0359 - accuracy: 0.9995 - val_loss: 0.5285 - val_accuracy: 0.8266\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.8374\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0303 - accuracy: 0.9998 - val_loss: 0.5189 - val_accuracy: 0.8212\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.8455\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.8356\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.5765 - val_accuracy: 0.8077\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.6665 - val_accuracy: 0.7862\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.8275\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.8598\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.8401\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0188 - accuracy: 0.9998 - val_loss: 0.8690 - val_accuracy: 0.7323\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.8473\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.8383\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.8347\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.8509\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8527\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8365\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.8518\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.8670\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.8131\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.8464\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.8607\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.8527\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.8365\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.8553\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8562\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.8509\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8527\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8535\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.8589\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.8455\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.8527\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.8535\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8544\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8571\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.8616\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.8571\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.8625\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.8598\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.8571\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8652\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.8634\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.8589\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.8616\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.8643\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8706\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.8697\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.8679\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.8625\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8634\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8670\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.8625\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.8643\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.8643\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8661\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.8625\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.8616\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.8616\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.8688\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8616\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.8679\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.8634\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.8634\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8652\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.8652\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8715\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.8679\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.8697\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.8634\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.8598\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.8697\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.8661\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.8670\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.8625\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8616\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.8652\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.8679\n",
            "Epoch 101/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.8688\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.1089 - accuracy: 0.6611 - val_loss: 1.8448 - val_accuracy: 0.3845\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6662 - accuracy: 0.8120 - val_loss: 3.2772 - val_accuracy: 0.2165\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5286 - accuracy: 0.8525 - val_loss: 0.8292 - val_accuracy: 0.7098\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4260 - accuracy: 0.8886 - val_loss: 3.0162 - val_accuracy: 0.3342\n",
            "Epoch 106/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.3560 - accuracy: 0.9078\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3602 - accuracy: 0.9062 - val_loss: 1.6241 - val_accuracy: 0.4915\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3923 - accuracy: 0.8947 - val_loss: 0.6400 - val_accuracy: 0.7969\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3008 - accuracy: 0.9236 - val_loss: 2.5327 - val_accuracy: 0.3989\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2578 - accuracy: 0.9424 - val_loss: 0.5618 - val_accuracy: 0.8383\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2255 - accuracy: 0.9530 - val_loss: 0.8022 - val_accuracy: 0.7332\n",
            "Epoch 111/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.1952 - accuracy: 0.9630\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1953 - accuracy: 0.9629 - val_loss: 1.0311 - val_accuracy: 0.6523\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2427 - accuracy: 0.9422 - val_loss: 1.3356 - val_accuracy: 0.5436\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1957 - accuracy: 0.9616 - val_loss: 0.7937 - val_accuracy: 0.7403\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1713 - accuracy: 0.9650 - val_loss: 0.7029 - val_accuracy: 0.7475\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1490 - accuracy: 0.9767 - val_loss: 0.7207 - val_accuracy: 0.7664\n",
            "Epoch 116/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.1279 - accuracy: 0.9807\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1282 - accuracy: 0.9806 - val_loss: 0.8247 - val_accuracy: 0.7376\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2137 - accuracy: 0.9566 - val_loss: 0.5748 - val_accuracy: 0.8131\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1509 - accuracy: 0.9763 - val_loss: 0.7433 - val_accuracy: 0.7592\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1277 - accuracy: 0.9824 - val_loss: 0.9693 - val_accuracy: 0.6586\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1137 - accuracy: 0.9873 - val_loss: 0.6449 - val_accuracy: 0.7916\n",
            "Epoch 121/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0937 - accuracy: 0.9924\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0944 - accuracy: 0.9921 - val_loss: 0.9354 - val_accuracy: 0.7035\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1747 - accuracy: 0.9681 - val_loss: 0.5927 - val_accuracy: 0.7862\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1257 - accuracy: 0.9844 - val_loss: 0.6572 - val_accuracy: 0.7601\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1018 - accuracy: 0.9896 - val_loss: 0.5836 - val_accuracy: 0.8140\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0856 - accuracy: 0.9955 - val_loss: 0.4378 - val_accuracy: 0.8482\n",
            "Epoch 126/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0764 - accuracy: 0.9953\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0764 - accuracy: 0.9953 - val_loss: 0.6186 - val_accuracy: 0.7817\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0931 - accuracy: 0.9921 - val_loss: 0.6036 - val_accuracy: 0.8140\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0833 - accuracy: 0.9953 - val_loss: 0.4917 - val_accuracy: 0.8293\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0661 - accuracy: 0.9977 - val_loss: 0.5289 - val_accuracy: 0.8176\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0617 - accuracy: 0.9977 - val_loss: 0.6518 - val_accuracy: 0.7808\n",
            "Epoch 131/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0524 - accuracy: 0.9983\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0524 - accuracy: 0.9984 - val_loss: 0.5069 - val_accuracy: 0.8446\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1541 - accuracy: 0.9670 - val_loss: 0.6140 - val_accuracy: 0.7942\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0912 - accuracy: 0.9903 - val_loss: 0.5673 - val_accuracy: 0.8050\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0712 - accuracy: 0.9962 - val_loss: 0.8412 - val_accuracy: 0.7520\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0635 - accuracy: 0.9982 - val_loss: 0.4008 - val_accuracy: 0.8787\n",
            "Epoch 136/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0540 - accuracy: 0.9988\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0543 - accuracy: 0.9989 - val_loss: 0.4101 - val_accuracy: 0.8625\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1479 - accuracy: 0.9706 - val_loss: 0.6368 - val_accuracy: 0.7745\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1146 - accuracy: 0.9788 - val_loss: 0.5086 - val_accuracy: 0.8203\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0750 - accuracy: 0.9941 - val_loss: 0.5217 - val_accuracy: 0.8257\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0644 - accuracy: 0.9964 - val_loss: 0.4498 - val_accuracy: 0.8518\n",
            "Epoch 141/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0540 - accuracy: 0.9979\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0543 - accuracy: 0.9977 - val_loss: 0.4299 - val_accuracy: 0.8598\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2014 - accuracy: 0.9528 - val_loss: 0.9236 - val_accuracy: 0.7341\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1261 - accuracy: 0.9761 - val_loss: 0.8787 - val_accuracy: 0.7008\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1003 - accuracy: 0.9853 - val_loss: 0.5203 - val_accuracy: 0.8419\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0765 - accuracy: 0.9948 - val_loss: 0.4500 - val_accuracy: 0.8625\n",
            "Epoch 146/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0664 - accuracy: 0.9955\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0664 - accuracy: 0.9957 - val_loss: 0.4143 - val_accuracy: 0.8688\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1227 - accuracy: 0.9885 - val_loss: 1.1453 - val_accuracy: 0.6496\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0927 - accuracy: 0.9939 - val_loss: 0.7458 - val_accuracy: 0.7367\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0756 - accuracy: 0.9955 - val_loss: 0.5880 - val_accuracy: 0.8095\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0678 - accuracy: 0.9975 - val_loss: 0.9833 - val_accuracy: 0.7197\n",
            "Epoch 151/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9979\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0599 - accuracy: 0.9977 - val_loss: 0.7129 - val_accuracy: 0.7475\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0953 - accuracy: 0.9912 - val_loss: 0.5694 - val_accuracy: 0.7987\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0703 - accuracy: 0.9971 - val_loss: 0.5124 - val_accuracy: 0.8338\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0603 - accuracy: 0.9984 - val_loss: 0.5088 - val_accuracy: 0.8518\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0484 - accuracy: 0.9993 - val_loss: 0.4823 - val_accuracy: 0.8598\n",
            "Epoch 156/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0480 - accuracy: 0.9995\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0480 - accuracy: 0.9995 - val_loss: 0.4579 - val_accuracy: 0.8697\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0831 - accuracy: 0.9955 - val_loss: 0.4619 - val_accuracy: 0.8607\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0665 - accuracy: 0.9973 - val_loss: 0.5458 - val_accuracy: 0.8365\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0528 - accuracy: 0.9998 - val_loss: 0.4218 - val_accuracy: 0.8661\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8643\n",
            "Epoch 161/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.6000 - val_accuracy: 0.8068\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0711 - accuracy: 0.9973 - val_loss: 0.4934 - val_accuracy: 0.8356\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0551 - accuracy: 0.9989 - val_loss: 0.4332 - val_accuracy: 0.8733\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0469 - accuracy: 0.9989 - val_loss: 0.4910 - val_accuracy: 0.8464\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0405 - accuracy: 0.9998 - val_loss: 0.4255 - val_accuracy: 0.8625\n",
            "Epoch 166/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0369 - accuracy: 0.9995\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0375 - accuracy: 0.9993 - val_loss: 0.5465 - val_accuracy: 0.8311\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6544 - accuracy: 0.7869 - val_loss: 2.4782 - val_accuracy: 0.4052\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3296 - accuracy: 0.8949 - val_loss: 0.8286 - val_accuracy: 0.7215\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2405 - accuracy: 0.9297 - val_loss: 1.4214 - val_accuracy: 0.5642\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1983 - accuracy: 0.9455 - val_loss: 0.6080 - val_accuracy: 0.7969\n",
            "Epoch 171/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.1551 - accuracy: 0.9619\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1577 - accuracy: 0.9600 - val_loss: 0.8084 - val_accuracy: 0.7332\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6903 - accuracy: 0.7727 - val_loss: 7.3067 - val_accuracy: 0.0467\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3245 - accuracy: 0.9031 - val_loss: 1.0444 - val_accuracy: 0.6496\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2210 - accuracy: 0.9431 - val_loss: 2.7427 - val_accuracy: 0.4232\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1812 - accuracy: 0.9553 - val_loss: 2.5782 - val_accuracy: 0.4358\n",
            "Epoch 176/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.1326 - accuracy: 0.9776\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1344 - accuracy: 0.9774 - val_loss: 0.8374 - val_accuracy: 0.7053\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1646 - accuracy: 0.9657 - val_loss: 0.8259 - val_accuracy: 0.7071\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1270 - accuracy: 0.9770 - val_loss: 1.1133 - val_accuracy: 0.6523\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1101 - accuracy: 0.9849 - val_loss: 0.5927 - val_accuracy: 0.8140\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0887 - accuracy: 0.9896 - val_loss: 1.2075 - val_accuracy: 0.6334\n",
            "Epoch 181/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0735 - accuracy: 0.9925\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0733 - accuracy: 0.9925 - val_loss: 0.4380 - val_accuracy: 0.8616\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3653 - accuracy: 0.8906 - val_loss: 0.7517 - val_accuracy: 0.7853\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1918 - accuracy: 0.9584 - val_loss: 0.9077 - val_accuracy: 0.7071\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1523 - accuracy: 0.9729 - val_loss: 0.7319 - val_accuracy: 0.7592\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1162 - accuracy: 0.9846 - val_loss: 0.4519 - val_accuracy: 0.8473\n",
            "Epoch 186/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0898 - accuracy: 0.9917\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0911 - accuracy: 0.9914 - val_loss: 0.5439 - val_accuracy: 0.8158\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1632 - accuracy: 0.9709 - val_loss: 1.2631 - val_accuracy: 0.5571\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1233 - accuracy: 0.9826 - val_loss: 0.6144 - val_accuracy: 0.8086\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0920 - accuracy: 0.9910 - val_loss: 0.6919 - val_accuracy: 0.7637\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0778 - accuracy: 0.9950 - val_loss: 0.4691 - val_accuracy: 0.8473\n",
            "Epoch 191/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0678 - accuracy: 0.9959\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0678 - accuracy: 0.9959 - val_loss: 0.6011 - val_accuracy: 0.8320\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0960 - accuracy: 0.9896 - val_loss: 0.6467 - val_accuracy: 0.7978\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0696 - accuracy: 0.9964 - val_loss: 0.4670 - val_accuracy: 0.8446\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0631 - accuracy: 0.9959 - val_loss: 0.4806 - val_accuracy: 0.8392\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9984 - val_loss: 0.6684 - val_accuracy: 0.8023\n",
            "Epoch 196/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0490 - accuracy: 0.9982\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0489 - accuracy: 0.9982 - val_loss: 0.5046 - val_accuracy: 0.8535\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9670 - val_loss: 0.8715 - val_accuracy: 0.7502\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1083 - accuracy: 0.9837 - val_loss: 0.5723 - val_accuracy: 0.8050\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0859 - accuracy: 0.9910 - val_loss: 0.5807 - val_accuracy: 0.8266\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0672 - accuracy: 0.9964 - val_loss: 0.6937 - val_accuracy: 0.7880\n",
            "Epoch 201/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0520 - accuracy: 0.9991\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0522 - accuracy: 0.9991 - val_loss: 0.5365 - val_accuracy: 0.8410\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1083 - accuracy: 0.9819 - val_loss: 0.5466 - val_accuracy: 0.8338\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0768 - accuracy: 0.9907 - val_loss: 0.5072 - val_accuracy: 0.8446\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0582 - accuracy: 0.9975 - val_loss: 1.2817 - val_accuracy: 0.5858\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0528 - accuracy: 0.9975 - val_loss: 0.4289 - val_accuracy: 0.8742\n",
            "Epoch 206/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0427 - accuracy: 0.9991\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0429 - accuracy: 0.9991 - val_loss: 0.5369 - val_accuracy: 0.8365\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0947 - accuracy: 0.9905 - val_loss: 0.5786 - val_accuracy: 0.8140\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0656 - accuracy: 0.9975 - val_loss: 2.4933 - val_accuracy: 0.5454\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0739 - accuracy: 0.9923 - val_loss: 0.4751 - val_accuracy: 0.8643\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0507 - accuracy: 0.9989 - val_loss: 0.5316 - val_accuracy: 0.8383\n",
            "Epoch 211/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0436 - accuracy: 0.9993\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0437 - accuracy: 0.9993 - val_loss: 0.4218 - val_accuracy: 0.8607\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0978 - accuracy: 0.9901 - val_loss: 0.5468 - val_accuracy: 0.8176\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0708 - accuracy: 0.9959 - val_loss: 0.4808 - val_accuracy: 0.8356\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0522 - accuracy: 0.9991 - val_loss: 0.4657 - val_accuracy: 0.8679\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0488 - accuracy: 0.9991 - val_loss: 0.4983 - val_accuracy: 0.8437\n",
            "Epoch 216/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0406 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0408 - accuracy: 0.9998 - val_loss: 0.4939 - val_accuracy: 0.8338\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1269 - accuracy: 0.9855 - val_loss: 3.5058 - val_accuracy: 0.2183\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0940 - accuracy: 0.9903 - val_loss: 0.7555 - val_accuracy: 0.7727\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0749 - accuracy: 0.9946 - val_loss: 0.7952 - val_accuracy: 0.7565\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0601 - accuracy: 0.9980 - val_loss: 0.5722 - val_accuracy: 0.8365\n",
            "Epoch 221/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9982\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0519 - accuracy: 0.9982 - val_loss: 0.5692 - val_accuracy: 0.8365\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1263 - accuracy: 0.9790 - val_loss: 0.6205 - val_accuracy: 0.8041\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0850 - accuracy: 0.9925 - val_loss: 0.5685 - val_accuracy: 0.8284\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0652 - accuracy: 0.9948 - val_loss: 0.5792 - val_accuracy: 0.8257\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0586 - accuracy: 0.9966 - val_loss: 0.6101 - val_accuracy: 0.8122\n",
            "Epoch 226/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0411 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.8643\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0863 - accuracy: 0.9932 - val_loss: 0.6570 - val_accuracy: 0.7925\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0628 - accuracy: 0.9980 - val_loss: 0.4716 - val_accuracy: 0.8482\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0506 - accuracy: 0.9982 - val_loss: 0.4890 - val_accuracy: 0.8527\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0463 - accuracy: 0.9989 - val_loss: 1.4716 - val_accuracy: 0.6316\n",
            "Epoch 231/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0454 - accuracy: 0.9993\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0454 - accuracy: 0.9993 - val_loss: 0.5102 - val_accuracy: 0.8338\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1681 - accuracy: 0.9688 - val_loss: 0.6548 - val_accuracy: 0.7871\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1212 - accuracy: 0.9842 - val_loss: 0.5699 - val_accuracy: 0.8239\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0929 - accuracy: 0.9923 - val_loss: 1.1553 - val_accuracy: 0.6864\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0783 - accuracy: 0.9946 - val_loss: 0.5108 - val_accuracy: 0.8392\n",
            "Epoch 236/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0651 - accuracy: 0.9958\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0650 - accuracy: 0.9959 - val_loss: 1.0513 - val_accuracy: 0.6909\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1413 - accuracy: 0.9709 - val_loss: 0.6700 - val_accuracy: 0.7844\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.9887 - val_loss: 0.5600 - val_accuracy: 0.8275\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0737 - accuracy: 0.9930 - val_loss: 0.7748 - val_accuracy: 0.7691\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0579 - accuracy: 0.9973 - val_loss: 0.4668 - val_accuracy: 0.8634\n",
            "Epoch 241/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0562 - accuracy: 0.9963\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0564 - accuracy: 0.9962 - val_loss: 0.4614 - val_accuracy: 0.8544\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1906 - accuracy: 0.9668 - val_loss: 0.8046 - val_accuracy: 0.7448\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1349 - accuracy: 0.9835 - val_loss: 0.7987 - val_accuracy: 0.7385\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1023 - accuracy: 0.9912 - val_loss: 0.5888 - val_accuracy: 0.8131\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0904 - accuracy: 0.9937 - val_loss: 0.5633 - val_accuracy: 0.8257\n",
            "Epoch 246/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9980\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0693 - accuracy: 0.9980 - val_loss: 0.5833 - val_accuracy: 0.8095\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2487 - accuracy: 0.9354 - val_loss: 0.6949 - val_accuracy: 0.7646\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1624 - accuracy: 0.9686 - val_loss: 0.7661 - val_accuracy: 0.7583\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1179 - accuracy: 0.9828 - val_loss: 0.5624 - val_accuracy: 0.8239\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1025 - accuracy: 0.9876 - val_loss: 0.6288 - val_accuracy: 0.7907\n",
            "Epoch 251/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0890 - accuracy: 0.9918\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0883 - accuracy: 0.9919 - val_loss: 0.4984 - val_accuracy: 0.8446\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2992 - accuracy: 0.9361 - val_loss: 1.1255 - val_accuracy: 0.6343\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2130 - accuracy: 0.9620 - val_loss: 0.6049 - val_accuracy: 0.8050\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1717 - accuracy: 0.9742 - val_loss: 1.1631 - val_accuracy: 0.6712\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1474 - accuracy: 0.9792 - val_loss: 0.5807 - val_accuracy: 0.8104\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1243 - accuracy: 0.9844 - val_loss: 0.7509 - val_accuracy: 0.7889\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1071 - accuracy: 0.9907 - val_loss: 0.7954 - val_accuracy: 0.7502\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0948 - accuracy: 0.9921 - val_loss: 0.7490 - val_accuracy: 0.7754\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0877 - accuracy: 0.9939 - val_loss: 0.4977 - val_accuracy: 0.8419\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0763 - accuracy: 0.9941 - val_loss: 0.4983 - val_accuracy: 0.8338\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0601 - accuracy: 0.9971 - val_loss: 0.5742 - val_accuracy: 0.8311\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0578 - accuracy: 0.9977 - val_loss: 0.5352 - val_accuracy: 0.8356\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0522 - accuracy: 0.9977 - val_loss: 0.6227 - val_accuracy: 0.8077\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0565 - accuracy: 0.9953 - val_loss: 0.5291 - val_accuracy: 0.8401\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0452 - accuracy: 0.9986 - val_loss: 0.5105 - val_accuracy: 0.8410\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0425 - accuracy: 0.9982 - val_loss: 0.5069 - val_accuracy: 0.8518\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0364 - accuracy: 0.9993 - val_loss: 0.5265 - val_accuracy: 0.8338\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0371 - accuracy: 0.9991 - val_loss: 0.5951 - val_accuracy: 0.8239\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9995 - val_loss: 0.5059 - val_accuracy: 0.8428\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9998 - val_loss: 0.4935 - val_accuracy: 0.8491\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0260 - accuracy: 0.9998 - val_loss: 0.4631 - val_accuracy: 0.8544\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.8544\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0252 - accuracy: 0.9998 - val_loss: 0.4632 - val_accuracy: 0.8500\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9980 - val_loss: 0.5527 - val_accuracy: 0.8302\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0274 - accuracy: 0.9993 - val_loss: 0.4841 - val_accuracy: 0.8500\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0208 - accuracy: 0.9998 - val_loss: 0.4929 - val_accuracy: 0.8446\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.8482\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.8527\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.5156 - val_accuracy: 0.8446\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.6007 - val_accuracy: 0.8194\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0198 - accuracy: 0.9993 - val_loss: 0.5428 - val_accuracy: 0.8491\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0185 - accuracy: 0.9995 - val_loss: 0.5818 - val_accuracy: 0.8428\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8509\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0173 - accuracy: 0.9995 - val_loss: 0.7524 - val_accuracy: 0.7655\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0175 - accuracy: 0.9993 - val_loss: 0.4965 - val_accuracy: 0.8500\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0164 - accuracy: 0.9998 - val_loss: 0.5023 - val_accuracy: 0.8473\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.8589\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.8562\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.8535\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0177 - accuracy: 0.9986 - val_loss: 0.5149 - val_accuracy: 0.8535\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.8562\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.8553\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8527\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.8491\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.5265 - val_accuracy: 0.8518\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.8500\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.5269 - val_accuracy: 0.8410\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.8607\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.6452 - val_accuracy: 0.8122\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.8553\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8446\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0113 - accuracy: 0.9998 - val_loss: 0.5128 - val_accuracy: 0.8446\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.8482\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.8544\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.8500\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8509\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.8544\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.5528 - val_accuracy: 0.8338\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.8580\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.8500\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.8518\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.8410\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.8607\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.8518\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.8571\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.8571\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.8562\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.4882 - val_accuracy: 0.8589\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.8580\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 0.9986 - val_loss: 0.4940 - val_accuracy: 0.8616\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.8544\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.8589\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8482\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.8535\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.5247 - val_accuracy: 0.8455\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.8562\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.8634\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.5180 - val_accuracy: 0.8535\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.8518\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.8544\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.8509\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.8580\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.8562\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.8616\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.8544\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9995 - val_loss: 0.4996 - val_accuracy: 0.8598\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.8464\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 0.9995 - val_loss: 0.4929 - val_accuracy: 0.8607\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.8535\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.8607\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.7736 - val_accuracy: 0.7978\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.5146 - val_accuracy: 0.8562\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.8580\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.8607\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.8598\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.8562\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.8544\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.8607\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.8607\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 0.9998 - val_loss: 0.5147 - val_accuracy: 0.8580\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.8643\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.8473\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8509\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.8616\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.8553\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.8607\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.8589\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.8589\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.8571\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.5201 - val_accuracy: 0.8580\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.8634\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8544\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.8571\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.8535\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5250 - val_accuracy: 0.8571\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.8607\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.8634\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.8580\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 0.9993 - val_loss: 0.5298 - val_accuracy: 0.8571\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.8625\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.8634\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8625\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8652\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.8625\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8598\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.8589\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.5202 - val_accuracy: 0.8509\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.8580\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.8607\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.8616\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.8634\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.8589\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.8634\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.8607\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.8634\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.8518\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.8571\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.8607\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.8571\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5376 - val_accuracy: 0.8535\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 0.9998 - val_loss: 0.5207 - val_accuracy: 0.8589\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8580\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.8607\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5166 - val_accuracy: 0.8571\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5171 - val_accuracy: 0.8562\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.8580\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.8607\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5170 - val_accuracy: 0.8616\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5347 - val_accuracy: 0.8562\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5288 - val_accuracy: 0.8535\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5174 - val_accuracy: 0.8607\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.8589\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.8598\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.8634\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5177 - val_accuracy: 0.8589\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5205 - val_accuracy: 0.8562\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5366 - val_accuracy: 0.8473\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5224 - val_accuracy: 0.8589\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8589\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.8607\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5437 - val_accuracy: 0.8643\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5181 - val_accuracy: 0.8527\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.7709 - val_accuracy: 0.8077\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8580\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.5575 - val_accuracy: 0.8509\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.8518\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8527\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.5229 - val_accuracy: 0.8607\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5231 - val_accuracy: 0.8571\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5198 - val_accuracy: 0.8571\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5225 - val_accuracy: 0.8553\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8562\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5226 - val_accuracy: 0.8571\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5199 - val_accuracy: 0.8625\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8544\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.8535\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.8544\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.8607\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 0.8589\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5220 - val_accuracy: 0.8580\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.8580\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5263 - val_accuracy: 0.8616\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5234 - val_accuracy: 0.8607\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.5158 - val_accuracy: 0.8562\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.5152 - val_accuracy: 0.8625\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5179 - val_accuracy: 0.8589\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5326 - val_accuracy: 0.8553\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.5272 - val_accuracy: 0.8598\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5541 - val_accuracy: 0.8553\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.8589\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5159 - val_accuracy: 0.8562\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.8598\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5396 - val_accuracy: 0.8571\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.8500\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5217 - val_accuracy: 0.8598\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.8607\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.8607\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8625\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 0.8491\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.8562\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.8598\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.8580\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5266 - val_accuracy: 0.8562\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.8616\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.5356 - val_accuracy: 0.8553\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.8553\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8625\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 0.8598\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 0.8571\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.8661\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.8562\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.8598\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.5321 - val_accuracy: 0.8598\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.8571\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.8598\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.5327 - val_accuracy: 0.8580\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.8562\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.8518\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8562\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8589\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.8589\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5283 - val_accuracy: 0.8580\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.8589\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.8553\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.8580\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8598\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.8527\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5298 - val_accuracy: 0.8589\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.8544\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.8527\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.8527\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.8562\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5316 - val_accuracy: 0.8580\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.8562\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.8634\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8580\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.8580\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8589\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5324 - val_accuracy: 0.8625\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.8571\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.5282 - val_accuracy: 0.8518\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5305 - val_accuracy: 0.8553\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5317 - val_accuracy: 0.8562\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5609 - val_accuracy: 0.8571\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.8527\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.8571\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.8607\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5303 - val_accuracy: 0.8571\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.8535\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8580\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BV-Btru0000d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "caffe7a3-4ea6-4c69-b0c8-5093d5c4f485"
      },
      "source": [
        "pruningcallback_2=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.85,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_2=model_to_prune_2.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_2],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 1s 12ms/step - loss: 1.5819 - accuracy: 0.4797 - val_loss: 2.9023 - val_accuracy: 0.0458\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9624 - accuracy: 0.6932 - val_loss: 3.7186 - val_accuracy: 0.1357\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7106 - accuracy: 0.7901 - val_loss: 4.9346 - val_accuracy: 0.1375\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5696 - accuracy: 0.8430 - val_loss: 5.9093 - val_accuracy: 0.1447\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4589 - accuracy: 0.8857 - val_loss: 5.3381 - val_accuracy: 0.1959\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3725 - accuracy: 0.9123 - val_loss: 3.3456 - val_accuracy: 0.2668\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3123 - accuracy: 0.9318 - val_loss: 2.1043 - val_accuracy: 0.3989\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2625 - accuracy: 0.9501 - val_loss: 1.0362 - val_accuracy: 0.6469\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2172 - accuracy: 0.9623 - val_loss: 0.6731 - val_accuracy: 0.7835\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1890 - accuracy: 0.9709 - val_loss: 0.7331 - val_accuracy: 0.7601\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1592 - accuracy: 0.9799 - val_loss: 0.6431 - val_accuracy: 0.7969\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1329 - accuracy: 0.9849 - val_loss: 1.1619 - val_accuracy: 0.6469\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1228 - accuracy: 0.9862 - val_loss: 1.0528 - val_accuracy: 0.6406\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1016 - accuracy: 0.9921 - val_loss: 0.5927 - val_accuracy: 0.8068\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0855 - accuracy: 0.9962 - val_loss: 0.5405 - val_accuracy: 0.8221\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0772 - accuracy: 0.9962 - val_loss: 0.6493 - val_accuracy: 0.8041\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0682 - accuracy: 0.9971 - val_loss: 0.5473 - val_accuracy: 0.8266\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0611 - accuracy: 0.9968 - val_loss: 0.6629 - val_accuracy: 0.7700\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0545 - accuracy: 0.9991 - val_loss: 0.5445 - val_accuracy: 0.8230\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0475 - accuracy: 0.9995 - val_loss: 0.5526 - val_accuracy: 0.8194\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0471 - accuracy: 0.9993 - val_loss: 0.4918 - val_accuracy: 0.8446\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0403 - accuracy: 0.9995 - val_loss: 0.5875 - val_accuracy: 0.8005\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0378 - accuracy: 0.9995 - val_loss: 0.4812 - val_accuracy: 0.8446\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0363 - accuracy: 0.9993 - val_loss: 0.5456 - val_accuracy: 0.8239\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.8419\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 0.6601 - val_accuracy: 0.7862\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.8401\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.8383\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.5308 - val_accuracy: 0.8266\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 0.6981\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.8401\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.8464\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.8410\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0185 - accuracy: 0.9998 - val_loss: 0.9093 - val_accuracy: 0.7269\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0180 - accuracy: 0.9998 - val_loss: 0.4768 - val_accuracy: 0.8553\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.8571\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 0.5923 - val_accuracy: 0.8257\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.8607\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.8473\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.8562\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.8473\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.8589\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.5796 - val_accuracy: 0.8149\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8509\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.8518\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.8464\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8491\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.8518\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.8500\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.8455\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.8634\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8437\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.8544\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8509\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.8571\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8544\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.8544\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.8544\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.8527\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.8544\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.8500\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.8598\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.8527\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.8616\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.8544\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.8509\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.8607\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.8535\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.8616\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.8625\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8580\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.8589\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.8544\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.8553\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.8571\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.8598\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.8634\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.8580\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.8625\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.8544\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.8553\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8598\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.8562\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.8616\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.8616\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.8580\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8544\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.8544\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.8625\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.8553\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.8589\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.8616\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.8544\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.8634\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.8625\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.8643\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.8580\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.8562\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.8580\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8598\n",
            "Epoch 101/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.8616\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.0422 - accuracy: 0.6808 - val_loss: 1.5854 - val_accuracy: 0.4474\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6405 - accuracy: 0.8199 - val_loss: 2.1258 - val_accuracy: 0.4016\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5177 - accuracy: 0.8525 - val_loss: 1.4764 - val_accuracy: 0.5040\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4262 - accuracy: 0.8877 - val_loss: 1.2246 - val_accuracy: 0.6460\n",
            "Epoch 106/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.3509 - accuracy: 0.9077\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3537 - accuracy: 0.9076 - val_loss: 2.7649 - val_accuracy: 0.3504\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3832 - accuracy: 0.8995 - val_loss: 0.8086 - val_accuracy: 0.6945\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3101 - accuracy: 0.9205 - val_loss: 1.2969 - val_accuracy: 0.5885\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2675 - accuracy: 0.9388 - val_loss: 1.5345 - val_accuracy: 0.5436\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2401 - accuracy: 0.9440 - val_loss: 2.0556 - val_accuracy: 0.4385\n",
            "Epoch 111/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.2063 - accuracy: 0.9570\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2060 - accuracy: 0.9571 - val_loss: 0.7048 - val_accuracy: 0.7583\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2588 - accuracy: 0.9408 - val_loss: 1.9424 - val_accuracy: 0.4843\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2054 - accuracy: 0.9575 - val_loss: 4.2201 - val_accuracy: 0.1572\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1876 - accuracy: 0.9648 - val_loss: 0.6883 - val_accuracy: 0.7799\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1560 - accuracy: 0.9740 - val_loss: 0.9643 - val_accuracy: 0.6730\n",
            "Epoch 116/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.1356 - accuracy: 0.9777\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1358 - accuracy: 0.9779 - val_loss: 0.5735 - val_accuracy: 0.7969\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1791 - accuracy: 0.9638 - val_loss: 0.5986 - val_accuracy: 0.7987\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1402 - accuracy: 0.9781 - val_loss: 1.1408 - val_accuracy: 0.6712\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1202 - accuracy: 0.9844 - val_loss: 0.8626 - val_accuracy: 0.7134\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1040 - accuracy: 0.9912 - val_loss: 0.5589 - val_accuracy: 0.8149\n",
            "Epoch 121/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0870 - accuracy: 0.9927\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0874 - accuracy: 0.9925 - val_loss: 1.7089 - val_accuracy: 0.4672\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9697 - val_loss: 1.4569 - val_accuracy: 0.5921\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1150 - accuracy: 0.9844 - val_loss: 0.5155 - val_accuracy: 0.8410\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0981 - accuracy: 0.9876 - val_loss: 1.4498 - val_accuracy: 0.5508\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0855 - accuracy: 0.9934 - val_loss: 0.6842 - val_accuracy: 0.7529\n",
            "Epoch 126/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9966\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0734 - accuracy: 0.9964 - val_loss: 0.7258 - val_accuracy: 0.7853\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1283 - accuracy: 0.9831 - val_loss: 0.7949 - val_accuracy: 0.7143\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1054 - accuracy: 0.9869 - val_loss: 0.7981 - val_accuracy: 0.7314\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0836 - accuracy: 0.9934 - val_loss: 0.5059 - val_accuracy: 0.8329\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0691 - accuracy: 0.9944 - val_loss: 1.0405 - val_accuracy: 0.6864\n",
            "Epoch 131/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0585 - accuracy: 0.9991\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0585 - accuracy: 0.9991 - val_loss: 0.7825 - val_accuracy: 0.7673\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1375 - accuracy: 0.9765 - val_loss: 0.6916 - val_accuracy: 0.7727\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0840 - accuracy: 0.9939 - val_loss: 0.6093 - val_accuracy: 0.8122\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0670 - accuracy: 0.9966 - val_loss: 1.4429 - val_accuracy: 0.5427\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0608 - accuracy: 0.9986 - val_loss: 0.4513 - val_accuracy: 0.8535\n",
            "Epoch 136/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0502 - accuracy: 0.9988\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 0.0512 - accuracy: 0.9986 - val_loss: 0.5175 - val_accuracy: 0.8401\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1206 - accuracy: 0.9772 - val_loss: 0.6444 - val_accuracy: 0.7960\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0769 - accuracy: 0.9957 - val_loss: 0.4589 - val_accuracy: 0.8518\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0575 - accuracy: 0.9975 - val_loss: 0.4853 - val_accuracy: 0.8437\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0480 - accuracy: 0.9991 - val_loss: 0.5424 - val_accuracy: 0.8212\n",
            "Epoch 141/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0428 - accuracy: 0.9989\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0428 - accuracy: 0.9989 - val_loss: 0.4077 - val_accuracy: 0.8760\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1398 - accuracy: 0.9733 - val_loss: 2.6578 - val_accuracy: 0.3863\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.9905 - val_loss: 0.7568 - val_accuracy: 0.7682\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0729 - accuracy: 0.9930 - val_loss: 0.5103 - val_accuracy: 0.8383\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0607 - accuracy: 0.9957 - val_loss: 0.4665 - val_accuracy: 0.8571\n",
            "Epoch 146/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0470 - accuracy: 0.9995\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0471 - accuracy: 0.9995 - val_loss: 0.3900 - val_accuracy: 0.8760\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1452 - accuracy: 0.9727 - val_loss: 0.5077 - val_accuracy: 0.8311\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0906 - accuracy: 0.9898 - val_loss: 0.4884 - val_accuracy: 0.8383\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0660 - accuracy: 0.9971 - val_loss: 0.5853 - val_accuracy: 0.8239\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0585 - accuracy: 0.9986 - val_loss: 0.6053 - val_accuracy: 0.8113\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0499 - accuracy: 0.9977\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9977 - val_loss: 0.6787 - val_accuracy: 0.7781\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2057 - accuracy: 0.9460 - val_loss: 2.8362 - val_accuracy: 0.2794\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1167 - accuracy: 0.9794 - val_loss: 3.1120 - val_accuracy: 0.2480\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0836 - accuracy: 0.9923 - val_loss: 0.8538 - val_accuracy: 0.7332\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0620 - accuracy: 0.9964 - val_loss: 0.5364 - val_accuracy: 0.8392\n",
            "Epoch 156/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0600 - accuracy: 0.9971\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0597 - accuracy: 0.9973 - val_loss: 0.5845 - val_accuracy: 0.8113\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1924 - accuracy: 0.9501 - val_loss: 1.3044 - val_accuracy: 0.5957\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1153 - accuracy: 0.9781 - val_loss: 0.6604 - val_accuracy: 0.7754\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0833 - accuracy: 0.9930 - val_loss: 0.7974 - val_accuracy: 0.7448\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0634 - accuracy: 0.9975 - val_loss: 0.9001 - val_accuracy: 0.6981\n",
            "Epoch 161/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0565 - accuracy: 0.9966\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0565 - accuracy: 0.9966 - val_loss: 0.5696 - val_accuracy: 0.8131\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1766 - accuracy: 0.9571 - val_loss: 0.8972 - val_accuracy: 0.7314\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1108 - accuracy: 0.9819 - val_loss: 0.8233 - val_accuracy: 0.7610\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0836 - accuracy: 0.9925 - val_loss: 0.6476 - val_accuracy: 0.8032\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0666 - accuracy: 0.9968 - val_loss: 0.5070 - val_accuracy: 0.8239\n",
            "Epoch 166/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0557 - accuracy: 0.9976\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0572 - accuracy: 0.9975 - val_loss: 0.6195 - val_accuracy: 0.7996\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5498 - accuracy: 0.8312 - val_loss: 2.6804 - val_accuracy: 0.3890\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1837 - accuracy: 0.9614 - val_loss: 1.2870 - val_accuracy: 0.5948\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1368 - accuracy: 0.9751 - val_loss: 1.0897 - val_accuracy: 0.6586\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0974 - accuracy: 0.9885 - val_loss: 0.4804 - val_accuracy: 0.8473\n",
            "Epoch 171/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0779 - accuracy: 0.9940\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.9937 - val_loss: 0.8360 - val_accuracy: 0.7493\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2052 - accuracy: 0.9498 - val_loss: 1.3372 - val_accuracy: 0.6155\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1336 - accuracy: 0.9783 - val_loss: 0.5744 - val_accuracy: 0.8320\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1009 - accuracy: 0.9892 - val_loss: 0.9693 - val_accuracy: 0.6981\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0858 - accuracy: 0.9914 - val_loss: 1.8645 - val_accuracy: 0.5094\n",
            "Epoch 176/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0688 - accuracy: 0.9960\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0688 - accuracy: 0.9959 - val_loss: 0.5342 - val_accuracy: 0.8239\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1125 - accuracy: 0.9833 - val_loss: 0.6513 - val_accuracy: 0.7969\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0831 - accuracy: 0.9934 - val_loss: 0.9863 - val_accuracy: 0.7152\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0776 - accuracy: 0.9937 - val_loss: 0.4956 - val_accuracy: 0.8383\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0685 - accuracy: 0.9959 - val_loss: 0.8639 - val_accuracy: 0.7412\n",
            "Epoch 181/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0541 - accuracy: 0.9988\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0536 - accuracy: 0.9989 - val_loss: 0.4730 - val_accuracy: 0.8616\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0997 - accuracy: 0.9883 - val_loss: 0.9626 - val_accuracy: 0.7035\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0682 - accuracy: 0.9977 - val_loss: 0.4976 - val_accuracy: 0.8311\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 0.9959 - val_loss: 1.1235 - val_accuracy: 0.6289\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0502 - accuracy: 0.9995 - val_loss: 0.4620 - val_accuracy: 0.8518\n",
            "Epoch 186/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9995\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0424 - accuracy: 0.9995 - val_loss: 0.4869 - val_accuracy: 0.8302\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0890 - accuracy: 0.9923 - val_loss: 4.0442 - val_accuracy: 0.2695\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0758 - accuracy: 0.9950 - val_loss: 0.5057 - val_accuracy: 0.8410\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0551 - accuracy: 0.9982 - val_loss: 0.5161 - val_accuracy: 0.8356\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0456 - accuracy: 0.9993 - val_loss: 0.4894 - val_accuracy: 0.8580\n",
            "Epoch 191/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0409 - accuracy: 0.9998\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0408 - accuracy: 0.9998 - val_loss: 0.5090 - val_accuracy: 0.8419\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1745 - accuracy: 0.9690 - val_loss: 0.6349 - val_accuracy: 0.7960\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1094 - accuracy: 0.9889 - val_loss: 1.1224 - val_accuracy: 0.6361\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0947 - accuracy: 0.9889 - val_loss: 0.5046 - val_accuracy: 0.8500\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0720 - accuracy: 0.9964 - val_loss: 1.1080 - val_accuracy: 0.6631\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0689 - accuracy: 0.9944\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0689 - accuracy: 0.9944 - val_loss: 0.7560 - val_accuracy: 0.7960\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1428 - accuracy: 0.9761 - val_loss: 3.7346 - val_accuracy: 0.3369\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1156 - accuracy: 0.9810 - val_loss: 0.5158 - val_accuracy: 0.8437\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0817 - accuracy: 0.9934 - val_loss: 0.5431 - val_accuracy: 0.8473\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0613 - accuracy: 0.9980 - val_loss: 0.4842 - val_accuracy: 0.8473\n",
            "Epoch 201/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9993\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0518 - accuracy: 0.9993 - val_loss: 0.6182 - val_accuracy: 0.8212\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5713 - accuracy: 0.8177 - val_loss: 4.0226 - val_accuracy: 0.4016\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3271 - accuracy: 0.9110 - val_loss: 1.0510 - val_accuracy: 0.6891\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2447 - accuracy: 0.9370 - val_loss: 1.5115 - val_accuracy: 0.5660\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2044 - accuracy: 0.9510 - val_loss: 2.2358 - val_accuracy: 0.4043\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9627\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1706 - accuracy: 0.9627 - val_loss: 1.9734 - val_accuracy: 0.4376\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5161 - accuracy: 0.8324 - val_loss: 1.4298 - val_accuracy: 0.5580\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3253 - accuracy: 0.9035 - val_loss: 1.9518 - val_accuracy: 0.4124\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2552 - accuracy: 0.9288 - val_loss: 0.9591 - val_accuracy: 0.7242\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2221 - accuracy: 0.9422 - val_loss: 2.0492 - val_accuracy: 0.4034\n",
            "Epoch 211/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.1906 - accuracy: 0.9554\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1917 - accuracy: 0.9539 - val_loss: 2.3682 - val_accuracy: 0.3890\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2596 - accuracy: 0.9352 - val_loss: 0.9360 - val_accuracy: 0.7053\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2149 - accuracy: 0.9462 - val_loss: 0.6216 - val_accuracy: 0.7960\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1803 - accuracy: 0.9602 - val_loss: 0.7150 - val_accuracy: 0.7709\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1622 - accuracy: 0.9675 - val_loss: 0.8041 - val_accuracy: 0.7314\n",
            "Epoch 216/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.1345 - accuracy: 0.9769\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1352 - accuracy: 0.9761 - val_loss: 0.8490 - val_accuracy: 0.7233\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8418 - accuracy: 0.7327 - val_loss: 1.9970 - val_accuracy: 0.4367\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4772 - accuracy: 0.8507 - val_loss: 0.6799 - val_accuracy: 0.7745\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3645 - accuracy: 0.8882 - val_loss: 8.9034 - val_accuracy: 0.0898\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3181 - accuracy: 0.9024 - val_loss: 0.7333 - val_accuracy: 0.7565\n",
            "Epoch 221/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.2608 - accuracy: 0.9292\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2597 - accuracy: 0.9297 - val_loss: 1.3870 - val_accuracy: 0.6047\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3050 - accuracy: 0.9137 - val_loss: 1.9023 - val_accuracy: 0.4438\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2495 - accuracy: 0.9311 - val_loss: 0.6527 - val_accuracy: 0.7781\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2177 - accuracy: 0.9469 - val_loss: 0.5870 - val_accuracy: 0.8104\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2026 - accuracy: 0.9498 - val_loss: 0.7224 - val_accuracy: 0.7637\n",
            "Epoch 226/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.1673 - accuracy: 0.9656\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1693 - accuracy: 0.9652 - val_loss: 0.6562 - val_accuracy: 0.7709\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2763 - accuracy: 0.9288 - val_loss: 0.6947 - val_accuracy: 0.7610\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2097 - accuracy: 0.9550 - val_loss: 0.8190 - val_accuracy: 0.7341\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1918 - accuracy: 0.9614 - val_loss: 0.6183 - val_accuracy: 0.7898\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1619 - accuracy: 0.9677 - val_loss: 1.2489 - val_accuracy: 0.6478\n",
            "Epoch 231/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.1502 - accuracy: 0.9723\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1546 - accuracy: 0.9709 - val_loss: 0.5855 - val_accuracy: 0.7925\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2792 - accuracy: 0.9241 - val_loss: 0.8686 - val_accuracy: 0.7161\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2182 - accuracy: 0.9505 - val_loss: 0.7518 - val_accuracy: 0.7511\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.9654 - val_loss: 0.7417 - val_accuracy: 0.7475\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1697 - accuracy: 0.9675 - val_loss: 0.8583 - val_accuracy: 0.7305\n",
            "Epoch 236/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.1401 - accuracy: 0.9745\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1401 - accuracy: 0.9745 - val_loss: 0.8930 - val_accuracy: 0.7385\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3184 - accuracy: 0.9110 - val_loss: 0.6844 - val_accuracy: 0.7835\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2547 - accuracy: 0.9372 - val_loss: 1.1570 - val_accuracy: 0.6514\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2119 - accuracy: 0.9564 - val_loss: 0.7028 - val_accuracy: 0.7736\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1863 - accuracy: 0.9614 - val_loss: 0.7651 - val_accuracy: 0.7637\n",
            "Epoch 241/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.1726 - accuracy: 0.9692\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1725 - accuracy: 0.9693 - val_loss: 0.5038 - val_accuracy: 0.8329\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3245 - accuracy: 0.9126 - val_loss: 0.6711 - val_accuracy: 0.7799\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2591 - accuracy: 0.9394 - val_loss: 0.8967 - val_accuracy: 0.7035\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2203 - accuracy: 0.9530 - val_loss: 0.6099 - val_accuracy: 0.7916\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2066 - accuracy: 0.9555 - val_loss: 0.5667 - val_accuracy: 0.8104\n",
            "Epoch 246/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.1897 - accuracy: 0.9563\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1910 - accuracy: 0.9559 - val_loss: 0.6461 - val_accuracy: 0.7754\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3153 - accuracy: 0.9132 - val_loss: 1.3558 - val_accuracy: 0.5660\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2479 - accuracy: 0.9433 - val_loss: 0.6600 - val_accuracy: 0.7826\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2179 - accuracy: 0.9503 - val_loss: 0.5819 - val_accuracy: 0.8032\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.9582 - val_loss: 0.6622 - val_accuracy: 0.7673\n",
            "Epoch 251/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.1801 - accuracy: 0.9664\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1801 - accuracy: 0.9657 - val_loss: 0.6475 - val_accuracy: 0.7916\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.4753 - accuracy: 0.5088 - val_loss: 3.8987 - val_accuracy: 0.2300\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9437 - accuracy: 0.6837 - val_loss: 3.1342 - val_accuracy: 0.2615\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7934 - accuracy: 0.7316 - val_loss: 2.5981 - val_accuracy: 0.3908\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7126 - accuracy: 0.7639 - val_loss: 1.3241 - val_accuracy: 0.5535\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6521 - accuracy: 0.7865 - val_loss: 1.2855 - val_accuracy: 0.6074\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6066 - accuracy: 0.7971 - val_loss: 3.9289 - val_accuracy: 0.1473\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5591 - accuracy: 0.8150 - val_loss: 0.8908 - val_accuracy: 0.6990\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5381 - accuracy: 0.8192 - val_loss: 0.7507 - val_accuracy: 0.7475\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5048 - accuracy: 0.8389 - val_loss: 1.0895 - val_accuracy: 0.6424\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4669 - accuracy: 0.8477 - val_loss: 0.7756 - val_accuracy: 0.7430\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4377 - accuracy: 0.8543 - val_loss: 0.7965 - val_accuracy: 0.7394\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4285 - accuracy: 0.8613 - val_loss: 0.9174 - val_accuracy: 0.6864\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3983 - accuracy: 0.8755 - val_loss: 0.9971 - val_accuracy: 0.7026\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3845 - accuracy: 0.8809 - val_loss: 0.8918 - val_accuracy: 0.6927\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3837 - accuracy: 0.8800 - val_loss: 0.7949 - val_accuracy: 0.7287\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3479 - accuracy: 0.8967 - val_loss: 1.0985 - val_accuracy: 0.6460\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3306 - accuracy: 0.8999 - val_loss: 1.0609 - val_accuracy: 0.6783\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3265 - accuracy: 0.8983 - val_loss: 0.9090 - val_accuracy: 0.6882\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2964 - accuracy: 0.9137 - val_loss: 0.7512 - val_accuracy: 0.7601\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2885 - accuracy: 0.9128 - val_loss: 1.2499 - val_accuracy: 0.6460\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2741 - accuracy: 0.9202 - val_loss: 1.1739 - val_accuracy: 0.6757\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2695 - accuracy: 0.9202 - val_loss: 1.4175 - val_accuracy: 0.6047\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2630 - accuracy: 0.9254 - val_loss: 1.2663 - val_accuracy: 0.6307\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2447 - accuracy: 0.9295 - val_loss: 1.5500 - val_accuracy: 0.5355\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2359 - accuracy: 0.9311 - val_loss: 2.7740 - val_accuracy: 0.4214\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2265 - accuracy: 0.9417 - val_loss: 0.7421 - val_accuracy: 0.7718\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2068 - accuracy: 0.9485 - val_loss: 0.7555 - val_accuracy: 0.7736\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2154 - accuracy: 0.9419 - val_loss: 0.7105 - val_accuracy: 0.7718\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2039 - accuracy: 0.9480 - val_loss: 1.2588 - val_accuracy: 0.6388\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1946 - accuracy: 0.9503 - val_loss: 0.8262 - val_accuracy: 0.7493\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.9555 - val_loss: 0.7180 - val_accuracy: 0.7772\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1690 - accuracy: 0.9602 - val_loss: 1.4386 - val_accuracy: 0.6217\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1826 - accuracy: 0.9494 - val_loss: 3.0231 - val_accuracy: 0.3854\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1885 - accuracy: 0.9498 - val_loss: 0.8899 - val_accuracy: 0.7484\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1695 - accuracy: 0.9571 - val_loss: 0.9207 - val_accuracy: 0.7080\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1540 - accuracy: 0.9641 - val_loss: 0.7735 - val_accuracy: 0.7601\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1408 - accuracy: 0.9677 - val_loss: 1.0143 - val_accuracy: 0.6801\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1192 - accuracy: 0.9767 - val_loss: 1.4466 - val_accuracy: 0.6173\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1378 - accuracy: 0.9715 - val_loss: 1.4358 - val_accuracy: 0.5957\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1292 - accuracy: 0.9729 - val_loss: 0.9341 - val_accuracy: 0.7152\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1397 - accuracy: 0.9645 - val_loss: 1.9854 - val_accuracy: 0.5229\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1447 - accuracy: 0.9650 - val_loss: 0.8241 - val_accuracy: 0.7403\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1207 - accuracy: 0.9747 - val_loss: 0.9937 - val_accuracy: 0.7089\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1203 - accuracy: 0.9738 - val_loss: 0.7931 - val_accuracy: 0.7628\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1042 - accuracy: 0.9790 - val_loss: 1.4171 - val_accuracy: 0.6397\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1051 - accuracy: 0.9812 - val_loss: 0.9484 - val_accuracy: 0.7466\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0973 - accuracy: 0.9835 - val_loss: 0.8977 - val_accuracy: 0.7547\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0952 - accuracy: 0.9844 - val_loss: 0.8857 - val_accuracy: 0.7502\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0835 - accuracy: 0.9860 - val_loss: 0.8546 - val_accuracy: 0.7592\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0890 - accuracy: 0.9869 - val_loss: 0.9906 - val_accuracy: 0.7107\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0945 - accuracy: 0.9844 - val_loss: 0.9024 - val_accuracy: 0.7314\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0772 - accuracy: 0.9880 - val_loss: 0.9200 - val_accuracy: 0.7556\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0902 - accuracy: 0.9815 - val_loss: 0.8345 - val_accuracy: 0.7583\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0766 - accuracy: 0.9873 - val_loss: 0.9991 - val_accuracy: 0.7080\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0712 - accuracy: 0.9896 - val_loss: 1.0003 - val_accuracy: 0.7107\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0662 - accuracy: 0.9910 - val_loss: 1.0104 - val_accuracy: 0.7251\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0652 - accuracy: 0.9928 - val_loss: 1.0315 - val_accuracy: 0.7314\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0541 - accuracy: 0.9937 - val_loss: 0.8965 - val_accuracy: 0.7412\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0654 - accuracy: 0.9916 - val_loss: 1.1331 - val_accuracy: 0.6783\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0689 - accuracy: 0.9883 - val_loss: 0.9508 - val_accuracy: 0.7484\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0546 - accuracy: 0.9944 - val_loss: 0.9563 - val_accuracy: 0.7358\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0792 - accuracy: 0.9844 - val_loss: 0.9193 - val_accuracy: 0.7547\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0613 - accuracy: 0.9907 - val_loss: 0.8182 - val_accuracy: 0.7646\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0596 - accuracy: 0.9916 - val_loss: 1.0299 - val_accuracy: 0.6954\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0631 - accuracy: 0.9885 - val_loss: 0.8422 - val_accuracy: 0.7610\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0468 - accuracy: 0.9966 - val_loss: 0.8944 - val_accuracy: 0.7619\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0754 - accuracy: 0.9849 - val_loss: 0.8461 - val_accuracy: 0.7682\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0533 - accuracy: 0.9925 - val_loss: 0.8556 - val_accuracy: 0.7709\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0406 - accuracy: 0.9980 - val_loss: 0.9057 - val_accuracy: 0.7619\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0378 - accuracy: 0.9973 - val_loss: 0.8215 - val_accuracy: 0.7709\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0362 - accuracy: 0.9971 - val_loss: 0.8797 - val_accuracy: 0.7682\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0415 - accuracy: 0.9959 - val_loss: 0.9469 - val_accuracy: 0.7673\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0386 - accuracy: 0.9968 - val_loss: 0.8365 - val_accuracy: 0.7700\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0327 - accuracy: 0.9980 - val_loss: 0.8383 - val_accuracy: 0.7745\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0347 - accuracy: 0.9962 - val_loss: 0.8884 - val_accuracy: 0.7547\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0393 - accuracy: 0.9957 - val_loss: 0.9972 - val_accuracy: 0.7341\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0379 - accuracy: 0.9955 - val_loss: 1.0189 - val_accuracy: 0.7260\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0332 - accuracy: 0.9975 - val_loss: 0.9314 - val_accuracy: 0.7556\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0317 - accuracy: 0.9980 - val_loss: 0.9211 - val_accuracy: 0.7637\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0246 - accuracy: 0.9993 - val_loss: 1.2279 - val_accuracy: 0.6855\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9980 - val_loss: 0.8991 - val_accuracy: 0.7547\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0248 - accuracy: 0.9986 - val_loss: 0.8606 - val_accuracy: 0.7781\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0227 - accuracy: 0.9993 - val_loss: 0.8949 - val_accuracy: 0.7655\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0234 - accuracy: 0.9989 - val_loss: 0.9112 - val_accuracy: 0.7682\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0291 - accuracy: 0.9980 - val_loss: 0.8742 - val_accuracy: 0.7646\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0590 - accuracy: 0.9876 - val_loss: 1.7585 - val_accuracy: 0.6074\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0359 - accuracy: 0.9959 - val_loss: 0.8868 - val_accuracy: 0.7574\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0321 - accuracy: 0.9953 - val_loss: 1.2669 - val_accuracy: 0.6828\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0369 - accuracy: 0.9953 - val_loss: 0.9179 - val_accuracy: 0.7637\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0244 - accuracy: 0.9991 - val_loss: 0.8799 - val_accuracy: 0.7691\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0184 - accuracy: 0.9993 - val_loss: 0.8628 - val_accuracy: 0.7826\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0219 - accuracy: 0.9993 - val_loss: 0.8713 - val_accuracy: 0.7835\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0290 - accuracy: 0.9966 - val_loss: 0.9006 - val_accuracy: 0.7700\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0231 - accuracy: 0.9991 - val_loss: 1.0286 - val_accuracy: 0.7376\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0269 - accuracy: 0.9966 - val_loss: 0.9931 - val_accuracy: 0.7412\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 0.9975 - val_loss: 0.9319 - val_accuracy: 0.7565\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0374 - accuracy: 0.9930 - val_loss: 0.9205 - val_accuracy: 0.7709\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0258 - accuracy: 0.9982 - val_loss: 0.8850 - val_accuracy: 0.7808\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 0.9993 - val_loss: 0.9140 - val_accuracy: 0.7718\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0219 - accuracy: 0.9977 - val_loss: 0.9138 - val_accuracy: 0.7736\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0237 - accuracy: 0.9975 - val_loss: 1.0029 - val_accuracy: 0.7511\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0202 - accuracy: 0.9989 - val_loss: 0.9550 - val_accuracy: 0.7529\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0228 - accuracy: 0.9973 - val_loss: 1.0388 - val_accuracy: 0.7412\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0388 - accuracy: 0.9944 - val_loss: 1.2745 - val_accuracy: 0.7116\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0328 - accuracy: 0.9968 - val_loss: 0.9679 - val_accuracy: 0.7529\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0221 - accuracy: 0.9984 - val_loss: 0.9392 - val_accuracy: 0.7592\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0179 - accuracy: 0.9993 - val_loss: 0.9091 - val_accuracy: 0.7709\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0703 - accuracy: 0.9824 - val_loss: 0.9648 - val_accuracy: 0.7601\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0328 - accuracy: 0.9962 - val_loss: 0.9184 - val_accuracy: 0.7727\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0263 - accuracy: 0.9971 - val_loss: 0.9551 - val_accuracy: 0.7637\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0219 - accuracy: 0.9986 - val_loss: 0.8915 - val_accuracy: 0.7718\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0160 - accuracy: 0.9993 - val_loss: 0.8756 - val_accuracy: 0.7754\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0193 - accuracy: 0.9984 - val_loss: 0.9246 - val_accuracy: 0.7781\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0162 - accuracy: 0.9995 - val_loss: 0.9253 - val_accuracy: 0.7709\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0178 - accuracy: 0.9989 - val_loss: 0.9290 - val_accuracy: 0.7583\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0203 - accuracy: 0.9982 - val_loss: 0.9430 - val_accuracy: 0.7682\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0145 - accuracy: 0.9998 - val_loss: 0.9214 - val_accuracy: 0.7745\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0180 - accuracy: 0.9982 - val_loss: 0.8868 - val_accuracy: 0.7853\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0171 - accuracy: 0.9989 - val_loss: 0.9698 - val_accuracy: 0.7556\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 0.9995 - val_loss: 1.1920 - val_accuracy: 0.7206\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0165 - accuracy: 0.9986 - val_loss: 0.9282 - val_accuracy: 0.7781\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.9654 - val_accuracy: 0.7682\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.9238 - val_accuracy: 0.7790\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0123 - accuracy: 0.9993 - val_loss: 0.9411 - val_accuracy: 0.7718\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0122 - accuracy: 0.9995 - val_loss: 1.1878 - val_accuracy: 0.7188\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0393 - accuracy: 0.9925 - val_loss: 0.9881 - val_accuracy: 0.7646\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 0.9975 - val_loss: 1.3284 - val_accuracy: 0.6667\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0227 - accuracy: 0.9968 - val_loss: 0.9348 - val_accuracy: 0.7772\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.9446 - val_accuracy: 0.7637\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0152 - accuracy: 0.9982 - val_loss: 1.2040 - val_accuracy: 0.7358\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0145 - accuracy: 0.9995 - val_loss: 1.0071 - val_accuracy: 0.7736\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0125 - accuracy: 0.9989 - val_loss: 0.9173 - val_accuracy: 0.7754\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 0.9993 - val_loss: 0.9250 - val_accuracy: 0.7781\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0114 - accuracy: 0.9993 - val_loss: 0.9220 - val_accuracy: 0.7781\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.9492 - val_accuracy: 0.7700\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.9627 - val_accuracy: 0.7745\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0132 - accuracy: 0.9991 - val_loss: 0.9762 - val_accuracy: 0.7745\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 0.9998 - val_loss: 0.9395 - val_accuracy: 0.7772\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.7763\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0103 - accuracy: 0.9998 - val_loss: 0.9647 - val_accuracy: 0.7781\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0262 - accuracy: 0.9948 - val_loss: 0.9494 - val_accuracy: 0.7763\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0131 - accuracy: 0.9991 - val_loss: 0.9534 - val_accuracy: 0.7736\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 0.9995 - val_loss: 1.3068 - val_accuracy: 0.6945\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 1.4420 - val_accuracy: 0.6586\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.9950 - val_accuracy: 0.7682\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0098 - accuracy: 0.9998 - val_loss: 0.9322 - val_accuracy: 0.7781\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 0.9998 - val_loss: 0.9822 - val_accuracy: 0.7799\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 0.9841 - val_accuracy: 0.7664\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0127 - accuracy: 0.9991 - val_loss: 0.9379 - val_accuracy: 0.7880\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9404 - val_accuracy: 0.7880\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.9526 - val_accuracy: 0.7835\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.9623 - val_accuracy: 0.7736\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0134 - accuracy: 0.9982 - val_loss: 1.1467 - val_accuracy: 0.7350\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0112 - accuracy: 0.9993 - val_loss: 0.9532 - val_accuracy: 0.7754\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.9740 - val_accuracy: 0.7826\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0100 - accuracy: 0.9995 - val_loss: 0.9687 - val_accuracy: 0.7826\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9741 - val_accuracy: 0.7745\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 0.9993 - val_loss: 0.9872 - val_accuracy: 0.7727\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.9751 - val_accuracy: 0.7790\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0139 - accuracy: 0.9984 - val_loss: 0.9626 - val_accuracy: 0.7889\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.9632 - val_accuracy: 0.7781\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 1.0234 - val_accuracy: 0.7709\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0206 - accuracy: 0.9957 - val_loss: 0.9912 - val_accuracy: 0.7718\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 1.1808 - val_accuracy: 0.7242\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0168 - accuracy: 0.9973 - val_loss: 0.9605 - val_accuracy: 0.7727\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 0.9995 - val_loss: 1.0018 - val_accuracy: 0.7772\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 0.9993 - val_loss: 1.0902 - val_accuracy: 0.7439\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.9838 - val_accuracy: 0.7682\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.1580 - val_accuracy: 0.7394\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.0352 - val_accuracy: 0.7691\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0093 - accuracy: 0.9995 - val_loss: 1.0012 - val_accuracy: 0.7754\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.1521 - val_accuracy: 0.7547\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 0.9998 - val_loss: 0.9485 - val_accuracy: 0.7844\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.9528 - val_accuracy: 0.7853\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 0.9870 - val_accuracy: 0.7871\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 0.9980 - val_accuracy: 0.7718\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.9998 - val_accuracy: 0.7673\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.7574\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 0.9980 - val_loss: 1.0233 - val_accuracy: 0.7727\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.7763\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0083 - accuracy: 0.9995 - val_loss: 1.0664 - val_accuracy: 0.7637\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 0.9998 - val_loss: 1.0243 - val_accuracy: 0.7745\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 0.9998 - val_loss: 1.0049 - val_accuracy: 0.7673\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0081 - accuracy: 0.9998 - val_loss: 0.9847 - val_accuracy: 0.7799\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 0.9998 - val_loss: 0.9873 - val_accuracy: 0.7808\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.0100 - val_accuracy: 0.7772\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0135 - accuracy: 0.9982 - val_loss: 1.0359 - val_accuracy: 0.7664\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 0.9993 - val_loss: 12.1730 - val_accuracy: 0.3270\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1191 - accuracy: 0.9672 - val_loss: 1.2647 - val_accuracy: 0.7062\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0241 - accuracy: 0.9964 - val_loss: 0.9381 - val_accuracy: 0.7835\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0118 - accuracy: 0.9991 - val_loss: 0.9990 - val_accuracy: 0.7754\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0101 - accuracy: 0.9995 - val_loss: 0.9146 - val_accuracy: 0.7781\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 0.7772\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.9667 - val_accuracy: 0.7745\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0090 - accuracy: 0.9998 - val_loss: 0.9804 - val_accuracy: 0.7781\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.9617 - val_accuracy: 0.7736\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0064 - accuracy: 0.9998 - val_loss: 0.9871 - val_accuracy: 0.7799\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.9877 - val_accuracy: 0.7835\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.9987 - val_accuracy: 0.7727\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0096 - accuracy: 0.9989 - val_loss: 2.1502 - val_accuracy: 0.6128\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0347 - accuracy: 0.9932 - val_loss: 1.0626 - val_accuracy: 0.7718\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0111 - accuracy: 0.9995 - val_loss: 1.0143 - val_accuracy: 0.7646\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 0.9629 - val_accuracy: 0.7736\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 0.9903 - val_accuracy: 0.7718\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.9682 - val_accuracy: 0.7772\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 0.9995 - val_loss: 1.0247 - val_accuracy: 0.7709\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 0.9998 - val_loss: 0.9982 - val_accuracy: 0.7655\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.9638 - val_accuracy: 0.7853\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 0.9998 - val_loss: 1.0382 - val_accuracy: 0.7790\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0060 - val_accuracy: 0.7700\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0076 - accuracy: 0.9993 - val_loss: 1.3815 - val_accuracy: 0.7206\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 0.9982 - val_loss: 0.9976 - val_accuracy: 0.7781\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 0.9945 - val_accuracy: 0.7763\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 0.9998 - val_loss: 0.9960 - val_accuracy: 0.7808\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 1.0052 - val_accuracy: 0.7763\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 0.9993 - val_loss: 1.0442 - val_accuracy: 0.7673\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 0.9998 - val_loss: 1.0151 - val_accuracy: 0.7763\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.0293 - val_accuracy: 0.7754\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.0200 - val_accuracy: 0.7835\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 0.9993 - val_loss: 1.0003 - val_accuracy: 0.7799\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0071 - accuracy: 0.9998 - val_loss: 1.0053 - val_accuracy: 0.7736\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.9811 - val_accuracy: 0.7826\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 1.0289 - val_accuracy: 0.7727\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.0089 - val_accuracy: 0.7781\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.9974 - val_accuracy: 0.7763\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 0.9993 - val_loss: 1.0629 - val_accuracy: 0.7682\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 0.9991 - val_loss: 1.0124 - val_accuracy: 0.7727\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 0.9995 - val_loss: 1.5422 - val_accuracy: 0.6963\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0108 - accuracy: 0.9986 - val_loss: 1.0263 - val_accuracy: 0.7664\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.9843 - val_accuracy: 0.7781\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.0050 - val_accuracy: 0.7781\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 0.7826\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0576 - val_accuracy: 0.7709\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9998 - val_loss: 1.0910 - val_accuracy: 0.7556\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.0271 - val_accuracy: 0.7781\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 1.0078 - val_accuracy: 0.7844\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.1357 - val_accuracy: 0.7565\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 0.9998 - val_loss: 1.0293 - val_accuracy: 0.7709\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0365 - val_accuracy: 0.7736\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0314 - val_accuracy: 0.7844\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0427 - val_accuracy: 0.7781\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0593 - val_accuracy: 0.7772\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.0750 - val_accuracy: 0.7619\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.7826\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.0386 - val_accuracy: 0.7799\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 0.9995 - val_loss: 3.8370 - val_accuracy: 0.5076\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 0.9975 - val_loss: 1.0351 - val_accuracy: 0.7754\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 0.9995 - val_loss: 1.0328 - val_accuracy: 0.7763\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.0301 - val_accuracy: 0.7781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGHig-9o07fP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0c057bb7-169a-4970-8cc8-af47f3500366"
      },
      "source": [
        "pruningcallback_3=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.90,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_3=model_to_prune_3.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_3],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 1.5791 - accuracy: 0.4745 - val_loss: 2.9591 - val_accuracy: 0.0458\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9536 - accuracy: 0.6943 - val_loss: 3.8973 - val_accuracy: 0.0710\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7044 - accuracy: 0.7964 - val_loss: 5.0775 - val_accuracy: 0.1366\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5589 - accuracy: 0.8477 - val_loss: 6.4277 - val_accuracy: 0.1384\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4551 - accuracy: 0.8859 - val_loss: 5.3523 - val_accuracy: 0.1707\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3659 - accuracy: 0.9166 - val_loss: 3.6135 - val_accuracy: 0.3172\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3057 - accuracy: 0.9361 - val_loss: 1.8500 - val_accuracy: 0.4295\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2570 - accuracy: 0.9512 - val_loss: 1.1086 - val_accuracy: 0.6128\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2147 - accuracy: 0.9616 - val_loss: 0.6094 - val_accuracy: 0.8158\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1857 - accuracy: 0.9706 - val_loss: 0.5686 - val_accuracy: 0.8212\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1586 - accuracy: 0.9815 - val_loss: 0.6327 - val_accuracy: 0.7942\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1330 - accuracy: 0.9846 - val_loss: 0.7099 - val_accuracy: 0.7484\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1198 - accuracy: 0.9883 - val_loss: 1.9752 - val_accuracy: 0.4807\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1003 - accuracy: 0.9923 - val_loss: 0.5332 - val_accuracy: 0.8356\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0840 - accuracy: 0.9968 - val_loss: 0.5415 - val_accuracy: 0.8212\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0787 - accuracy: 0.9953 - val_loss: 0.6405 - val_accuracy: 0.7799\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0670 - accuracy: 0.9968 - val_loss: 0.5153 - val_accuracy: 0.8329\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0598 - accuracy: 0.9973 - val_loss: 0.5488 - val_accuracy: 0.8185\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0542 - accuracy: 0.9986 - val_loss: 0.5501 - val_accuracy: 0.8185\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8356\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0470 - accuracy: 0.9993 - val_loss: 0.4612 - val_accuracy: 0.8491\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0397 - accuracy: 0.9998 - val_loss: 0.4738 - val_accuracy: 0.8500\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0380 - accuracy: 0.9995 - val_loss: 0.4802 - val_accuracy: 0.8455\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0363 - accuracy: 0.9995 - val_loss: 0.5980 - val_accuracy: 0.8059\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.8320\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0300 - accuracy: 0.9998 - val_loss: 0.5005 - val_accuracy: 0.8410\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0265 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.8428\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.8446\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.8329\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 0.6089 - val_accuracy: 0.8140\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0211 - accuracy: 0.9998 - val_loss: 0.5566 - val_accuracy: 0.8248\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.8518\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.8374\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0187 - accuracy: 0.9998 - val_loss: 0.8462 - val_accuracy: 0.7314\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0181 - accuracy: 0.9998 - val_loss: 0.4756 - val_accuracy: 0.8544\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.8518\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.9546 - val_accuracy: 0.7053\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.8634\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.8580\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.8464\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.8607\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8697\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5582 - val_accuracy: 0.8176\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.8598\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8473\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.8661\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.8518\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.8544\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8598\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.8598\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.8706\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.8509\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.8643\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.5892 - val_accuracy: 0.8212\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.8742\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.8652\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.8464\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8670\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.8661\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.8607\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.8697\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.8598\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.8679\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.8697\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.8625\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.8643\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8706\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.8688\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.8733\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.8661\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.8715\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.8643\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.8661\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.8625\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.8670\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.8724\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.8760\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.8724\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.8706\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.8706\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.8625\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8679\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8715\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8733\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.8733\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.8634\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.8688\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.8751\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8679\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.8724\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.8697\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.8706\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.8679\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.8742\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.8742\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8760\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.8787\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.8706\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.8688\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.8652\n",
            "Epoch 101/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.8715\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.0301 - accuracy: 0.6911 - val_loss: 2.2010 - val_accuracy: 0.3998\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6317 - accuracy: 0.8249 - val_loss: 1.4723 - val_accuracy: 0.4942\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5049 - accuracy: 0.8622 - val_loss: 1.4269 - val_accuracy: 0.5714\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4185 - accuracy: 0.8897 - val_loss: 1.2188 - val_accuracy: 0.5849\n",
            "Epoch 106/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.3372 - accuracy: 0.9176\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3425 - accuracy: 0.9160 - val_loss: 2.2927 - val_accuracy: 0.4654\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3478 - accuracy: 0.9162 - val_loss: 0.8311 - val_accuracy: 0.7188\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2873 - accuracy: 0.9324 - val_loss: 1.9355 - val_accuracy: 0.4636\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2443 - accuracy: 0.9492 - val_loss: 0.8737 - val_accuracy: 0.7053\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2237 - accuracy: 0.9541 - val_loss: 0.9930 - val_accuracy: 0.6891\n",
            "Epoch 111/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.1951 - accuracy: 0.9630\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1952 - accuracy: 0.9629 - val_loss: 0.7697 - val_accuracy: 0.7107\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2297 - accuracy: 0.9467 - val_loss: 0.5778 - val_accuracy: 0.8059\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1856 - accuracy: 0.9627 - val_loss: 0.7514 - val_accuracy: 0.7619\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1591 - accuracy: 0.9711 - val_loss: 0.7151 - val_accuracy: 0.7610\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1386 - accuracy: 0.9808 - val_loss: 0.5437 - val_accuracy: 0.8302\n",
            "Epoch 116/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.1181 - accuracy: 0.9834\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1187 - accuracy: 0.9831 - val_loss: 0.8147 - val_accuracy: 0.7457\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1895 - accuracy: 0.9672 - val_loss: 0.5564 - val_accuracy: 0.8212\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1371 - accuracy: 0.9855 - val_loss: 0.6248 - val_accuracy: 0.7853\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1178 - accuracy: 0.9887 - val_loss: 0.9163 - val_accuracy: 0.6846\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1126 - accuracy: 0.9889 - val_loss: 0.8143 - val_accuracy: 0.7592\n",
            "Epoch 121/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9948\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0857 - accuracy: 0.9946 - val_loss: 0.5882 - val_accuracy: 0.7907\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1483 - accuracy: 0.9774 - val_loss: 0.8784 - val_accuracy: 0.7323\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1096 - accuracy: 0.9887 - val_loss: 0.5997 - val_accuracy: 0.7709\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0905 - accuracy: 0.9923 - val_loss: 0.7370 - val_accuracy: 0.7691\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0788 - accuracy: 0.9962 - val_loss: 0.6982 - val_accuracy: 0.7475\n",
            "Epoch 126/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0686 - accuracy: 0.9971\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0690 - accuracy: 0.9973 - val_loss: 0.5897 - val_accuracy: 0.8086\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1144 - accuracy: 0.9885 - val_loss: 0.5484 - val_accuracy: 0.8212\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0995 - accuracy: 0.9910 - val_loss: 0.6050 - val_accuracy: 0.8032\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0784 - accuracy: 0.9957 - val_loss: 0.4617 - val_accuracy: 0.8491\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0667 - accuracy: 0.9982 - val_loss: 0.5162 - val_accuracy: 0.8284\n",
            "Epoch 131/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9989\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0552 - accuracy: 0.9989 - val_loss: 0.4391 - val_accuracy: 0.8643\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1819 - accuracy: 0.9629 - val_loss: 1.3414 - val_accuracy: 0.5508\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1128 - accuracy: 0.9846 - val_loss: 0.5483 - val_accuracy: 0.8149\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0860 - accuracy: 0.9950 - val_loss: 1.2398 - val_accuracy: 0.6199\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0733 - accuracy: 0.9957 - val_loss: 0.6839 - val_accuracy: 0.7772\n",
            "Epoch 136/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0617 - accuracy: 0.9973\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 0.9968 - val_loss: 0.5674 - val_accuracy: 0.8230\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1337 - accuracy: 0.9785 - val_loss: 0.5629 - val_accuracy: 0.7925\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0954 - accuracy: 0.9907 - val_loss: 0.8046 - val_accuracy: 0.7502\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0693 - accuracy: 0.9964 - val_loss: 0.5220 - val_accuracy: 0.8527\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0638 - accuracy: 0.9975 - val_loss: 0.4354 - val_accuracy: 0.8715\n",
            "Epoch 141/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0500 - accuracy: 0.9991\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0500 - accuracy: 0.9991 - val_loss: 0.4991 - val_accuracy: 0.8401\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1310 - accuracy: 0.9822 - val_loss: 1.2431 - val_accuracy: 0.5615\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0998 - accuracy: 0.9901 - val_loss: 0.5860 - val_accuracy: 0.8086\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0735 - accuracy: 0.9959 - val_loss: 0.4478 - val_accuracy: 0.8751\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0616 - accuracy: 0.9977 - val_loss: 0.5296 - val_accuracy: 0.8293\n",
            "Epoch 146/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9975\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0545 - accuracy: 0.9973 - val_loss: 1.3353 - val_accuracy: 0.6586\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1593 - accuracy: 0.9693 - val_loss: 0.7251 - val_accuracy: 0.7655\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.9932 - val_loss: 0.5521 - val_accuracy: 0.8293\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0747 - accuracy: 0.9939 - val_loss: 0.5967 - val_accuracy: 0.8320\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0637 - accuracy: 0.9975 - val_loss: 0.5929 - val_accuracy: 0.8275\n",
            "Epoch 151/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0506 - accuracy: 0.9991\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0506 - accuracy: 0.9991 - val_loss: 1.4707 - val_accuracy: 0.5651\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1871 - accuracy: 0.9605 - val_loss: 0.6259 - val_accuracy: 0.7871\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1143 - accuracy: 0.9880 - val_loss: 2.1782 - val_accuracy: 0.4474\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0991 - accuracy: 0.9892 - val_loss: 0.8083 - val_accuracy: 0.7341\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0743 - accuracy: 0.9944 - val_loss: 0.5388 - val_accuracy: 0.8464\n",
            "Epoch 156/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0676 - accuracy: 0.9964\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0676 - accuracy: 0.9964 - val_loss: 0.5653 - val_accuracy: 0.8311\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1854 - accuracy: 0.9611 - val_loss: 1.2327 - val_accuracy: 0.6586\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1018 - accuracy: 0.9907 - val_loss: 0.5418 - val_accuracy: 0.8392\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0801 - accuracy: 0.9941 - val_loss: 0.8878 - val_accuracy: 0.7412\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0656 - accuracy: 0.9975 - val_loss: 0.5136 - val_accuracy: 0.8410\n",
            "Epoch 161/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.0557 - accuracy: 0.9982\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0558 - accuracy: 0.9982 - val_loss: 0.4604 - val_accuracy: 0.8652\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2291 - accuracy: 0.9408 - val_loss: 1.4578 - val_accuracy: 0.5714\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1078 - accuracy: 0.9860 - val_loss: 0.5951 - val_accuracy: 0.8158\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0808 - accuracy: 0.9937 - val_loss: 0.8846 - val_accuracy: 0.7341\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0671 - accuracy: 0.9962 - val_loss: 0.5472 - val_accuracy: 0.8320\n",
            "Epoch 166/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0576 - accuracy: 0.9980\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0576 - accuracy: 0.9980 - val_loss: 0.7193 - val_accuracy: 0.7637\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4426 - accuracy: 0.8617 - val_loss: 4.9753 - val_accuracy: 0.2938\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1753 - accuracy: 0.9643 - val_loss: 0.5474 - val_accuracy: 0.8257\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1255 - accuracy: 0.9783 - val_loss: 1.0962 - val_accuracy: 0.6334\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0948 - accuracy: 0.9903 - val_loss: 0.9418 - val_accuracy: 0.6891\n",
            "Epoch 171/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.9936\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0792 - accuracy: 0.9937 - val_loss: 0.4838 - val_accuracy: 0.8482\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1654 - accuracy: 0.9709 - val_loss: 2.2653 - val_accuracy: 0.4367\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1056 - accuracy: 0.9896 - val_loss: 0.5266 - val_accuracy: 0.8473\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0829 - accuracy: 0.9932 - val_loss: 0.5757 - val_accuracy: 0.8221\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0731 - accuracy: 0.9953 - val_loss: 1.4318 - val_accuracy: 0.6334\n",
            "Epoch 176/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0627 - accuracy: 0.9976\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 0.9977 - val_loss: 0.5064 - val_accuracy: 0.8437\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3507 - accuracy: 0.9017 - val_loss: 3.5942 - val_accuracy: 0.2183\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1771 - accuracy: 0.9657 - val_loss: 1.3005 - val_accuracy: 0.6011\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1385 - accuracy: 0.9772 - val_loss: 0.7138 - val_accuracy: 0.7969\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1033 - accuracy: 0.9901 - val_loss: 0.6466 - val_accuracy: 0.7987\n",
            "Epoch 181/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0823 - accuracy: 0.9961\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0825 - accuracy: 0.9957 - val_loss: 0.5257 - val_accuracy: 0.8293\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6534 - accuracy: 0.7912 - val_loss: 1.2854 - val_accuracy: 0.5714\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2901 - accuracy: 0.9284 - val_loss: 1.0528 - val_accuracy: 0.6622\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2241 - accuracy: 0.9519 - val_loss: 2.9079 - val_accuracy: 0.3711\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1911 - accuracy: 0.9593 - val_loss: 0.7387 - val_accuracy: 0.7610\n",
            "Epoch 186/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.1366 - accuracy: 0.9816\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1365 - accuracy: 0.9815 - val_loss: 0.5154 - val_accuracy: 0.8293\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2648 - accuracy: 0.9399 - val_loss: 0.6825 - val_accuracy: 0.7880\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1943 - accuracy: 0.9715 - val_loss: 1.0544 - val_accuracy: 0.6595\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1658 - accuracy: 0.9747 - val_loss: 0.6813 - val_accuracy: 0.7978\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9844 - val_loss: 0.9072 - val_accuracy: 0.7008\n",
            "Epoch 191/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.1158 - accuracy: 0.9854\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1154 - accuracy: 0.9858 - val_loss: 0.8085 - val_accuracy: 0.7323\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1748 - accuracy: 0.9709 - val_loss: 1.0406 - val_accuracy: 0.6819\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1273 - accuracy: 0.9880 - val_loss: 0.5668 - val_accuracy: 0.8212\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1109 - accuracy: 0.9883 - val_loss: 0.6044 - val_accuracy: 0.7969\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0898 - accuracy: 0.9941 - val_loss: 0.6711 - val_accuracy: 0.7960\n",
            "Epoch 196/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0864 - accuracy: 0.9919\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0863 - accuracy: 0.9921 - val_loss: 0.6302 - val_accuracy: 0.8149\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1704 - accuracy: 0.9715 - val_loss: 0.8111 - val_accuracy: 0.7421\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1336 - accuracy: 0.9849 - val_loss: 0.7983 - val_accuracy: 0.7781\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1123 - accuracy: 0.9869 - val_loss: 0.6137 - val_accuracy: 0.7969\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0912 - accuracy: 0.9932 - val_loss: 0.5157 - val_accuracy: 0.8275\n",
            "Epoch 201/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.0707 - accuracy: 0.9979\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0705 - accuracy: 0.9977 - val_loss: 1.0394 - val_accuracy: 0.6514\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2145 - accuracy: 0.9602 - val_loss: 0.5913 - val_accuracy: 0.8095\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1538 - accuracy: 0.9774 - val_loss: 0.5296 - val_accuracy: 0.8419\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1218 - accuracy: 0.9883 - val_loss: 1.1382 - val_accuracy: 0.6361\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.9903 - val_loss: 1.3163 - val_accuracy: 0.6244\n",
            "Epoch 206/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0836 - accuracy: 0.9962\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0836 - accuracy: 0.9962 - val_loss: 1.2623 - val_accuracy: 0.5984\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3200 - accuracy: 0.9193 - val_loss: 0.8343 - val_accuracy: 0.7556\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2192 - accuracy: 0.9596 - val_loss: 1.4664 - val_accuracy: 0.5849\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1943 - accuracy: 0.9634 - val_loss: 0.8971 - val_accuracy: 0.7179\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1455 - accuracy: 0.9803 - val_loss: 0.6315 - val_accuracy: 0.8005\n",
            "Epoch 211/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.1287 - accuracy: 0.9841\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1282 - accuracy: 0.9844 - val_loss: 0.5080 - val_accuracy: 0.8500\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3177 - accuracy: 0.9254 - val_loss: 0.9575 - val_accuracy: 0.6837\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2379 - accuracy: 0.9526 - val_loss: 0.9341 - val_accuracy: 0.7053\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1941 - accuracy: 0.9690 - val_loss: 0.5872 - val_accuracy: 0.8194\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9713 - val_loss: 1.7038 - val_accuracy: 0.5076\n",
            "Epoch 216/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.1445 - accuracy: 0.9812\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1438 - accuracy: 0.9815 - val_loss: 0.5306 - val_accuracy: 0.8158\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3418 - accuracy: 0.9221 - val_loss: 1.1021 - val_accuracy: 0.6694\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2511 - accuracy: 0.9528 - val_loss: 1.1183 - val_accuracy: 0.6433\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2246 - accuracy: 0.9611 - val_loss: 1.9837 - val_accuracy: 0.4663\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1930 - accuracy: 0.9702 - val_loss: 0.7220 - val_accuracy: 0.7880\n",
            "Epoch 221/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.1544 - accuracy: 0.9809\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1546 - accuracy: 0.9806 - val_loss: 0.6072 - val_accuracy: 0.7960\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2988 - accuracy: 0.9297 - val_loss: 0.6976 - val_accuracy: 0.7862\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2263 - accuracy: 0.9528 - val_loss: 0.8171 - val_accuracy: 0.7341\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1914 - accuracy: 0.9668 - val_loss: 0.9882 - val_accuracy: 0.7089\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1724 - accuracy: 0.9718 - val_loss: 0.6864 - val_accuracy: 0.7673\n",
            "Epoch 226/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.1456 - accuracy: 0.9802\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1456 - accuracy: 0.9801 - val_loss: 0.7668 - val_accuracy: 0.7610\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6358 - accuracy: 0.8355 - val_loss: 0.9825 - val_accuracy: 0.6819\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5059 - accuracy: 0.8900 - val_loss: 2.1713 - val_accuracy: 0.4124\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4394 - accuracy: 0.9051 - val_loss: 1.0110 - val_accuracy: 0.6586\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3933 - accuracy: 0.9182 - val_loss: 1.1556 - val_accuracy: 0.6226\n",
            "Epoch 231/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.3664 - accuracy: 0.9234\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3673 - accuracy: 0.9232 - val_loss: 0.7733 - val_accuracy: 0.7493\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4464 - accuracy: 0.8877 - val_loss: 1.8556 - val_accuracy: 0.4286\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3840 - accuracy: 0.9085 - val_loss: 0.7422 - val_accuracy: 0.7520\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3280 - accuracy: 0.9322 - val_loss: 0.9789 - val_accuracy: 0.6972\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3085 - accuracy: 0.9302 - val_loss: 1.0711 - val_accuracy: 0.6550\n",
            "Epoch 236/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.2801 - accuracy: 0.9400\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2803 - accuracy: 0.9399 - val_loss: 1.2774 - val_accuracy: 0.6190\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4828 - accuracy: 0.8660 - val_loss: 1.0201 - val_accuracy: 0.6810\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4016 - accuracy: 0.8952 - val_loss: 2.0296 - val_accuracy: 0.4268\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3602 - accuracy: 0.9132 - val_loss: 1.2512 - val_accuracy: 0.5948\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3241 - accuracy: 0.9257 - val_loss: 0.8140 - val_accuracy: 0.7376\n",
            "Epoch 241/500\n",
            "86/89 [===========================>..] - ETA: 0s - loss: 0.3035 - accuracy: 0.9302\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3024 - accuracy: 0.9306 - val_loss: 0.7228 - val_accuracy: 0.7835\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7631 - accuracy: 0.7887 - val_loss: 2.0243 - val_accuracy: 0.4331\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6170 - accuracy: 0.8409 - val_loss: 0.9661 - val_accuracy: 0.6909\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5658 - accuracy: 0.8529 - val_loss: 2.2199 - val_accuracy: 0.4277\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5251 - accuracy: 0.8665 - val_loss: 0.9804 - val_accuracy: 0.7080\n",
            "Epoch 246/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.8805\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4832 - accuracy: 0.8798 - val_loss: 0.8239 - val_accuracy: 0.7350\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8356 - accuracy: 0.7517 - val_loss: 1.8905 - val_accuracy: 0.4403\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7091 - accuracy: 0.7973 - val_loss: 0.8847 - val_accuracy: 0.7278\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6500 - accuracy: 0.8113 - val_loss: 0.9116 - val_accuracy: 0.7242\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6009 - accuracy: 0.8319 - val_loss: 1.3823 - val_accuracy: 0.6146\n",
            "Epoch 251/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.5720 - accuracy: 0.8448\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5699 - accuracy: 0.8450 - val_loss: 1.5013 - val_accuracy: 0.6038\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.1470 - accuracy: 0.6392 - val_loss: 1.4341 - val_accuracy: 0.5112\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9325 - accuracy: 0.7232 - val_loss: 2.1186 - val_accuracy: 0.3477\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8628 - accuracy: 0.7411 - val_loss: 2.0101 - val_accuracy: 0.3899\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7979 - accuracy: 0.7682 - val_loss: 1.0978 - val_accuracy: 0.6514\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7614 - accuracy: 0.7765 - val_loss: 0.9630 - val_accuracy: 0.7071\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7140 - accuracy: 0.7802 - val_loss: 1.4235 - val_accuracy: 0.5624\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6777 - accuracy: 0.8007 - val_loss: 1.8342 - val_accuracy: 0.4349\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6684 - accuracy: 0.7935 - val_loss: 0.8814 - val_accuracy: 0.7170\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6282 - accuracy: 0.8111 - val_loss: 1.5886 - val_accuracy: 0.5067\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6002 - accuracy: 0.8129 - val_loss: 1.5596 - val_accuracy: 0.5220\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5794 - accuracy: 0.8267 - val_loss: 0.9374 - val_accuracy: 0.6918\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5671 - accuracy: 0.8285 - val_loss: 0.9406 - val_accuracy: 0.6918\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5517 - accuracy: 0.8364 - val_loss: 1.3504 - val_accuracy: 0.5571\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5223 - accuracy: 0.8439 - val_loss: 0.8353 - val_accuracy: 0.7439\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5147 - accuracy: 0.8421 - val_loss: 0.8875 - val_accuracy: 0.7179\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4999 - accuracy: 0.8484 - val_loss: 1.1889 - val_accuracy: 0.6146\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4932 - accuracy: 0.8529 - val_loss: 1.3038 - val_accuracy: 0.5804\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4812 - accuracy: 0.8529 - val_loss: 0.8631 - val_accuracy: 0.7161\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4592 - accuracy: 0.8633 - val_loss: 1.3328 - val_accuracy: 0.5867\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4457 - accuracy: 0.8601 - val_loss: 0.8554 - val_accuracy: 0.7278\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8735 - val_loss: 0.8134 - val_accuracy: 0.7314\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4252 - accuracy: 0.8744 - val_loss: 2.5399 - val_accuracy: 0.3549\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4207 - accuracy: 0.8694 - val_loss: 1.0289 - val_accuracy: 0.6774\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.8753 - val_loss: 1.2580 - val_accuracy: 0.5957\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3881 - accuracy: 0.8845 - val_loss: 0.9119 - val_accuracy: 0.7179\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3931 - accuracy: 0.8789 - val_loss: 0.9832 - val_accuracy: 0.6765\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3827 - accuracy: 0.8803 - val_loss: 0.7870 - val_accuracy: 0.7332\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3697 - accuracy: 0.8943 - val_loss: 1.7278 - val_accuracy: 0.5247\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3710 - accuracy: 0.8927 - val_loss: 1.0554 - val_accuracy: 0.6864\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3525 - accuracy: 0.8967 - val_loss: 1.6015 - val_accuracy: 0.5373\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3545 - accuracy: 0.8943 - val_loss: 0.9326 - val_accuracy: 0.6999\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3391 - accuracy: 0.9022 - val_loss: 1.0106 - val_accuracy: 0.6855\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3133 - accuracy: 0.9067 - val_loss: 2.8069 - val_accuracy: 0.3450\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3334 - accuracy: 0.9006 - val_loss: 0.9036 - val_accuracy: 0.7341\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3190 - accuracy: 0.9056 - val_loss: 2.4597 - val_accuracy: 0.4106\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3114 - accuracy: 0.9119 - val_loss: 0.8096 - val_accuracy: 0.7538\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3205 - accuracy: 0.8999 - val_loss: 1.2314 - val_accuracy: 0.6667\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3017 - accuracy: 0.9089 - val_loss: 0.9231 - val_accuracy: 0.7179\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3047 - accuracy: 0.9117 - val_loss: 0.8515 - val_accuracy: 0.7367\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2851 - accuracy: 0.9182 - val_loss: 0.8288 - val_accuracy: 0.7448\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2956 - accuracy: 0.9080 - val_loss: 2.0150 - val_accuracy: 0.4843\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2903 - accuracy: 0.9112 - val_loss: 0.8858 - val_accuracy: 0.7242\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2801 - accuracy: 0.9184 - val_loss: 0.9239 - val_accuracy: 0.7278\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2689 - accuracy: 0.9187 - val_loss: 0.8761 - val_accuracy: 0.7206\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2660 - accuracy: 0.9241 - val_loss: 1.1209 - val_accuracy: 0.6721\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2530 - accuracy: 0.9286 - val_loss: 0.9488 - val_accuracy: 0.7161\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2504 - accuracy: 0.9266 - val_loss: 1.4976 - val_accuracy: 0.5939\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2519 - accuracy: 0.9259 - val_loss: 0.7796 - val_accuracy: 0.7538\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2507 - accuracy: 0.9306 - val_loss: 1.0474 - val_accuracy: 0.7053\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2346 - accuracy: 0.9333 - val_loss: 0.9681 - val_accuracy: 0.7107\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2293 - accuracy: 0.9376 - val_loss: 1.1983 - val_accuracy: 0.6424\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2292 - accuracy: 0.9340 - val_loss: 3.8940 - val_accuracy: 0.2830\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2365 - accuracy: 0.9333 - val_loss: 1.0984 - val_accuracy: 0.6801\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2285 - accuracy: 0.9358 - val_loss: 1.2899 - val_accuracy: 0.6289\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2156 - accuracy: 0.9428 - val_loss: 1.2917 - val_accuracy: 0.6208\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2266 - accuracy: 0.9327 - val_loss: 1.1163 - val_accuracy: 0.6667\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2139 - accuracy: 0.9410 - val_loss: 1.9698 - val_accuracy: 0.5166\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2116 - accuracy: 0.9442 - val_loss: 1.1600 - val_accuracy: 0.6631\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1964 - accuracy: 0.9514 - val_loss: 0.8027 - val_accuracy: 0.7583\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1771 - accuracy: 0.9548 - val_loss: 2.7775 - val_accuracy: 0.4394\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2043 - accuracy: 0.9399 - val_loss: 1.0775 - val_accuracy: 0.6909\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1924 - accuracy: 0.9458 - val_loss: 1.0935 - val_accuracy: 0.7134\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2011 - accuracy: 0.9404 - val_loss: 1.2462 - val_accuracy: 0.6487\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1982 - accuracy: 0.9492 - val_loss: 1.5491 - val_accuracy: 0.5732\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1997 - accuracy: 0.9424 - val_loss: 0.8495 - val_accuracy: 0.7412\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1754 - accuracy: 0.9544 - val_loss: 1.6220 - val_accuracy: 0.5813\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1956 - accuracy: 0.9449 - val_loss: 0.8457 - val_accuracy: 0.7565\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1729 - accuracy: 0.9532 - val_loss: 1.0699 - val_accuracy: 0.7044\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1706 - accuracy: 0.9571 - val_loss: 1.2000 - val_accuracy: 0.6523\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1856 - accuracy: 0.9510 - val_loss: 1.1591 - val_accuracy: 0.6739\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1756 - accuracy: 0.9514 - val_loss: 1.1092 - val_accuracy: 0.6927\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1670 - accuracy: 0.9555 - val_loss: 0.9657 - val_accuracy: 0.7260\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1604 - accuracy: 0.9600 - val_loss: 1.0495 - val_accuracy: 0.7098\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1653 - accuracy: 0.9573 - val_loss: 1.1149 - val_accuracy: 0.7134\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1559 - accuracy: 0.9600 - val_loss: 1.1927 - val_accuracy: 0.6783\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1580 - accuracy: 0.9568 - val_loss: 1.2530 - val_accuracy: 0.6658\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1515 - accuracy: 0.9596 - val_loss: 0.9453 - val_accuracy: 0.7341\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1560 - accuracy: 0.9614 - val_loss: 0.9396 - val_accuracy: 0.7457\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1631 - accuracy: 0.9582 - val_loss: 1.0844 - val_accuracy: 0.7062\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1409 - accuracy: 0.9645 - val_loss: 1.4643 - val_accuracy: 0.6181\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1596 - accuracy: 0.9548 - val_loss: 1.1348 - val_accuracy: 0.7107\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1584 - accuracy: 0.9577 - val_loss: 1.2002 - val_accuracy: 0.6730\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9641 - val_loss: 1.0977 - val_accuracy: 0.7134\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1410 - accuracy: 0.9629 - val_loss: 1.0371 - val_accuracy: 0.7350\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9607 - val_loss: 1.1951 - val_accuracy: 0.7008\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1489 - accuracy: 0.9600 - val_loss: 1.2086 - val_accuracy: 0.6864\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1450 - accuracy: 0.9643 - val_loss: 1.0916 - val_accuracy: 0.6909\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1338 - accuracy: 0.9675 - val_loss: 1.4297 - val_accuracy: 0.6379\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1248 - accuracy: 0.9684 - val_loss: 1.0786 - val_accuracy: 0.7008\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1265 - accuracy: 0.9693 - val_loss: 1.2128 - val_accuracy: 0.7017\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1175 - accuracy: 0.9736 - val_loss: 1.0802 - val_accuracy: 0.7287\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1232 - accuracy: 0.9688 - val_loss: 1.3376 - val_accuracy: 0.6685\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1233 - accuracy: 0.9686 - val_loss: 1.0658 - val_accuracy: 0.7278\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1150 - accuracy: 0.9731 - val_loss: 1.0042 - val_accuracy: 0.7341\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1307 - accuracy: 0.9652 - val_loss: 1.3294 - val_accuracy: 0.6882\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1311 - accuracy: 0.9643 - val_loss: 1.3871 - val_accuracy: 0.6694\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1416 - accuracy: 0.9589 - val_loss: 1.0861 - val_accuracy: 0.7215\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1303 - accuracy: 0.9666 - val_loss: 1.2834 - val_accuracy: 0.6792\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1177 - accuracy: 0.9720 - val_loss: 1.1485 - val_accuracy: 0.7179\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1210 - accuracy: 0.9686 - val_loss: 1.0676 - val_accuracy: 0.7224\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1228 - accuracy: 0.9681 - val_loss: 1.6293 - val_accuracy: 0.6190\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1077 - accuracy: 0.9747 - val_loss: 1.2066 - val_accuracy: 0.7161\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1194 - accuracy: 0.9720 - val_loss: 1.3977 - val_accuracy: 0.6748\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1245 - accuracy: 0.9695 - val_loss: 1.1185 - val_accuracy: 0.7278\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1354 - accuracy: 0.9634 - val_loss: 1.4213 - val_accuracy: 0.6622\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1169 - accuracy: 0.9686 - val_loss: 1.4664 - val_accuracy: 0.6676\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1080 - accuracy: 0.9749 - val_loss: 1.0033 - val_accuracy: 0.7448\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1109 - accuracy: 0.9740 - val_loss: 1.8758 - val_accuracy: 0.6029\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1074 - accuracy: 0.9727 - val_loss: 1.1379 - val_accuracy: 0.7188\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1086 - accuracy: 0.9774 - val_loss: 1.0632 - val_accuracy: 0.7367\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0993 - accuracy: 0.9761 - val_loss: 1.4065 - val_accuracy: 0.7044\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1007 - accuracy: 0.9749 - val_loss: 1.4816 - val_accuracy: 0.6532\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0973 - accuracy: 0.9790 - val_loss: 0.9814 - val_accuracy: 0.7574\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0911 - accuracy: 0.9810 - val_loss: 1.0240 - val_accuracy: 0.7358\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0932 - accuracy: 0.9776 - val_loss: 1.1573 - val_accuracy: 0.7206\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0949 - accuracy: 0.9785 - val_loss: 1.4093 - val_accuracy: 0.6613\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0967 - accuracy: 0.9763 - val_loss: 1.1314 - val_accuracy: 0.7215\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1039 - accuracy: 0.9733 - val_loss: 1.5890 - val_accuracy: 0.6280\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1008 - accuracy: 0.9772 - val_loss: 1.1439 - val_accuracy: 0.7287\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0864 - accuracy: 0.9831 - val_loss: 1.1193 - val_accuracy: 0.7152\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0985 - accuracy: 0.9749 - val_loss: 1.5097 - val_accuracy: 0.6631\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0973 - accuracy: 0.9761 - val_loss: 1.6539 - val_accuracy: 0.6577\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0806 - accuracy: 0.9840 - val_loss: 1.3017 - val_accuracy: 0.7008\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0801 - accuracy: 0.9833 - val_loss: 1.5579 - val_accuracy: 0.6514\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0918 - accuracy: 0.9781 - val_loss: 1.4334 - val_accuracy: 0.6424\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1118 - accuracy: 0.9693 - val_loss: 1.0128 - val_accuracy: 0.7412\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0965 - accuracy: 0.9765 - val_loss: 1.5370 - val_accuracy: 0.6819\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0919 - accuracy: 0.9799 - val_loss: 1.1388 - val_accuracy: 0.7242\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0819 - accuracy: 0.9808 - val_loss: 1.2125 - val_accuracy: 0.7116\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0850 - accuracy: 0.9794 - val_loss: 1.7043 - val_accuracy: 0.6640\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0796 - accuracy: 0.9833 - val_loss: 1.1548 - val_accuracy: 0.7367\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0800 - accuracy: 0.9828 - val_loss: 1.5538 - val_accuracy: 0.6496\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0834 - accuracy: 0.9790 - val_loss: 1.1338 - val_accuracy: 0.7188\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0678 - accuracy: 0.9864 - val_loss: 1.1881 - val_accuracy: 0.7152\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0874 - accuracy: 0.9797 - val_loss: 1.3647 - val_accuracy: 0.6891\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0866 - accuracy: 0.9781 - val_loss: 1.2581 - val_accuracy: 0.6990\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0809 - accuracy: 0.9817 - val_loss: 1.1733 - val_accuracy: 0.7278\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0742 - accuracy: 0.9842 - val_loss: 1.1398 - val_accuracy: 0.7296\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0735 - accuracy: 0.9855 - val_loss: 2.2985 - val_accuracy: 0.5472\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0935 - accuracy: 0.9761 - val_loss: 1.1408 - val_accuracy: 0.7224\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0711 - accuracy: 0.9842 - val_loss: 1.3643 - val_accuracy: 0.7017\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0771 - accuracy: 0.9844 - val_loss: 1.0191 - val_accuracy: 0.7556\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0775 - accuracy: 0.9835 - val_loss: 2.4605 - val_accuracy: 0.5571\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0924 - accuracy: 0.9761 - val_loss: 1.8746 - val_accuracy: 0.6137\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0758 - accuracy: 0.9812 - val_loss: 1.2395 - val_accuracy: 0.7125\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0668 - accuracy: 0.9876 - val_loss: 1.2225 - val_accuracy: 0.6981\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0807 - accuracy: 0.9819 - val_loss: 1.1904 - val_accuracy: 0.7332\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0830 - accuracy: 0.9799 - val_loss: 1.1788 - val_accuracy: 0.7170\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0775 - accuracy: 0.9817 - val_loss: 1.1888 - val_accuracy: 0.7305\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0687 - accuracy: 0.9817 - val_loss: 1.1174 - val_accuracy: 0.7412\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0615 - accuracy: 0.9880 - val_loss: 1.2759 - val_accuracy: 0.7287\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0622 - accuracy: 0.9885 - val_loss: 1.3042 - val_accuracy: 0.7071\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0751 - accuracy: 0.9801 - val_loss: 1.1811 - val_accuracy: 0.7278\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0734 - accuracy: 0.9824 - val_loss: 1.1719 - val_accuracy: 0.7439\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0764 - accuracy: 0.9819 - val_loss: 1.1952 - val_accuracy: 0.7206\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0756 - accuracy: 0.9799 - val_loss: 1.2222 - val_accuracy: 0.7080\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0822 - accuracy: 0.9803 - val_loss: 1.1742 - val_accuracy: 0.7394\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0617 - accuracy: 0.9896 - val_loss: 1.0908 - val_accuracy: 0.7484\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0663 - accuracy: 0.9864 - val_loss: 1.1876 - val_accuracy: 0.7179\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0595 - accuracy: 0.9876 - val_loss: 1.2879 - val_accuracy: 0.7197\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0628 - accuracy: 0.9871 - val_loss: 1.1588 - val_accuracy: 0.7394\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0563 - accuracy: 0.9898 - val_loss: 1.8331 - val_accuracy: 0.6460\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0750 - accuracy: 0.9808 - val_loss: 1.5051 - val_accuracy: 0.6846\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0687 - accuracy: 0.9828 - val_loss: 1.2225 - val_accuracy: 0.7296\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0736 - accuracy: 0.9819 - val_loss: 1.2277 - val_accuracy: 0.7260\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0712 - accuracy: 0.9842 - val_loss: 1.1746 - val_accuracy: 0.7314\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0548 - accuracy: 0.9889 - val_loss: 1.0986 - val_accuracy: 0.7350\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0628 - accuracy: 0.9860 - val_loss: 1.2097 - val_accuracy: 0.7358\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0741 - accuracy: 0.9808 - val_loss: 1.2137 - val_accuracy: 0.7332\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0631 - accuracy: 0.9860 - val_loss: 1.1700 - val_accuracy: 0.7385\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0696 - accuracy: 0.9803 - val_loss: 1.1853 - val_accuracy: 0.7332\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0617 - accuracy: 0.9853 - val_loss: 1.2640 - val_accuracy: 0.7080\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0609 - accuracy: 0.9873 - val_loss: 1.2840 - val_accuracy: 0.7116\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0557 - accuracy: 0.9878 - val_loss: 1.4283 - val_accuracy: 0.6774\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0609 - accuracy: 0.9860 - val_loss: 1.7012 - val_accuracy: 0.6676\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0634 - accuracy: 0.9849 - val_loss: 1.2475 - val_accuracy: 0.7350\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0646 - accuracy: 0.9853 - val_loss: 1.5102 - val_accuracy: 0.7017\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0499 - accuracy: 0.9903 - val_loss: 1.3238 - val_accuracy: 0.7125\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0531 - accuracy: 0.9896 - val_loss: 1.3323 - val_accuracy: 0.7098\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0575 - accuracy: 0.9864 - val_loss: 1.2962 - val_accuracy: 0.7179\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0585 - accuracy: 0.9858 - val_loss: 1.2149 - val_accuracy: 0.7215\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0496 - accuracy: 0.9903 - val_loss: 1.3547 - val_accuracy: 0.7098\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0639 - accuracy: 0.9858 - val_loss: 1.2522 - val_accuracy: 0.7251\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0554 - accuracy: 0.9876 - val_loss: 1.1858 - val_accuracy: 0.7439\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0560 - accuracy: 0.9889 - val_loss: 1.2917 - val_accuracy: 0.7260\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0558 - accuracy: 0.9876 - val_loss: 1.2738 - val_accuracy: 0.7134\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0539 - accuracy: 0.9883 - val_loss: 1.2582 - val_accuracy: 0.7206\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0492 - accuracy: 0.9907 - val_loss: 2.2275 - val_accuracy: 0.6361\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0590 - accuracy: 0.9873 - val_loss: 1.2546 - val_accuracy: 0.7188\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0535 - accuracy: 0.9896 - val_loss: 1.1819 - val_accuracy: 0.7520\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0541 - accuracy: 0.9860 - val_loss: 1.2607 - val_accuracy: 0.7296\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0629 - accuracy: 0.9844 - val_loss: 1.3228 - val_accuracy: 0.7287\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0533 - accuracy: 0.9887 - val_loss: 1.4018 - val_accuracy: 0.7062\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0610 - accuracy: 0.9851 - val_loss: 2.2454 - val_accuracy: 0.6235\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0612 - accuracy: 0.9835 - val_loss: 1.1834 - val_accuracy: 0.7314\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0545 - accuracy: 0.9883 - val_loss: 1.3545 - val_accuracy: 0.7053\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0508 - accuracy: 0.9889 - val_loss: 1.5023 - val_accuracy: 0.6837\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0632 - accuracy: 0.9862 - val_loss: 1.3304 - val_accuracy: 0.7179\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0426 - accuracy: 0.9937 - val_loss: 1.3200 - val_accuracy: 0.7269\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0579 - accuracy: 0.9851 - val_loss: 6.3690 - val_accuracy: 0.2704\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0696 - accuracy: 0.9824 - val_loss: 1.3199 - val_accuracy: 0.7188\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0599 - accuracy: 0.9842 - val_loss: 1.2584 - val_accuracy: 0.7412\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0506 - accuracy: 0.9885 - val_loss: 1.2117 - val_accuracy: 0.7403\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0575 - accuracy: 0.9892 - val_loss: 1.2514 - val_accuracy: 0.7332\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0453 - accuracy: 0.9921 - val_loss: 1.3700 - val_accuracy: 0.7188\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0425 - accuracy: 0.9912 - val_loss: 1.4645 - val_accuracy: 0.7107\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0657 - accuracy: 0.9806 - val_loss: 1.3127 - val_accuracy: 0.7179\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0476 - accuracy: 0.9905 - val_loss: 1.2760 - val_accuracy: 0.7358\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0490 - accuracy: 0.9885 - val_loss: 1.2657 - val_accuracy: 0.7439\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0414 - accuracy: 0.9916 - val_loss: 1.1575 - val_accuracy: 0.7350\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0443 - accuracy: 0.9905 - val_loss: 3.5415 - val_accuracy: 0.4771\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0439 - accuracy: 0.9912 - val_loss: 1.6859 - val_accuracy: 0.6765\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0455 - accuracy: 0.9907 - val_loss: 1.2533 - val_accuracy: 0.7421\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0320 - accuracy: 0.9950 - val_loss: 1.2163 - val_accuracy: 0.7269\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0551 - accuracy: 0.9873 - val_loss: 2.5510 - val_accuracy: 0.5517\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0447 - accuracy: 0.9921 - val_loss: 1.3370 - val_accuracy: 0.7188\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0387 - accuracy: 0.9941 - val_loss: 1.2788 - val_accuracy: 0.7376\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0300 - accuracy: 0.9962 - val_loss: 1.5339 - val_accuracy: 0.7080\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0386 - accuracy: 0.9930 - val_loss: 1.3947 - val_accuracy: 0.7044\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0477 - accuracy: 0.9889 - val_loss: 1.6923 - val_accuracy: 0.6819\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0625 - accuracy: 0.9837 - val_loss: 1.2467 - val_accuracy: 0.7278\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0690 - accuracy: 0.9824 - val_loss: 1.2869 - val_accuracy: 0.7484\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0438 - accuracy: 0.9903 - val_loss: 1.2246 - val_accuracy: 0.7403\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0387 - accuracy: 0.9925 - val_loss: 1.2673 - val_accuracy: 0.7269\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0416 - accuracy: 0.9941 - val_loss: 1.2729 - val_accuracy: 0.7314\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0521 - accuracy: 0.9883 - val_loss: 1.1899 - val_accuracy: 0.7394\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0502 - accuracy: 0.9878 - val_loss: 1.2732 - val_accuracy: 0.7556\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0450 - accuracy: 0.9905 - val_loss: 1.3653 - val_accuracy: 0.7287\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0432 - accuracy: 0.9914 - val_loss: 2.0023 - val_accuracy: 0.6334\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0503 - accuracy: 0.9894 - val_loss: 1.3053 - val_accuracy: 0.7197\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0561 - accuracy: 0.9864 - val_loss: 1.4017 - val_accuracy: 0.7062\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0422 - accuracy: 0.9914 - val_loss: 1.3239 - val_accuracy: 0.7215\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0412 - accuracy: 0.9916 - val_loss: 1.3262 - val_accuracy: 0.7233\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 1.6861 - val_accuracy: 0.6828\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0430 - accuracy: 0.9914 - val_loss: 1.6489 - val_accuracy: 0.6837\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0405 - accuracy: 0.9930 - val_loss: 1.3224 - val_accuracy: 0.7224\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0328 - accuracy: 0.9948 - val_loss: 1.3498 - val_accuracy: 0.7044\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9941 - val_loss: 1.2784 - val_accuracy: 0.7296\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0312 - accuracy: 0.9953 - val_loss: 1.2711 - val_accuracy: 0.7421\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0340 - accuracy: 0.9950 - val_loss: 1.6115 - val_accuracy: 0.6927\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0398 - accuracy: 0.9912 - val_loss: 2.8810 - val_accuracy: 0.4762\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0508 - accuracy: 0.9876 - val_loss: 1.2650 - val_accuracy: 0.7403\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0351 - accuracy: 0.9946 - val_loss: 1.4895 - val_accuracy: 0.6864\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0382 - accuracy: 0.9921 - val_loss: 1.3361 - val_accuracy: 0.7278\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0340 - accuracy: 0.9937 - val_loss: 1.2799 - val_accuracy: 0.7287\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0307 - accuracy: 0.9955 - val_loss: 1.5880 - val_accuracy: 0.6891\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0346 - accuracy: 0.9948 - val_loss: 1.4089 - val_accuracy: 0.7107\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0396 - accuracy: 0.9903 - val_loss: 1.3592 - val_accuracy: 0.7197\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0317 - accuracy: 0.9934 - val_loss: 1.3543 - val_accuracy: 0.7188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wmiv69fmx4WW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42df3237-f9be-4c9b-e4a0-1866531f7177"
      },
      "source": [
        "pruningcallback_4=PruningCallback(init_step=100, end_step=250,\n",
        "                                init_sparsity=0.4, end_sparsity=0.95,pruning_step=5)\n",
        "tf.random.set_seed(1234)\n",
        "hist_p_4=model_to_prune_4.fit(X_train_50.reshape(-1,dim_50[0],dim_50[0],3), y_train, \n",
        "                     batch_size=50, epochs=500,\n",
        "                     callbacks=[pruningcallback_4],\n",
        "                     validation_data=(X_test_50.reshape(-1,dim_50[0],dim_50[0],3),y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "89/89 [==============================] - 1s 11ms/step - loss: 1.5884 - accuracy: 0.4751 - val_loss: 2.9478 - val_accuracy: 0.0458\n",
            "Epoch 2/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.9577 - accuracy: 0.6993 - val_loss: 3.8575 - val_accuracy: 0.0458\n",
            "Epoch 3/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7090 - accuracy: 0.7906 - val_loss: 4.9494 - val_accuracy: 0.1348\n",
            "Epoch 4/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5628 - accuracy: 0.8443 - val_loss: 6.5482 - val_accuracy: 0.1375\n",
            "Epoch 5/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4571 - accuracy: 0.8843 - val_loss: 5.3298 - val_accuracy: 0.1806\n",
            "Epoch 6/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3661 - accuracy: 0.9184 - val_loss: 4.3968 - val_accuracy: 0.2480\n",
            "Epoch 7/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3067 - accuracy: 0.9365 - val_loss: 2.1087 - val_accuracy: 0.3935\n",
            "Epoch 8/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2571 - accuracy: 0.9507 - val_loss: 1.0868 - val_accuracy: 0.6388\n",
            "Epoch 9/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2152 - accuracy: 0.9632 - val_loss: 0.7222 - val_accuracy: 0.7664\n",
            "Epoch 10/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1835 - accuracy: 0.9724 - val_loss: 0.6957 - val_accuracy: 0.7529\n",
            "Epoch 11/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1553 - accuracy: 0.9812 - val_loss: 0.6695 - val_accuracy: 0.7772\n",
            "Epoch 12/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1302 - accuracy: 0.9851 - val_loss: 0.6867 - val_accuracy: 0.7646\n",
            "Epoch 13/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1205 - accuracy: 0.9873 - val_loss: 1.9637 - val_accuracy: 0.4600\n",
            "Epoch 14/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0986 - accuracy: 0.9932 - val_loss: 0.5763 - val_accuracy: 0.8185\n",
            "Epoch 15/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0829 - accuracy: 0.9968 - val_loss: 0.4917 - val_accuracy: 0.8347\n",
            "Epoch 16/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0770 - accuracy: 0.9946 - val_loss: 0.8423 - val_accuracy: 0.7323\n",
            "Epoch 17/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0673 - accuracy: 0.9966 - val_loss: 0.5631 - val_accuracy: 0.8122\n",
            "Epoch 18/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0591 - accuracy: 0.9975 - val_loss: 0.5958 - val_accuracy: 0.7826\n",
            "Epoch 19/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0534 - accuracy: 0.9984 - val_loss: 0.5091 - val_accuracy: 0.8302\n",
            "Epoch 20/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.8437\n",
            "Epoch 21/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0465 - accuracy: 0.9995 - val_loss: 0.4846 - val_accuracy: 0.8419\n",
            "Epoch 22/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0396 - accuracy: 0.9995 - val_loss: 0.4807 - val_accuracy: 0.8401\n",
            "Epoch 23/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0370 - accuracy: 0.9993 - val_loss: 0.5551 - val_accuracy: 0.8113\n",
            "Epoch 24/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0352 - accuracy: 0.9998 - val_loss: 0.5085 - val_accuracy: 0.8446\n",
            "Epoch 25/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 0.5135 - val_accuracy: 0.8365\n",
            "Epoch 26/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0296 - accuracy: 0.9998 - val_loss: 0.5403 - val_accuracy: 0.8230\n",
            "Epoch 27/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.8455\n",
            "Epoch 28/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.8535\n",
            "Epoch 29/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.8437\n",
            "Epoch 30/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.5769 - val_accuracy: 0.8158\n",
            "Epoch 31/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 0.6824 - val_accuracy: 0.7781\n",
            "Epoch 32/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.8598\n",
            "Epoch 33/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.8338\n",
            "Epoch 34/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0182 - accuracy: 0.9998 - val_loss: 0.7887 - val_accuracy: 0.7529\n",
            "Epoch 35/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0183 - accuracy: 0.9998 - val_loss: 0.5090 - val_accuracy: 0.8392\n",
            "Epoch 36/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.8652\n",
            "Epoch 37/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.6621 - val_accuracy: 0.7898\n",
            "Epoch 38/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.8437\n",
            "Epoch 39/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.8544\n",
            "Epoch 40/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.8473\n",
            "Epoch 41/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.8580\n",
            "Epoch 42/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8589\n",
            "Epoch 43/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.8302\n",
            "Epoch 44/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.8500\n",
            "Epoch 45/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.8410\n",
            "Epoch 46/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.8553\n",
            "Epoch 47/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.8518\n",
            "Epoch 48/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.8553\n",
            "Epoch 49/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.8589\n",
            "Epoch 50/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.8455\n",
            "Epoch 51/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.8634\n",
            "Epoch 52/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.8500\n",
            "Epoch 53/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.8616\n",
            "Epoch 54/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.8509\n",
            "Epoch 55/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.8589\n",
            "Epoch 56/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.8625\n",
            "Epoch 57/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.8562\n",
            "Epoch 58/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.8670\n",
            "Epoch 59/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.8607\n",
            "Epoch 60/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.8580\n",
            "Epoch 61/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.8562\n",
            "Epoch 62/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.8580\n",
            "Epoch 63/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.8679\n",
            "Epoch 64/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.8643\n",
            "Epoch 65/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.8598\n",
            "Epoch 66/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.8553\n",
            "Epoch 67/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.8616\n",
            "Epoch 68/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.8580\n",
            "Epoch 69/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.8661\n",
            "Epoch 70/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.8706\n",
            "Epoch 71/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.8616\n",
            "Epoch 72/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.8643\n",
            "Epoch 73/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.8661\n",
            "Epoch 74/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.8715\n",
            "Epoch 75/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.8679\n",
            "Epoch 76/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.8670\n",
            "Epoch 77/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.8634\n",
            "Epoch 78/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.8589\n",
            "Epoch 79/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.8688\n",
            "Epoch 80/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8634\n",
            "Epoch 81/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.8625\n",
            "Epoch 82/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.8661\n",
            "Epoch 83/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.8544\n",
            "Epoch 84/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8679\n",
            "Epoch 85/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.8742\n",
            "Epoch 86/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.8544\n",
            "Epoch 87/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8688\n",
            "Epoch 88/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.8688\n",
            "Epoch 89/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.8634\n",
            "Epoch 90/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.8643\n",
            "Epoch 91/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.8688\n",
            "Epoch 92/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.8688\n",
            "Epoch 93/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.8625\n",
            "Epoch 94/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.8661\n",
            "Epoch 95/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.8670\n",
            "Epoch 96/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.8607\n",
            "Epoch 97/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.8670\n",
            "Epoch 98/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.8733\n",
            "Epoch 99/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.8598\n",
            "Epoch 100/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.8553\n",
            "Epoch 101/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0037 - accuracy: 1.0000\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.8661\n",
            "Epoch 102/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.0069 - accuracy: 0.6957 - val_loss: 1.6931 - val_accuracy: 0.4214\n",
            "Epoch 103/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6199 - accuracy: 0.8285 - val_loss: 1.3887 - val_accuracy: 0.5085\n",
            "Epoch 104/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4958 - accuracy: 0.8617 - val_loss: 1.0029 - val_accuracy: 0.6559\n",
            "Epoch 105/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4059 - accuracy: 0.8958 - val_loss: 1.0319 - val_accuracy: 0.6604\n",
            "Epoch 106/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.3320 - accuracy: 0.9152\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3338 - accuracy: 0.9146 - val_loss: 1.5243 - val_accuracy: 0.5499\n",
            "Epoch 107/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3728 - accuracy: 0.9067 - val_loss: 0.7199 - val_accuracy: 0.7682\n",
            "Epoch 108/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3041 - accuracy: 0.9239 - val_loss: 0.8294 - val_accuracy: 0.7448\n",
            "Epoch 109/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2612 - accuracy: 0.9397 - val_loss: 0.7821 - val_accuracy: 0.7376\n",
            "Epoch 110/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2326 - accuracy: 0.9471 - val_loss: 0.6018 - val_accuracy: 0.8059\n",
            "Epoch 111/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.2015 - accuracy: 0.9609\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2019 - accuracy: 0.9607 - val_loss: 0.6971 - val_accuracy: 0.7538\n",
            "Epoch 112/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2470 - accuracy: 0.9512 - val_loss: 0.6484 - val_accuracy: 0.7709\n",
            "Epoch 113/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2059 - accuracy: 0.9607 - val_loss: 0.7021 - val_accuracy: 0.7601\n",
            "Epoch 114/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1782 - accuracy: 0.9695 - val_loss: 0.5846 - val_accuracy: 0.8005\n",
            "Epoch 115/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1607 - accuracy: 0.9740 - val_loss: 0.5748 - val_accuracy: 0.7960\n",
            "Epoch 116/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.1342 - accuracy: 0.9805\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1351 - accuracy: 0.9797 - val_loss: 0.7710 - val_accuracy: 0.7448\n",
            "Epoch 117/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2250 - accuracy: 0.9512 - val_loss: 0.6987 - val_accuracy: 0.7637\n",
            "Epoch 118/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1650 - accuracy: 0.9720 - val_loss: 0.5028 - val_accuracy: 0.8347\n",
            "Epoch 119/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1445 - accuracy: 0.9799 - val_loss: 1.7835 - val_accuracy: 0.5040\n",
            "Epoch 120/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1297 - accuracy: 0.9815 - val_loss: 0.6092 - val_accuracy: 0.8212\n",
            "Epoch 121/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.1054 - accuracy: 0.9895\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1067 - accuracy: 0.9889 - val_loss: 1.2298 - val_accuracy: 0.6226\n",
            "Epoch 122/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1904 - accuracy: 0.9659 - val_loss: 0.9298 - val_accuracy: 0.6676\n",
            "Epoch 123/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1375 - accuracy: 0.9822 - val_loss: 0.6685 - val_accuracy: 0.7619\n",
            "Epoch 124/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1167 - accuracy: 0.9862 - val_loss: 0.8116 - val_accuracy: 0.7421\n",
            "Epoch 125/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1020 - accuracy: 0.9896 - val_loss: 0.9056 - val_accuracy: 0.7008\n",
            "Epoch 126/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.0890 - accuracy: 0.9929\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0895 - accuracy: 0.9928 - val_loss: 0.5106 - val_accuracy: 0.8158\n",
            "Epoch 127/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1483 - accuracy: 0.9758 - val_loss: 0.7415 - val_accuracy: 0.7691\n",
            "Epoch 128/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1150 - accuracy: 0.9867 - val_loss: 0.5669 - val_accuracy: 0.8311\n",
            "Epoch 129/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0904 - accuracy: 0.9932 - val_loss: 0.5433 - val_accuracy: 0.8104\n",
            "Epoch 130/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0789 - accuracy: 0.9953 - val_loss: 0.5515 - val_accuracy: 0.8230\n",
            "Epoch 131/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 0.0687 - accuracy: 0.9959\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0686 - accuracy: 0.9959 - val_loss: 0.6993 - val_accuracy: 0.7754\n",
            "Epoch 132/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1693 - accuracy: 0.9659 - val_loss: 1.3329 - val_accuracy: 0.6523\n",
            "Epoch 133/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1031 - accuracy: 0.9887 - val_loss: 0.5853 - val_accuracy: 0.8212\n",
            "Epoch 134/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0850 - accuracy: 0.9930 - val_loss: 5.2779 - val_accuracy: 0.1689\n",
            "Epoch 135/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0748 - accuracy: 0.9955 - val_loss: 0.4597 - val_accuracy: 0.8661\n",
            "Epoch 136/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0592 - accuracy: 0.9975\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0592 - accuracy: 0.9975 - val_loss: 0.4335 - val_accuracy: 0.8715\n",
            "Epoch 137/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2241 - accuracy: 0.9492 - val_loss: 0.7114 - val_accuracy: 0.7538\n",
            "Epoch 138/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1368 - accuracy: 0.9801 - val_loss: 0.4894 - val_accuracy: 0.8275\n",
            "Epoch 139/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1029 - accuracy: 0.9892 - val_loss: 0.7688 - val_accuracy: 0.7682\n",
            "Epoch 140/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0803 - accuracy: 0.9964 - val_loss: 0.5173 - val_accuracy: 0.8284\n",
            "Epoch 141/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.0666 - accuracy: 0.9981\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0660 - accuracy: 0.9982 - val_loss: 0.4815 - val_accuracy: 0.8580\n",
            "Epoch 142/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2261 - accuracy: 0.9426 - val_loss: 2.8638 - val_accuracy: 0.3675\n",
            "Epoch 143/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1240 - accuracy: 0.9853 - val_loss: 1.6183 - val_accuracy: 0.4825\n",
            "Epoch 144/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1033 - accuracy: 0.9873 - val_loss: 0.4893 - val_accuracy: 0.8491\n",
            "Epoch 145/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0815 - accuracy: 0.9946 - val_loss: 0.6218 - val_accuracy: 0.8140\n",
            "Epoch 146/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9989\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.0670 - accuracy: 0.9989 - val_loss: 0.4415 - val_accuracy: 0.8464\n",
            "Epoch 147/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8089 - accuracy: 0.7350 - val_loss: 3.8323 - val_accuracy: 0.3495\n",
            "Epoch 148/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3415 - accuracy: 0.8931 - val_loss: 2.6030 - val_accuracy: 0.4079\n",
            "Epoch 149/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2543 - accuracy: 0.9277 - val_loss: 0.8602 - val_accuracy: 0.7161\n",
            "Epoch 150/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2155 - accuracy: 0.9451 - val_loss: 0.7734 - val_accuracy: 0.7341\n",
            "Epoch 151/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9547\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1845 - accuracy: 0.9539 - val_loss: 3.1304 - val_accuracy: 0.3091\n",
            "Epoch 152/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4695 - accuracy: 0.8473 - val_loss: 2.2564 - val_accuracy: 0.3845\n",
            "Epoch 153/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3421 - accuracy: 0.8922 - val_loss: 1.6046 - val_accuracy: 0.5535\n",
            "Epoch 154/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2906 - accuracy: 0.9160 - val_loss: 1.2169 - val_accuracy: 0.6208\n",
            "Epoch 155/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2358 - accuracy: 0.9370 - val_loss: 0.7088 - val_accuracy: 0.7826\n",
            "Epoch 156/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.2140 - accuracy: 0.9437\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2132 - accuracy: 0.9440 - val_loss: 0.6859 - val_accuracy: 0.7835\n",
            "Epoch 157/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8608 - accuracy: 0.7135 - val_loss: 5.8031 - val_accuracy: 0.1312\n",
            "Epoch 158/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4803 - accuracy: 0.8484 - val_loss: 1.3543 - val_accuracy: 0.5651\n",
            "Epoch 159/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3898 - accuracy: 0.8807 - val_loss: 0.8355 - val_accuracy: 0.6999\n",
            "Epoch 160/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3206 - accuracy: 0.9038 - val_loss: 1.2722 - val_accuracy: 0.6226\n",
            "Epoch 161/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.2736 - accuracy: 0.9193\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2735 - accuracy: 0.9196 - val_loss: 1.2721 - val_accuracy: 0.6146\n",
            "Epoch 162/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6955 - accuracy: 0.7662 - val_loss: 1.7759 - val_accuracy: 0.4987\n",
            "Epoch 163/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.5363 - accuracy: 0.8231 - val_loss: 1.4089 - val_accuracy: 0.6020\n",
            "Epoch 164/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4640 - accuracy: 0.8488 - val_loss: 2.8215 - val_accuracy: 0.3369\n",
            "Epoch 165/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.4149 - accuracy: 0.8699 - val_loss: 1.0915 - val_accuracy: 0.6388\n",
            "Epoch 166/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.3766 - accuracy: 0.8866\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3783 - accuracy: 0.8870 - val_loss: 1.2866 - val_accuracy: 0.6173\n",
            "Epoch 167/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3810 - accuracy: 0.8870 - val_loss: 0.7569 - val_accuracy: 0.7376\n",
            "Epoch 168/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3413 - accuracy: 0.9047 - val_loss: 0.7180 - val_accuracy: 0.7466\n",
            "Epoch 169/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3247 - accuracy: 0.9123 - val_loss: 1.5296 - val_accuracy: 0.5651\n",
            "Epoch 170/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2941 - accuracy: 0.9252 - val_loss: 0.8275 - val_accuracy: 0.7161\n",
            "Epoch 171/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.2626 - accuracy: 0.9363\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2626 - accuracy: 0.9363 - val_loss: 2.1384 - val_accuracy: 0.3872\n",
            "Epoch 172/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3721 - accuracy: 0.8902 - val_loss: 1.1740 - val_accuracy: 0.6460\n",
            "Epoch 173/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.3042 - accuracy: 0.9153 - val_loss: 1.1759 - val_accuracy: 0.6757\n",
            "Epoch 174/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2757 - accuracy: 0.9291 - val_loss: 0.6596 - val_accuracy: 0.7987\n",
            "Epoch 175/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2550 - accuracy: 0.9322 - val_loss: 1.0615 - val_accuracy: 0.6945\n",
            "Epoch 176/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 0.2342 - accuracy: 0.9436\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2343 - accuracy: 0.9433 - val_loss: 0.7344 - val_accuracy: 0.7457\n",
            "Epoch 177/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2857 - accuracy: 0.9302 - val_loss: 1.1778 - val_accuracy: 0.5849\n",
            "Epoch 178/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2379 - accuracy: 0.9480 - val_loss: 1.0508 - val_accuracy: 0.6361\n",
            "Epoch 179/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2217 - accuracy: 0.9498 - val_loss: 0.7023 - val_accuracy: 0.7736\n",
            "Epoch 180/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1962 - accuracy: 0.9596 - val_loss: 0.8234 - val_accuracy: 0.7493\n",
            "Epoch 181/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9654\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1705 - accuracy: 0.9654 - val_loss: 0.6331 - val_accuracy: 0.8014\n",
            "Epoch 182/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2853 - accuracy: 0.9352 - val_loss: 0.7238 - val_accuracy: 0.7538\n",
            "Epoch 183/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2413 - accuracy: 0.9455 - val_loss: 1.4219 - val_accuracy: 0.6226\n",
            "Epoch 184/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2159 - accuracy: 0.9548 - val_loss: 0.7514 - val_accuracy: 0.7538\n",
            "Epoch 185/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1917 - accuracy: 0.9641 - val_loss: 0.7471 - val_accuracy: 0.7358\n",
            "Epoch 186/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.1663 - accuracy: 0.9732\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1667 - accuracy: 0.9733 - val_loss: 0.6940 - val_accuracy: 0.7520\n",
            "Epoch 187/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2567 - accuracy: 0.9397 - val_loss: 0.8183 - val_accuracy: 0.7341\n",
            "Epoch 188/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2155 - accuracy: 0.9580 - val_loss: 0.7561 - val_accuracy: 0.7394\n",
            "Epoch 189/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1750 - accuracy: 0.9679 - val_loss: 1.9851 - val_accuracy: 0.5391\n",
            "Epoch 190/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1763 - accuracy: 0.9634 - val_loss: 0.8969 - val_accuracy: 0.6828\n",
            "Epoch 191/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 0.1476 - accuracy: 0.9753\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1473 - accuracy: 0.9758 - val_loss: 0.6846 - val_accuracy: 0.7844\n",
            "Epoch 192/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2883 - accuracy: 0.9284 - val_loss: 0.8026 - val_accuracy: 0.7430\n",
            "Epoch 193/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2262 - accuracy: 0.9532 - val_loss: 0.9063 - val_accuracy: 0.7188\n",
            "Epoch 194/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2009 - accuracy: 0.9634 - val_loss: 0.6155 - val_accuracy: 0.8023\n",
            "Epoch 195/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1700 - accuracy: 0.9715 - val_loss: 0.8820 - val_accuracy: 0.7448\n",
            "Epoch 196/500\n",
            "89/89 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9724\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1653 - accuracy: 0.9724 - val_loss: 1.1016 - val_accuracy: 0.7071\n",
            "Epoch 197/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2466 - accuracy: 0.9494 - val_loss: 0.6561 - val_accuracy: 0.7664\n",
            "Epoch 198/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1936 - accuracy: 0.9648 - val_loss: 0.7943 - val_accuracy: 0.7439\n",
            "Epoch 199/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1823 - accuracy: 0.9688 - val_loss: 0.6609 - val_accuracy: 0.7799\n",
            "Epoch 200/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1542 - accuracy: 0.9772 - val_loss: 0.5726 - val_accuracy: 0.7951\n",
            "Epoch 201/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.1358 - accuracy: 0.9816\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1392 - accuracy: 0.9803 - val_loss: 1.5907 - val_accuracy: 0.5687\n",
            "Epoch 202/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.2357 - accuracy: 0.9480 - val_loss: 1.0509 - val_accuracy: 0.6541\n",
            "Epoch 203/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1804 - accuracy: 0.9688 - val_loss: 0.9993 - val_accuracy: 0.7017\n",
            "Epoch 204/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1625 - accuracy: 0.9731 - val_loss: 0.6979 - val_accuracy: 0.7772\n",
            "Epoch 205/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1508 - accuracy: 0.9774 - val_loss: 0.7509 - val_accuracy: 0.7502\n",
            "Epoch 206/500\n",
            "84/89 [===========================>..] - ETA: 0s - loss: 0.1308 - accuracy: 0.9821\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.1324 - accuracy: 0.9817 - val_loss: 0.9867 - val_accuracy: 0.7143\n",
            "Epoch 207/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.0313 - accuracy: 0.3394 - val_loss: 8.4138 - val_accuracy: 0.0692\n",
            "Epoch 208/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.1832 - accuracy: 0.6030 - val_loss: 4.5662 - val_accuracy: 0.0916\n",
            "Epoch 209/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8865 - accuracy: 0.7045 - val_loss: 2.1752 - val_accuracy: 0.3190\n",
            "Epoch 210/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7191 - accuracy: 0.7689 - val_loss: 2.5089 - val_accuracy: 0.2803\n",
            "Epoch 211/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.6485 - accuracy: 0.7862\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.6524 - accuracy: 0.7842 - val_loss: 1.3940 - val_accuracy: 0.5103\n",
            "Epoch 212/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.5066 - accuracy: 0.1308 - val_loss: 2.9518 - val_accuracy: 0.1375\n",
            "Epoch 213/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4405 - accuracy: 0.1306 - val_loss: 4.3579 - val_accuracy: 0.0818\n",
            "Epoch 214/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4349 - accuracy: 0.1358 - val_loss: 2.4779 - val_accuracy: 0.1096\n",
            "Epoch 215/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4316 - accuracy: 0.1313 - val_loss: 2.4492 - val_accuracy: 0.1375\n",
            "Epoch 216/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 2.4129 - accuracy: 0.1381\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4090 - accuracy: 0.1365 - val_loss: 3.4430 - val_accuracy: 0.1330\n",
            "Epoch 217/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4070 - accuracy: 0.1453 - val_loss: 2.5190 - val_accuracy: 0.1096\n",
            "Epoch 218/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.9458 - accuracy: 0.3299 - val_loss: 10.1163 - val_accuracy: 0.1303\n",
            "Epoch 219/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 1.1016 - accuracy: 0.6455 - val_loss: 2.1233 - val_accuracy: 0.3154\n",
            "Epoch 220/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.8894 - accuracy: 0.7176 - val_loss: 1.8199 - val_accuracy: 0.3854\n",
            "Epoch 221/500\n",
            "87/89 [============================>.] - ETA: 0s - loss: 0.7601 - accuracy: 0.7605\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 0.7624 - accuracy: 0.7601 - val_loss: 0.9943 - val_accuracy: 0.6586\n",
            "Epoch 222/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4502 - accuracy: 0.1261 - val_loss: 3.9778 - val_accuracy: 0.0458\n",
            "Epoch 223/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4347 - accuracy: 0.1313 - val_loss: 3.0602 - val_accuracy: 0.0970\n",
            "Epoch 224/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4328 - accuracy: 0.1313 - val_loss: 2.6084 - val_accuracy: 0.0970\n",
            "Epoch 225/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4286 - accuracy: 0.1344 - val_loss: 2.4586 - val_accuracy: 0.0970\n",
            "Epoch 226/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 2.4286 - accuracy: 0.1259\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4285 - accuracy: 0.1258 - val_loss: 2.4261 - val_accuracy: 0.1375\n",
            "Epoch 227/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4405 - accuracy: 0.1288 - val_loss: 2.4657 - val_accuracy: 0.1015\n",
            "Epoch 228/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4316 - accuracy: 0.1319 - val_loss: 2.4355 - val_accuracy: 0.1312\n",
            "Epoch 229/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4285 - accuracy: 0.1356 - val_loss: 2.4304 - val_accuracy: 0.1375\n",
            "Epoch 230/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4282 - accuracy: 0.1387 - val_loss: 2.4365 - val_accuracy: 0.1294\n",
            "Epoch 231/500\n",
            "88/89 [============================>.] - ETA: 0s - loss: 2.4269 - accuracy: 0.1318\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4274 - accuracy: 0.1313 - val_loss: 2.4347 - val_accuracy: 0.1375\n",
            "Epoch 232/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4343 - accuracy: 0.1335 - val_loss: 2.4887 - val_accuracy: 0.1375\n",
            "Epoch 233/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4296 - accuracy: 0.1240 - val_loss: 2.4393 - val_accuracy: 0.1285\n",
            "Epoch 234/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4264 - accuracy: 0.1340 - val_loss: 2.4251 - val_accuracy: 0.1285\n",
            "Epoch 235/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4234 - accuracy: 0.1403 - val_loss: 2.4232 - val_accuracy: 0.1375\n",
            "Epoch 236/500\n",
            "85/89 [===========================>..] - ETA: 0s - loss: 2.4256 - accuracy: 0.1329\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4240 - accuracy: 0.1324 - val_loss: 2.4274 - val_accuracy: 0.1285\n",
            "Epoch 237/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4268 - accuracy: 0.1374 - val_loss: 2.4293 - val_accuracy: 0.1375\n",
            "Epoch 238/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4258 - accuracy: 0.1374 - val_loss: 2.4231 - val_accuracy: 0.1312\n",
            "Epoch 239/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4231 - accuracy: 0.1344 - val_loss: 2.4139 - val_accuracy: 0.1348\n",
            "Epoch 240/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1390 - val_loss: 2.6325 - val_accuracy: 0.1249\n",
            "Epoch 241/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 2.4103 - accuracy: 0.1439\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4079 - accuracy: 0.1426 - val_loss: 2.6871 - val_accuracy: 0.0863\n",
            "Epoch 242/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4290 - accuracy: 0.1245 - val_loss: 2.4356 - val_accuracy: 0.1285\n",
            "Epoch 243/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4259 - accuracy: 0.1286 - val_loss: 2.4265 - val_accuracy: 0.1285\n",
            "Epoch 244/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4238 - accuracy: 0.1308 - val_loss: 2.4214 - val_accuracy: 0.1375\n",
            "Epoch 245/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4235 - accuracy: 0.1340 - val_loss: 2.4214 - val_accuracy: 0.1375\n",
            "Epoch 246/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 2.4243 - accuracy: 0.1325\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4244 - accuracy: 0.1308 - val_loss: 2.4190 - val_accuracy: 0.1375\n",
            "Epoch 247/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4369 - accuracy: 0.1349 - val_loss: 2.5013 - val_accuracy: 0.1285\n",
            "Epoch 248/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4278 - accuracy: 0.1356 - val_loss: 2.4399 - val_accuracy: 0.1285\n",
            "Epoch 249/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4258 - accuracy: 0.1261 - val_loss: 2.4322 - val_accuracy: 0.0970\n",
            "Epoch 250/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4251 - accuracy: 0.1310 - val_loss: 2.4255 - val_accuracy: 0.1285\n",
            "Epoch 251/500\n",
            "83/89 [==========================>...] - ETA: 0s - loss: 2.4267 - accuracy: 0.1296\n",
            " pruning [ = = = = ]\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4257 - accuracy: 0.1299 - val_loss: 2.4217 - val_accuracy: 0.1285\n",
            "Epoch 252/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4574 - accuracy: 0.1286 - val_loss: 2.4545 - val_accuracy: 0.1375\n",
            "Epoch 253/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4440 - accuracy: 0.1347 - val_loss: 2.4258 - val_accuracy: 0.1285\n",
            "Epoch 254/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4374 - accuracy: 0.1297 - val_loss: 2.4259 - val_accuracy: 0.1285\n",
            "Epoch 255/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4323 - accuracy: 0.1268 - val_loss: 2.4278 - val_accuracy: 0.1375\n",
            "Epoch 256/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4269 - accuracy: 0.1365 - val_loss: 2.4269 - val_accuracy: 0.1285\n",
            "Epoch 257/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4279 - accuracy: 0.1347 - val_loss: 2.4229 - val_accuracy: 0.1375\n",
            "Epoch 258/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4261 - accuracy: 0.1270 - val_loss: 2.4212 - val_accuracy: 0.1375\n",
            "Epoch 259/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4260 - accuracy: 0.1313 - val_loss: 2.4210 - val_accuracy: 0.1375\n",
            "Epoch 260/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4245 - accuracy: 0.1347 - val_loss: 2.4216 - val_accuracy: 0.1375\n",
            "Epoch 261/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4243 - accuracy: 0.1324 - val_loss: 2.4208 - val_accuracy: 0.1375\n",
            "Epoch 262/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4241 - accuracy: 0.1356 - val_loss: 2.4207 - val_accuracy: 0.1375\n",
            "Epoch 263/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4230 - accuracy: 0.1315 - val_loss: 2.4248 - val_accuracy: 0.1285\n",
            "Epoch 264/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4221 - accuracy: 0.1394 - val_loss: 2.4196 - val_accuracy: 0.1375\n",
            "Epoch 265/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4229 - accuracy: 0.1349 - val_loss: 2.4199 - val_accuracy: 0.1375\n",
            "Epoch 266/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4230 - accuracy: 0.1315 - val_loss: 2.4198 - val_accuracy: 0.1375\n",
            "Epoch 267/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4227 - accuracy: 0.1313 - val_loss: 2.4206 - val_accuracy: 0.1285\n",
            "Epoch 268/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4227 - accuracy: 0.1292 - val_loss: 2.4192 - val_accuracy: 0.1375\n",
            "Epoch 269/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4218 - accuracy: 0.1338 - val_loss: 2.4210 - val_accuracy: 0.1285\n",
            "Epoch 270/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4213 - accuracy: 0.1281 - val_loss: 2.4195 - val_accuracy: 0.1375\n",
            "Epoch 271/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4214 - accuracy: 0.1333 - val_loss: 2.4191 - val_accuracy: 0.1375\n",
            "Epoch 272/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4219 - accuracy: 0.1317 - val_loss: 2.4192 - val_accuracy: 0.1375\n",
            "Epoch 273/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4214 - accuracy: 0.1333 - val_loss: 2.4184 - val_accuracy: 0.1375\n",
            "Epoch 274/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4204 - accuracy: 0.1292 - val_loss: 2.4219 - val_accuracy: 0.1375\n",
            "Epoch 275/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4206 - accuracy: 0.1356 - val_loss: 2.4191 - val_accuracy: 0.1375\n",
            "Epoch 276/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4205 - accuracy: 0.1349 - val_loss: 2.4181 - val_accuracy: 0.1375\n",
            "Epoch 277/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4210 - accuracy: 0.1362 - val_loss: 2.4183 - val_accuracy: 0.1375\n",
            "Epoch 278/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4209 - accuracy: 0.1353 - val_loss: 2.4177 - val_accuracy: 0.1375\n",
            "Epoch 279/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4200 - accuracy: 0.1353 - val_loss: 2.4193 - val_accuracy: 0.1375\n",
            "Epoch 280/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4206 - accuracy: 0.1408 - val_loss: 2.4207 - val_accuracy: 0.1285\n",
            "Epoch 281/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4199 - accuracy: 0.1272 - val_loss: 2.4191 - val_accuracy: 0.1375\n",
            "Epoch 282/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4200 - accuracy: 0.1349 - val_loss: 2.4186 - val_accuracy: 0.1375\n",
            "Epoch 283/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4200 - accuracy: 0.1349 - val_loss: 2.4179 - val_accuracy: 0.1375\n",
            "Epoch 284/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4203 - accuracy: 0.1304 - val_loss: 2.4182 - val_accuracy: 0.1375\n",
            "Epoch 285/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4200 - accuracy: 0.1367 - val_loss: 2.4181 - val_accuracy: 0.1375\n",
            "Epoch 286/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4201 - accuracy: 0.1362 - val_loss: 2.4182 - val_accuracy: 0.1375\n",
            "Epoch 287/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4199 - accuracy: 0.1353 - val_loss: 2.4180 - val_accuracy: 0.1375\n",
            "Epoch 288/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4195 - accuracy: 0.1376 - val_loss: 2.4183 - val_accuracy: 0.1375\n",
            "Epoch 289/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4190 - accuracy: 0.1353 - val_loss: 2.4182 - val_accuracy: 0.1375\n",
            "Epoch 290/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4197 - accuracy: 0.1277 - val_loss: 2.4179 - val_accuracy: 0.1375\n",
            "Epoch 291/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4193 - accuracy: 0.1356 - val_loss: 2.4179 - val_accuracy: 0.1375\n",
            "Epoch 292/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4193 - accuracy: 0.1338 - val_loss: 2.4184 - val_accuracy: 0.1375\n",
            "Epoch 293/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4195 - accuracy: 0.1344 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 294/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4193 - accuracy: 0.1362 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 295/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4192 - accuracy: 0.1356 - val_loss: 2.4175 - val_accuracy: 0.1375\n",
            "Epoch 296/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4195 - accuracy: 0.1335 - val_loss: 2.4179 - val_accuracy: 0.1375\n",
            "Epoch 297/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4197 - accuracy: 0.1360 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 298/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4193 - accuracy: 0.1326 - val_loss: 2.4177 - val_accuracy: 0.1375\n",
            "Epoch 299/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4194 - accuracy: 0.1362 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 300/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4195 - accuracy: 0.1378 - val_loss: 2.4172 - val_accuracy: 0.1375\n",
            "Epoch 301/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4192 - accuracy: 0.1362 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 302/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1385 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 303/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4195 - accuracy: 0.1338 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 304/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4189 - accuracy: 0.1362 - val_loss: 2.4180 - val_accuracy: 0.1285\n",
            "Epoch 305/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4198 - accuracy: 0.1319 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 306/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4190 - accuracy: 0.1310 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 307/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4192 - accuracy: 0.1365 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 308/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1335 - val_loss: 2.4184 - val_accuracy: 0.1375\n",
            "Epoch 309/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1347 - val_loss: 2.4181 - val_accuracy: 0.1375\n",
            "Epoch 310/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4192 - accuracy: 0.1356 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 311/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4190 - accuracy: 0.1360 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 312/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4190 - accuracy: 0.1331 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 313/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4191 - accuracy: 0.1313 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 314/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4191 - accuracy: 0.1342 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 315/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1365 - val_loss: 2.4181 - val_accuracy: 0.1375\n",
            "Epoch 316/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4190 - accuracy: 0.1358 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 317/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4191 - accuracy: 0.1335 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 318/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4194 - accuracy: 0.1344 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 319/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4195 - accuracy: 0.1331 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 320/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1344 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 321/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4189 - accuracy: 0.1367 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 322/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1283 - val_loss: 2.4178 - val_accuracy: 0.1375\n",
            "Epoch 323/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4191 - accuracy: 0.1362 - val_loss: 2.4172 - val_accuracy: 0.1375\n",
            "Epoch 324/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1338 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 325/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1371 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 326/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1380 - val_loss: 2.4171 - val_accuracy: 0.1285\n",
            "Epoch 327/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1367 - val_loss: 2.4177 - val_accuracy: 0.1285\n",
            "Epoch 328/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1324 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 329/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1362 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 330/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1340 - val_loss: 2.4175 - val_accuracy: 0.1375\n",
            "Epoch 331/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1319 - val_loss: 2.4172 - val_accuracy: 0.1375\n",
            "Epoch 332/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1342 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 333/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1351 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 334/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1338 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 335/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1351 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 336/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1333 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 337/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1340 - val_loss: 2.4178 - val_accuracy: 0.1375\n",
            "Epoch 338/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4190 - accuracy: 0.1317 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 339/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1349 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 340/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1358 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 341/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1338 - val_loss: 2.4172 - val_accuracy: 0.1375\n",
            "Epoch 342/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1326 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 343/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1362 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 344/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1356 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 345/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1356 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 346/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1292 - val_loss: 2.4177 - val_accuracy: 0.1375\n",
            "Epoch 347/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1367 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 348/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1360 - val_loss: 2.4170 - val_accuracy: 0.1285\n",
            "Epoch 349/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1331 - val_loss: 2.4179 - val_accuracy: 0.1375\n",
            "Epoch 350/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1333 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 351/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1338 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 352/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1356 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 353/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1387 - val_loss: 2.4174 - val_accuracy: 0.1285\n",
            "Epoch 354/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1344 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 355/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1326 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 356/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1360 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 357/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1313 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 358/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4189 - accuracy: 0.1362 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 359/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1342 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 360/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1356 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 361/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1344 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 362/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1353 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 363/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1380 - val_loss: 2.4172 - val_accuracy: 0.1285\n",
            "Epoch 364/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1394 - val_loss: 2.4173 - val_accuracy: 0.1285\n",
            "Epoch 365/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1290 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 366/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1333 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 367/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1356 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 368/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1367 - val_loss: 2.4170 - val_accuracy: 0.1285\n",
            "Epoch 369/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1351 - val_loss: 2.4169 - val_accuracy: 0.1285\n",
            "Epoch 370/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4188 - accuracy: 0.1322 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 371/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1304 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 372/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4187 - accuracy: 0.1344 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 373/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1385 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 374/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1304 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 375/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1344 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 376/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1338 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 377/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1319 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 378/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1358 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 379/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1362 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 380/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1331 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 381/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1371 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 382/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1371 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 383/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1358 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 384/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1319 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 385/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1333 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 386/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1362 - val_loss: 2.4176 - val_accuracy: 0.1375\n",
            "Epoch 387/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1351 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 388/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1365 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 389/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1324 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 390/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1356 - val_loss: 2.4172 - val_accuracy: 0.1375\n",
            "Epoch 391/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1324 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 392/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1362 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 393/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1358 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 394/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1326 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 395/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1326 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 396/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1340 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 397/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1338 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 398/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1356 - val_loss: 2.4170 - val_accuracy: 0.1285\n",
            "Epoch 399/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4178 - accuracy: 0.1374 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 400/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1351 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 401/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1353 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 402/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1347 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 403/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1351 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 404/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1356 - val_loss: 2.4168 - val_accuracy: 0.1285\n",
            "Epoch 405/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1342 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 406/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1347 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 407/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1356 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 408/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4186 - accuracy: 0.1362 - val_loss: 2.4170 - val_accuracy: 0.1285\n",
            "Epoch 409/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1376 - val_loss: 2.4172 - val_accuracy: 0.1285\n",
            "Epoch 410/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1317 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 411/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1367 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 412/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1387 - val_loss: 2.4172 - val_accuracy: 0.1285\n",
            "Epoch 413/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1344 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 414/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1340 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 415/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1356 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 416/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1371 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 417/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1347 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 418/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1369 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 419/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1344 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 420/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1371 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 421/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1380 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 422/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1365 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 423/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1367 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 424/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1344 - val_loss: 2.4170 - val_accuracy: 0.1375\n",
            "Epoch 425/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1331 - val_loss: 2.4172 - val_accuracy: 0.1285\n",
            "Epoch 426/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1353 - val_loss: 2.4172 - val_accuracy: 0.1285\n",
            "Epoch 427/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1347 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 428/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1299 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 429/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1335 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 430/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1342 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 431/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1338 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 432/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1356 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 433/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1362 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 434/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1371 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 435/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1335 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 436/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4184 - accuracy: 0.1356 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 437/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1340 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 438/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1338 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 439/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1371 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 440/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1335 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 441/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1360 - val_loss: 2.4167 - val_accuracy: 0.1285\n",
            "Epoch 442/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1378 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 443/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1329 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 444/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1344 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 445/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1333 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 446/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1308 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 447/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1362 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 448/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4185 - accuracy: 0.1315 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 449/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1349 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 450/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1347 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 451/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1315 - val_loss: 2.4175 - val_accuracy: 0.1375\n",
            "Epoch 452/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1376 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 453/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1335 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 454/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1324 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 455/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1356 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 456/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1344 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 457/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1360 - val_loss: 2.4163 - val_accuracy: 0.1375\n",
            "Epoch 458/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1358 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 459/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1362 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 460/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1347 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 461/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1369 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 462/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1344 - val_loss: 2.4163 - val_accuracy: 0.1375\n",
            "Epoch 463/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4174 - accuracy: 0.1340 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 464/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1380 - val_loss: 2.4165 - val_accuracy: 0.1285\n",
            "Epoch 465/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1324 - val_loss: 2.4171 - val_accuracy: 0.1375\n",
            "Epoch 466/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1369 - val_loss: 2.4173 - val_accuracy: 0.1375\n",
            "Epoch 467/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1301 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 468/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1367 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 469/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1299 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 470/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1362 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 471/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1329 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 472/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1371 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 473/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1367 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 474/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4178 - accuracy: 0.1376 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 475/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1335 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 476/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1322 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 477/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1353 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 478/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1335 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 479/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4178 - accuracy: 0.1387 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 480/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1324 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 481/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4182 - accuracy: 0.1376 - val_loss: 2.4165 - val_accuracy: 0.1285\n",
            "Epoch 482/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1344 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 483/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1349 - val_loss: 2.4163 - val_accuracy: 0.1375\n",
            "Epoch 484/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4174 - accuracy: 0.1399 - val_loss: 2.4171 - val_accuracy: 0.1285\n",
            "Epoch 485/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1310 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 486/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1353 - val_loss: 2.4167 - val_accuracy: 0.1285\n",
            "Epoch 487/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1401 - val_loss: 2.4174 - val_accuracy: 0.1285\n",
            "Epoch 488/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4177 - accuracy: 0.1347 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 489/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1297 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 490/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4178 - accuracy: 0.1378 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 491/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1342 - val_loss: 2.4165 - val_accuracy: 0.1375\n",
            "Epoch 492/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1351 - val_loss: 2.4168 - val_accuracy: 0.1375\n",
            "Epoch 493/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4183 - accuracy: 0.1371 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 494/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4178 - accuracy: 0.1326 - val_loss: 2.4167 - val_accuracy: 0.1375\n",
            "Epoch 495/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4181 - accuracy: 0.1351 - val_loss: 2.4163 - val_accuracy: 0.1375\n",
            "Epoch 496/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1331 - val_loss: 2.4166 - val_accuracy: 0.1375\n",
            "Epoch 497/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4175 - accuracy: 0.1376 - val_loss: 2.4174 - val_accuracy: 0.1375\n",
            "Epoch 498/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4176 - accuracy: 0.1367 - val_loss: 2.4169 - val_accuracy: 0.1375\n",
            "Epoch 499/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4179 - accuracy: 0.1356 - val_loss: 2.4164 - val_accuracy: 0.1375\n",
            "Epoch 500/500\n",
            "89/89 [==============================] - 1s 10ms/step - loss: 2.4180 - accuracy: 0.1360 - val_loss: 2.4164 - val_accuracy: 0.1375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omxT4tj3lYld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "4dcced5f-3284-40a0-d2fa-b63b36638834"
      },
      "source": [
        "new_pruned_model_0=pruningcallback_0.get_thinner_model()\n",
        "new_pruned_model_1=pruningcallback_1.get_thinner_model()\n",
        "new_pruned_model_2=pruningcallback_2.get_thinner_model()\n",
        "new_pruned_model_3=pruningcallback_3.get_thinner_model()\n",
        "new_pruned_model_4=pruningcallback_4.get_thinner_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 3, 3, 15)\n",
            "-7.5410156 0.0\n",
            "(3, 3, 15, 31)\n",
            "-2.695411 0.0\n",
            "(3, 3, 31, 47)\n",
            "-45.052773 0.0\n",
            "(3, 3, 47, 63)\n",
            "-81.61972 0.0\n",
            "(3, 3, 3, 12)\n",
            "-8.26709 0.0\n",
            "(3, 3, 12, 25)\n",
            "1.7593553 0.0\n",
            "(3, 3, 25, 38)\n",
            "-30.350323 0.0\n",
            "(3, 3, 38, 51)\n",
            "-63.22567 0.0\n",
            "(3, 3, 3, 9)\n",
            "-5.878269 0.0\n",
            "(3, 3, 9, 19)\n",
            "-3.9263458 0.0\n",
            "(3, 3, 19, 28)\n",
            "-43.71209 0.0\n",
            "(3, 3, 28, 38)\n",
            "-57.828503 0.0\n",
            "(3, 3, 3, 6)\n",
            "-8.545763 0.0\n",
            "(3, 3, 6, 12)\n",
            "-3.8894658 0.0\n",
            "(3, 3, 12, 19)\n",
            "-33.900696 0.0\n",
            "(3, 3, 19, 25)\n",
            "-37.1224 0.0\n",
            "(3, 3, 3, 3)\n",
            "-2.7801757 0.0\n",
            "(3, 3, 3, 6)\n",
            "-1.0940483 0.0\n",
            "(3, 3, 6, 9)\n",
            "-6.462391 0.0\n",
            "(3, 3, 9, 12)\n",
            "-11.470167 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUdWrGrSV52K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "772c3d8c-3403-471d-afbd-45725128ab48"
      },
      "source": [
        "PruningCallback.W_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-d734c336c743>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPruningCallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: type object 'PruningCallback' has no attribute 'W_mask'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UDO6Qidyle2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "24700ecf-3f19-425a-d8b2-3e524565fa96"
      },
      "source": [
        "score=model_simple.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_0.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_1.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_2.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_3.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=model_to_prune_4.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "print(\"\\n\")\n",
        "score=new_pruned_model_0.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_1.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_2.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_3.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)\n",
        "score=new_pruned_model_4.evaluate(X_test_50.reshape(-1,dim_50[0],dim_50[0],3), y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.8850\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.8652\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.8580\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.0271 - accuracy: 0.7772\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.3479 - accuracy: 0.7233\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.4163 - accuracy: 0.1375\n",
            "\n",
            "\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.9632 - accuracy: 0.8652\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.8385 - accuracy: 0.8580\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.4480 - accuracy: 0.7772\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.9832 - accuracy: 0.7233\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.4443 - accuracy: 0.1375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CSg8dROmM79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "3278f574-b7ed-4c7d-f78a-bde5b2faef4d"
      },
      "source": [
        "print(hist_p.history)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist_p.history[\"loss\"])\n",
        "plt.plot(hist_p.history[\"val_loss\"])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(hist_p.history[\"accuracy\"])\n",
        "plt.plot(hist_p.history[\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [1.5767972469329834, 0.9485172033309937, 0.7004455924034119, 0.5556265711784363, 0.4522484838962555, 0.365019291639328, 0.30196839570999146, 0.25505366921424866, 0.21638478338718414, 0.18440358340740204, 0.15807563066482544, 0.1296519786119461, 0.12091612070798874, 0.10013977438211441, 0.08391790837049484, 0.07748986780643463, 0.06653120368719101, 0.06014034152030945, 0.05415219068527222, 0.04748038202524185, 0.04777868464589119, 0.04058462753891945, 0.03813285380601883, 0.03610540181398392, 0.03048255853354931, 0.030688906088471413, 0.026872379705309868, 0.024303097277879715, 0.024453535676002502, 0.022613704204559326, 0.021504171192646027, 0.019693026319146156, 0.01925036497414112, 0.018903860822319984, 0.018880078569054604, 0.016925673931837082, 0.016052039340138435, 0.015492080710828304, 0.015120313502848148, 0.014416558668017387, 0.01294130738824606, 0.013310572132468224, 0.012313686311244965, 0.011677752248942852, 0.01171606220304966, 0.011040364392101765, 0.01050249207764864, 0.01058776956051588, 0.010451831854879856, 0.010319733060896397, 0.009425942786037922, 0.00975635927170515, 0.009340964257717133, 0.008956125937402248, 0.00848370511084795, 0.008052005432546139, 0.008246364071965218, 0.007984783500432968, 0.008066757582128048, 0.007429874502122402, 0.007410391699522734, 0.007338298484683037, 0.00698355957865715, 0.006902935914695263, 0.007182887755334377, 0.006601066794246435, 0.006726737134158611, 0.006963412277400494, 0.006132981739938259, 0.006383629981428385, 0.005979540292173624, 0.006188014056533575, 0.0060363104566931725, 0.005726865492761135, 0.005817652679979801, 0.005605414044111967, 0.005470686126500368, 0.005270087160170078, 0.005510307382792234, 0.00539670092985034, 0.005041242111474276, 0.004880504682660103, 0.005328579805791378, 0.004806176293641329, 0.004759408533573151, 0.004676309414207935, 0.004501496907323599, 0.004610962700098753, 0.004563209135085344, 0.004649539943784475, 0.004283499903976917, 0.004195854067802429, 0.004294456914067268, 0.004097705241292715, 0.003997154999524355, 0.004028679337352514, 0.004046608693897724, 0.004095746204257011, 0.0038312471006065607, 0.003723505651578307, 0.003765435889363289, 1.0576989650726318, 0.6541020274162292, 0.5272162556648254, 0.4312054514884949, 0.35769525170326233, 0.31294283270835876, 0.26638683676719666, 0.23446767032146454, 0.20343253016471863, 0.18267346918582916, 0.26883745193481445, 0.20680004358291626, 0.16941846907138824, 0.15168258547782898, 0.13028351962566376, 0.12237660586833954, 0.098556749522686, 0.08661532402038574, 0.08303524553775787, 0.06864090263843536, 0.1552903950214386, 0.10999405384063721, 0.08798163384199142, 0.0788177028298378, 0.06650800257921219, 0.05905218794941902, 0.05514919385313988, 0.046635378152132034, 0.04530400037765503, 0.03834303095936775, 0.28261929750442505, 0.10045876353979111, 0.07686924189329147, 0.06453530490398407, 0.0556023083627224, 0.0426289439201355, 0.04279754310846329, 0.03649907186627388, 0.032342929393053055, 0.029065104201436043, 0.09285677969455719, 0.06682416051626205, 0.0583302341401577, 0.05271466076374054, 0.043008964508771896, 0.039503052830696106, 0.033985741436481476, 0.030928272753953934, 0.02890908718109131, 0.026500603184103966, 0.16785717010498047, 0.08867088705301285, 0.06729616969823837, 0.0494159571826458, 0.046286582946777344, 0.04261213168501854, 0.0355134941637516, 0.03152035176753998, 0.02894255891442299, 0.026452209800481796, 0.18235740065574646, 0.0885418951511383, 0.06417296081781387, 0.05252751335501671, 0.04589642211794853, 0.0386580266058445, 0.035499926656484604, 0.03176746517419815, 0.028760887682437897, 0.025802183896303177, 0.7218711376190186, 0.30545690655708313, 0.2195829302072525, 0.18252292275428772, 0.13519877195358276, 0.10789401829242706, 0.09058360755443573, 0.08196643739938736, 0.07043436914682388, 0.05621511489152908, 0.5093634128570557, 0.2236071676015854, 0.1607632339000702, 0.12324586510658264, 0.09181136637926102, 0.08083262294530869, 0.0695636197924614, 0.05903351679444313, 0.04933490976691246, 0.04277834668755531, 0.5324274897575378, 0.2246231734752655, 0.1807134747505188, 0.12481950223445892, 0.10206261277198792, 0.08288627117872238, 0.07218149304389954, 0.05937931314110756, 0.050134167075157166, 0.042243197560310364, 0.14663350582122803, 0.0956009104847908, 0.07587084919214249, 0.06412067264318466, 0.05407840758562088, 0.04971395432949066, 0.04302910715341568, 0.04266321659088135, 0.03385729342699051, 0.03239257633686066, 0.13395501673221588, 0.09115186333656311, 0.07775703072547913, 0.06867339462041855, 0.05266714096069336, 0.04615374282002449, 0.03996077924966812, 0.03838682174682617, 0.03535522148013115, 0.030661284923553467, 0.22829824686050415, 0.15636569261550903, 0.10991678386926651, 0.10489857941865921, 0.0761847048997879, 0.06465160846710205, 0.05371691659092903, 0.04662741348147392, 0.04325096681714058, 0.04259617626667023, 0.22800879180431366, 0.14188572764396667, 0.10422035306692123, 0.0965481773018837, 0.07467906177043915, 0.06845145672559738, 0.05793114751577377, 0.047650616616010666, 0.04264557361602783, 0.04374188557267189, 0.23335902392864227, 0.14608681201934814, 0.10678169876337051, 0.09697794914245605, 0.08030645549297333, 0.06530094146728516, 0.053253185003995895, 0.04616360738873482, 0.05052536725997925, 0.04256361722946167, 0.2900978624820709, 0.20178203284740448, 0.14168430864810944, 0.12094317376613617, 0.1028255894780159, 0.0877731516957283, 0.07948782294988632, 0.07219941914081573, 0.057425111532211304, 0.05064787343144417, 0.04794159159064293, 0.04877619445323944, 0.0375768318772316, 0.03424966335296631, 0.03534501791000366, 0.02984265796840191, 0.030904574319720268, 0.02472560666501522, 0.025432271882891655, 0.021114254370331764, 0.019931087270379066, 0.020963434129953384, 0.023115884512662888, 0.01925942674279213, 0.017003420740365982, 0.0165715254843235, 0.01584882289171219, 0.014420779421925545, 0.015482746064662933, 0.014829360879957676, 0.013714747503399849, 0.012189364060759544, 0.01280832290649414, 0.01471648644655943, 0.013646972365677357, 0.011697210371494293, 0.010835230350494385, 0.009501122869551182, 0.010214123874902725, 0.00990575086325407, 0.009877236559987068, 0.009545602835714817, 0.00942719355225563, 0.008434965275228024, 0.009152930229902267, 0.008361496962606907, 0.007891446352005005, 0.008297724649310112, 0.007573968730866909, 0.009033321402966976, 0.015239881351590157, 0.0078310901299119, 0.007451329380273819, 0.007830113172531128, 0.006919397972524166, 0.007019737269729376, 0.007003178820014, 0.006290540099143982, 0.006096202414482832, 0.005853474140167236, 0.006134167779237032, 0.0058976695872843266, 0.0056522320955991745, 0.005960984155535698, 0.005718999542295933, 0.006115564610809088, 0.006136439274996519, 0.005339698866009712, 0.005723937880247831, 0.005272608250379562, 0.005700095556676388, 0.005266412161290646, 0.0049360706470906734, 0.004529758356511593, 0.004708659835159779, 0.004747483879327774, 0.004627008456736803, 0.004483105149120092, 0.004468488972634077, 0.004198058973997831, 0.004522145260125399, 0.004393755458295345, 0.004287497140467167, 0.004148862790316343, 0.004097204655408859, 0.004234333988279104, 0.004038423299789429, 0.004121246747672558, 0.003858124138787389, 0.0038020843639969826, 0.0033345066476613283, 0.0036441588308662176, 0.003665920114144683, 0.003628556150943041, 0.003760391380637884, 0.003622376127168536, 0.0038653630763292313, 0.0034985665697604418, 0.003453714307397604, 0.0036413827911019325, 0.003565114689990878, 0.003324009943753481, 0.0034790763165801764, 0.00410235533490777, 0.003848602529615164, 0.003324371064081788, 0.0030978252179920673, 0.003325148019939661, 0.0032756016589701176, 0.003490972565487027, 0.003424495691433549, 0.002944947686046362, 0.0034059302415698767, 0.0031345938332378864, 0.002882293425500393, 0.002982246922329068, 0.0033809503074735403, 0.003410161007195711, 0.0038904407992959023, 0.0029608977492898703, 0.002920930739492178, 0.002737008733674884, 0.0024947563651949167, 0.002677398733794689, 0.002699048025533557, 0.002983054146170616, 0.0027705926913768053, 0.0025061331689357758, 0.0024165918584913015, 0.0024830198381096125, 0.002407525898888707, 0.0025349422357976437, 0.002282212721183896, 0.0022976589389145374, 0.0025758452247828245, 0.002356981858611107, 0.002620244864374399, 0.0021983215119689703, 0.0022901445627212524, 0.0023905623238533735, 0.002181636169552803, 0.0024965726770460606, 0.0024773788172751665, 0.0025075695011764765, 0.0022013999987393618, 0.0021718530915677547, 0.002354418160393834, 0.0023915853817015886, 0.00247327983379364, 0.0021122293546795845, 0.0023486949503421783, 0.002154885558411479, 0.0023747424129396677, 0.0022249214816838503, 0.002273951191455126, 0.0021634798031300306, 0.002135460264980793, 0.0019775780383497477, 0.002087560249492526, 0.002022871747612953, 0.002068479545414448, 0.002173433545976877, 0.1334291249513626, 0.016591740772128105, 0.006911762990057468, 0.003929963801056147, 0.003570487489923835, 0.003192530246451497, 0.0030084336176514626, 0.002852784236893058, 0.0027317379135638475, 0.0032147769816219807, 0.002648558234795928, 0.002604228910058737, 0.0023380257189273834, 0.002627028850838542, 0.0025356165133416653, 0.0023905558045953512, 0.002256035339087248, 0.0022199794184416533, 0.002256112638860941, 0.0021044034510850906, 0.002124491147696972, 0.0022083744406700134, 0.0021253605373203754, 0.0019651821348816156, 0.002262653084471822, 0.0020391936413943768, 0.0020370124839246273, 0.0021479942370206118, 0.0017972447676584125, 0.0020408327691257, 0.0018832760397344828, 0.0018489164067432284, 0.0017070204485207796, 0.0017991422209888697, 0.001786839566193521, 0.001833725837059319, 0.0016413265839219093, 0.0018240241333842278, 0.0018284028628841043, 0.0017437777714803815, 0.0016754335956647992, 0.0018407722236588597, 0.001592944492585957, 0.0015675447648391128, 0.001697229570709169, 0.0015429304912686348, 0.0016778882127255201, 0.0014407186536118388, 0.0015948571963235736, 0.0016407358925789595, 0.0014982722932472825, 0.0013552650343626738, 0.0016520385397598147, 0.0015317960642278194, 0.0014159622369334102, 0.0013049887493252754, 0.0015287849819287658, 0.0014725886285305023, 0.0015203367220237851, 0.0014681328320875764, 0.0013703020522370934, 0.001344085205346346, 0.0014424837427213788, 0.0015574831049889326, 0.0017339445184916258, 0.001457172678783536, 0.0014991799835115671, 0.0013785787159577012, 0.0016780932201072574, 0.0013664084253832698, 0.001369131845422089, 0.0014502553967759013, 0.001327328267507255, 0.001344046788290143, 0.0012401019921526313, 0.001348678139038384, 0.001321981311775744, 0.001282203709706664, 0.0013178943190723658, 0.001331785344518721, 0.0012589107500389218, 0.00119395658839494, 0.001365161151625216, 0.0011814365861937404, 0.0011857629287987947, 0.0011671256506815553, 0.0011706185759976506], 'accuracy': [0.48169904947280884, 0.6988251209259033, 0.7962042689323425, 0.8459105491638184, 0.8870311975479126, 0.9170808792114258, 0.9374153017997742, 0.9498418569564819, 0.9627202749252319, 0.972661554813385, 0.9801174998283386, 0.9841843843460083, 0.987799346446991, 0.9918662309646606, 0.9963849782943726, 0.9966109395027161, 0.997740626335144, 0.9981924891471863, 0.9990962743759155, 0.9997740387916565, 0.9993221759796143, 0.9990962743759155, 0.9993221759796143, 0.9997740387916565, 1.0, 0.9997740387916565, 1.0, 1.0, 1.0, 1.0, 0.9997740387916565, 1.0, 1.0, 0.9997740387916565, 0.9997740387916565, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6730682253837585, 0.8145052194595337, 0.8551739454269409, 0.8838680386543274, 0.9082693457603455, 0.9245368242263794, 0.9408043622970581, 0.9466786980628967, 0.9597830772399902, 0.9645277857780457, 0.9387708902359009, 0.9568459391593933, 0.9694983959197998, 0.9774062633514404, 0.9789878129959106, 0.9819250106811523, 0.9909625053405762, 0.9948034286499023, 0.9936737418174744, 0.9968369007110596, 0.9685946702957153, 0.9850881099700928, 0.9927700161933899, 0.9950293898582458, 0.9981924891471863, 0.9986443519592285, 0.997740626335144, 0.9995481371879578, 0.9981924891471863, 0.9995481371879578, 0.9200180768966675, 0.9862177968025208, 0.9961590766906738, 0.9981924891471863, 0.9981924891471863, 0.9993221759796143, 0.9995481371879578, 0.9997740387916565, 0.9995481371879578, 1.0, 0.9916403293609619, 0.9984184503555298, 0.9979665875434875, 0.9979665875434875, 0.9997740387916565, 1.0, 0.9997740387916565, 1.0, 1.0, 0.9997740387916565, 0.9595571756362915, 0.9891549944877625, 0.9950293898582458, 0.9986443519592285, 0.9986443519592285, 0.9986443519592285, 0.9997740387916565, 1.0, 1.0, 1.0, 0.9563940167427063, 0.9900587201118469, 0.9966109395027161, 0.998870313167572, 0.998870313167572, 0.9997740387916565, 0.9997740387916565, 0.9997740387916565, 1.0, 1.0, 0.7695435881614685, 0.919792115688324, 0.9489380717277527, 0.9600090384483337, 0.9776321649551392, 0.98712158203125, 0.9905106425285339, 0.9932218790054321, 0.9954812526702881, 0.9993221759796143, 0.8436511754989624, 0.9478083848953247, 0.9683687090873718, 0.9801174998283386, 0.9898328185081482, 0.9929959177970886, 0.9966109395027161, 0.9959331154823303, 0.9984184503555298, 0.9997740387916565, 0.8402621150016785, 0.944193422794342, 0.9602349996566772, 0.9812471866607666, 0.9887031316757202, 0.9945774674415588, 0.9948034286499023, 0.9968369007110596, 0.9984184503555298, 0.998870313167572, 0.9762765765190125, 0.9938997030258179, 0.997740626335144, 0.9975146651268005, 0.9993221759796143, 0.9984184503555298, 0.9993221759796143, 0.9990962743759155, 1.0, 1.0, 0.9805693626403809, 0.9936737418174744, 0.9945774674415588, 0.9961590766906738, 0.998870313167572, 1.0, 0.9997740387916565, 0.9993221759796143, 0.9997740387916565, 0.9990962743759155, 0.9563940167427063, 0.9746949672698975, 0.9907365441322327, 0.9905106425285339, 0.9968369007110596, 0.9986443519592285, 0.9993221759796143, 0.9995481371879578, 0.9993221759796143, 0.9997740387916565, 0.9496158957481384, 0.9805693626403809, 0.9909625053405762, 0.9929959177970886, 0.9950293898582458, 0.9954812526702881, 0.9979665875434875, 0.9986443519592285, 0.9995481371879578, 0.9984184503555298, 0.9446452856063843, 0.9776321649551392, 0.9873474836349487, 0.9896068572998047, 0.9936737418174744, 0.9975146651268005, 0.9986443519592285, 0.9997740387916565, 0.997740626335144, 0.9990962743759155, 0.9317668080329895, 0.9647537469863892, 0.9805693626403809, 0.9850881099700928, 0.9923180937767029, 0.9920921921730042, 0.9938997030258179, 0.9961590766906738, 0.9984184503555298, 0.9981924891471863, 0.9986443519592285, 0.9979665875434875, 0.9997740387916565, 0.9997740387916565, 0.9995481371879578, 0.9997740387916565, 0.9990962743759155, 1.0, 0.998870313167572, 1.0, 1.0, 0.9995481371879578, 0.9995481371879578, 0.9997740387916565, 1.0, 0.9995481371879578, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9995481371879578, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997740387916565, 1.0, 1.0, 1.0, 1.0, 0.9997740387916565, 0.9986443519592285, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997740387916565, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9997740387916565, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9613646864891052, 0.998870313167572, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'val_loss': [2.9205756187438965, 3.88287091255188, 4.972583293914795, 6.473324298858643, 5.007349014282227, 3.5179965496063232, 2.092026472091675, 0.9311603307723999, 0.6238133311271667, 0.9133221507072449, 0.6483384966850281, 0.6659873127937317, 2.0404720306396484, 0.5714718699455261, 0.5184810757637024, 0.5804497003555298, 0.6410683393478394, 0.5328372716903687, 0.4912753105163574, 0.4801448881626129, 0.4783473312854767, 0.509680449962616, 0.5086106061935425, 0.5314851999282837, 0.49101439118385315, 0.5877059698104858, 0.45369642972946167, 0.47164514660835266, 0.5388448238372803, 0.6145002841949463, 0.5211371183395386, 0.4529869258403778, 0.4957163631916046, 0.8482581377029419, 0.46690595149993896, 0.4462565779685974, 0.5083635449409485, 0.4642869234085083, 0.46519702672958374, 0.46177905797958374, 0.4478015601634979, 0.44982871413230896, 0.5760172009468079, 0.45420488715171814, 0.43664032220840454, 0.4368007779121399, 0.44826287031173706, 0.45796653628349304, 0.4392254054546356, 0.49389296770095825, 0.4437369406223297, 0.44820964336395264, 0.45134276151657104, 0.5246806144714355, 0.43714427947998047, 0.43536630272865295, 0.47184842824935913, 0.43343597650527954, 0.4386619031429291, 0.45365700125694275, 0.4351191818714142, 0.44522684812545776, 0.48156797885894775, 0.4333278238773346, 0.46623796224594116, 0.449788898229599, 0.4444282352924347, 0.44158437848091125, 0.4381694197654724, 0.4307733476161957, 0.4422959089279175, 0.44725871086120605, 0.43819981813430786, 0.4320683479309082, 0.43913519382476807, 0.43190065026283264, 0.44429200887680054, 0.45950156450271606, 0.47695937752723694, 0.43935340642929077, 0.43749311566352844, 0.4364626109600067, 0.44709545373916626, 0.43272989988327026, 0.4566037356853485, 0.4515351355075836, 0.4309484660625458, 0.4439854621887207, 0.43076854944229126, 0.43503832817077637, 0.42979711294174194, 0.4335164427757263, 0.4444487392902374, 0.43256720900535583, 0.4346524178981781, 0.4354857802391052, 0.43468013405799866, 0.4319629371166229, 0.4491582214832306, 0.45881107449531555, 0.4424605071544647, 2.1936020851135254, 2.162654399871826, 2.4042978286743164, 2.040071487426758, 2.4313125610351562, 0.6352592706680298, 1.1254374980926514, 0.5347646474838257, 0.7991929054260254, 0.8227071762084961, 0.6242669820785522, 0.6650853157043457, 0.7733513116836548, 0.6193727850914001, 1.9594502449035645, 0.62184739112854, 0.45691636204719543, 0.8811516165733337, 0.8586050868034363, 0.6894199848175049, 0.7886709570884705, 0.4832659065723419, 0.9929184913635254, 0.4741843342781067, 0.5059459209442139, 0.4460779130458832, 0.44843828678131104, 0.6396253108978271, 0.6679304838180542, 0.434778094291687, 1.6816076040267944, 1.803494930267334, 1.3367502689361572, 0.5215916037559509, 0.6230157613754272, 0.47002148628234863, 0.5026025772094727, 0.44121983647346497, 0.5584850907325745, 0.42377975583076477, 0.6471271514892578, 1.3571990728378296, 0.5386596322059631, 0.458362877368927, 0.5834873914718628, 0.7165299654006958, 0.40439313650131226, 0.4385308027267456, 0.48892828822135925, 0.536160945892334, 0.8370373845100403, 1.5795235633850098, 0.5386906266212463, 0.438199907541275, 0.4916761815547943, 0.4887969493865967, 0.4374152421951294, 0.4676109552383423, 0.4274666905403137, 0.4144895076751709, 0.9655117988586426, 0.5557770133018494, 0.5353634357452393, 0.48169055581092834, 0.769705593585968, 0.4606911540031433, 0.5941817164421082, 0.5266444683074951, 0.4243084192276001, 0.48734498023986816, 1.4068609476089478, 1.6598719358444214, 2.432445526123047, 1.2363166809082031, 0.5744063258171082, 0.6899917721748352, 2.162929058074951, 0.49298009276390076, 0.945743203163147, 0.49252328276634216, 9.46413516998291, 1.4182288646697998, 0.887662947177887, 0.5055598020553589, 0.4999866187572479, 0.5697830319404602, 0.5279531478881836, 0.5958912968635559, 0.4704288840293884, 0.4508909583091736, 0.8771728277206421, 0.9680624604225159, 0.5558521151542664, 1.0650138854980469, 0.6864166855812073, 1.2722560167312622, 0.7287433743476868, 0.4813123345375061, 0.530871570110321, 0.4631914794445038, 0.6168379187583923, 0.7728172540664673, 1.0950340032577515, 0.5003625750541687, 0.5254153609275818, 0.5069615840911865, 0.900283932685852, 0.4825027585029602, 0.48261451721191406, 0.44868379831314087, 0.5716394186019897, 0.8647290468215942, 0.5788810849189758, 0.6469967365264893, 0.6035699844360352, 0.4850003719329834, 0.9431378245353699, 0.7203611731529236, 0.621879518032074, 0.4458082616329193, 0.6413179636001587, 0.5121971964836121, 0.5181533694267273, 0.5287549495697021, 0.621901273727417, 0.4724908471107483, 0.4667837619781494, 0.4917682111263275, 0.541664719581604, 1.172645092010498, 0.55500328540802, 0.6805611848831177, 1.0333491563796997, 0.5007073879241943, 0.8805965781211853, 0.5032885074615479, 0.5366852283477783, 0.48279884457588196, 0.46348264813423157, 0.4818249046802521, 1.0801572799682617, 0.6775199770927429, 0.5464583039283752, 0.561306357383728, 0.6268672943115234, 0.5783522725105286, 0.5701916813850403, 0.46415257453918457, 0.4572065472602844, 0.44244062900543213, 1.3862470388412476, 1.238694429397583, 0.6495329737663269, 0.5126215815544128, 0.6145013570785522, 0.6303008198738098, 0.7260655760765076, 0.5475441217422485, 0.5199739933013916, 0.5399983525276184, 0.6298876404762268, 0.5961354970932007, 0.5486742854118347, 0.4974874258041382, 0.531116783618927, 0.5305482745170593, 0.6436257362365723, 0.49889275431632996, 0.5379475951194763, 0.48760563135147095, 0.48497164249420166, 0.6394177675247192, 0.5016748905181885, 0.5096520185470581, 0.505406379699707, 0.5542811751365662, 0.48831453919410706, 0.4918906092643738, 0.6463712453842163, 0.4955298900604248, 0.48578137159347534, 0.5020785927772522, 1.0516704320907593, 0.48681679368019104, 0.552162230014801, 0.5049749612808228, 0.5328729152679443, 0.49692440032958984, 0.5491898655891418, 0.512097179889679, 0.52433842420578, 0.5076009631156921, 0.5090951919555664, 0.5215936899185181, 0.4971064627170563, 0.49609851837158203, 0.5083019733428955, 0.5148511528968811, 0.5072209239006042, 3.384554147720337, 0.546442449092865, 0.5203417539596558, 0.5262638330459595, 0.5299464464187622, 0.5114695429801941, 0.49679097533226013, 0.5300697684288025, 0.5132982730865479, 0.5170729160308838, 0.5128666758537292, 0.511332631111145, 0.5166547298431396, 0.5293582677841187, 0.5104067325592041, 0.5229731798171997, 0.5527393817901611, 0.5154432058334351, 0.5236031413078308, 0.5394408106803894, 0.5202523469924927, 0.526139497756958, 0.5154588222503662, 0.5212809443473816, 0.5310987830162048, 0.5244804620742798, 0.5119389891624451, 0.518047571182251, 0.5186222195625305, 0.5251602530479431, 0.5206383466720581, 0.5295491814613342, 0.5258540511131287, 0.5276055335998535, 0.5367332100868225, 0.5510202050209045, 0.6174522042274475, 0.5330623388290405, 0.5152423977851868, 0.5207390189170837, 0.5294416546821594, 0.5319982171058655, 0.5289255380630493, 0.5337203741073608, 0.5337628126144409, 0.5332354307174683, 0.5444865822792053, 0.5429225564002991, 0.5452685952186584, 0.5414412021636963, 0.5374561548233032, 0.5302505493164062, 0.515449047088623, 0.7041589617729187, 0.546863317489624, 0.5351266264915466, 0.5360943675041199, 0.5396974086761475, 0.5443286895751953, 0.5413493514060974, 0.5838484764099121, 0.5474966764450073, 0.5333067774772644, 0.5746868848800659, 0.5438835620880127, 0.5365954041481018, 0.5392141342163086, 0.5474313497543335, 0.5373451709747314, 0.5252904295921326, 0.5653769373893738, 0.5377193093299866, 0.5359944701194763, 0.5435493588447571, 0.5454885363578796, 0.5916934609413147, 0.5464538931846619, 0.538877546787262, 0.5362202525138855, 0.5319772958755493, 0.5378319621086121, 0.5354123115539551, 0.5306079983711243, 0.5270697474479675, 0.5478928685188293, 0.5490666031837463, 0.5429480075836182, 0.5310482382774353, 0.5454679131507874, 0.5418954491615295, 0.5357752442359924, 0.5534914135932922, 0.5706612467765808, 0.550098180770874, 0.5405715703964233, 0.564372718334198, 0.5447958707809448, 0.5494493246078491, 0.5424540638923645, 0.5550363063812256, 0.5450153946876526, 0.542048990726471, 0.5450720191001892, 0.5502877831459045, 0.550518810749054, 0.5507980585098267, 0.5418268442153931, 0.5347577929496765, 0.5421253442764282, 0.5412259697914124, 0.5493093729019165, 0.5536356568336487, 0.7687035799026489, 0.6904537677764893, 0.752250075340271, 0.5054960250854492, 0.5050244331359863, 0.5258261561393738, 0.5171477794647217, 0.5339259505271912, 0.5273783206939697, 0.5317187309265137, 0.5485808253288269, 0.5317012667655945, 0.5226351022720337, 0.5375040173530579, 0.5266733169555664, 0.5261247754096985, 0.5280219912528992, 0.5321467518806458, 0.5436522364616394, 0.5351519584655762, 0.5354783535003662, 0.5538721084594727, 0.5309114456176758, 0.5391650795936584, 0.5393722057342529, 0.5505711436271667, 0.5460783243179321, 0.5282599329948425, 0.5440882444381714, 0.5320103168487549, 0.5487943291664124, 0.5479874014854431, 0.534550666809082, 0.5311267971992493, 0.5350350737571716, 0.5459315180778503, 0.5512685775756836, 0.5604993104934692, 0.5969765782356262, 0.5549669861793518, 0.5418522953987122, 0.5438304543495178, 0.5580675005912781, 0.550839900970459, 0.5504955053329468, 0.5521109104156494, 0.5526401400566101, 0.5480935573577881, 0.5501641035079956, 0.553493320941925, 0.54352867603302, 0.5499565601348877, 0.5484597682952881, 0.5528149008750916, 0.5501660704612732, 0.5469315648078918, 0.550348162651062, 0.5481366515159607, 0.5544978976249695, 0.5520465970039368, 0.5466126799583435, 0.5489500164985657, 0.547637939453125, 0.5624943971633911, 0.5465407371520996, 0.559812605381012, 0.5895122289657593, 0.5667175054550171, 0.5483725666999817, 0.5665284991264343, 0.5528802871704102, 0.5702661871910095, 0.5392215251922607, 0.5486803650856018, 0.5545154809951782, 0.5508726835250854, 0.5595159530639648, 0.549913763999939, 0.5569371581077576, 0.5485060214996338, 0.5586167573928833, 0.5697577595710754, 0.5488265752792358, 0.5538731813430786, 0.5600664615631104, 0.5497280359268188, 0.5621331930160522, 0.5548180937767029], 'val_accuracy': [0.04672057554125786, 0.04582210257649422, 0.13746631145477295, 0.13746631145477295, 0.19856244325637817, 0.27852651476860046, 0.3935309946537018, 0.684636116027832, 0.7978436946868896, 0.684636116027832, 0.7951482534408569, 0.7852650284767151, 0.41868823766708374, 0.8140161633491516, 0.8301886916160583, 0.808625340461731, 0.7852650284767151, 0.8230009078979492, 0.8310871720314026, 0.8382749557495117, 0.8454627394676208, 0.835579514503479, 0.8445642590522766, 0.8212039470672607, 0.8391733765602112, 0.8167116045951843, 0.849056601524353, 0.8445642590522766, 0.8212039470672607, 0.7987421154975891, 0.8400718569755554, 0.8517520427703857, 0.8409703373908997, 0.7268643379211426, 0.8553459048271179, 0.8544474244117737, 0.8373764753341675, 0.8562443852424622, 0.8553459048271179, 0.8535489439964294, 0.8472596406936646, 0.8544474244117737, 0.8122192025184631, 0.8535489439964294, 0.8562443852424622, 0.8616352081298828, 0.8607367277145386, 0.8571428656578064, 0.8562443852424622, 0.8544474244117737, 0.8607367277145386, 0.8580413460731506, 0.8616352081298828, 0.8445642590522766, 0.8616352081298828, 0.8598382472991943, 0.8535489439964294, 0.8679245114326477, 0.8634321689605713, 0.8643306493759155, 0.8598382472991943, 0.8607367277145386, 0.85265052318573, 0.8643306493759155, 0.8571428656578064, 0.8643306493759155, 0.8670260310173035, 0.8607367277145386, 0.866127610206604, 0.866127610206604, 0.866127610206604, 0.8670260310173035, 0.8670260310173035, 0.8697214722633362, 0.8706199526786804, 0.8634321689605713, 0.8634321689605713, 0.862533688545227, 0.8571428656578064, 0.8706199526786804, 0.8715184330940247, 0.8688229918479919, 0.8598382472991943, 0.8652291297912598, 0.8535489439964294, 0.8607367277145386, 0.8670260310173035, 0.8706199526786804, 0.8652291297912598, 0.866127610206604, 0.8688229918479919, 0.862533688545227, 0.8679245114326477, 0.8715184330940247, 0.8670260310173035, 0.8670260310173035, 0.862533688545227, 0.862533688545227, 0.8670260310173035, 0.8670260310173035, 0.866127610206604, 0.394429475069046, 0.35399821400642395, 0.37106919288635254, 0.41419586539268494, 0.3980233669281006, 0.7969452142715454, 0.6460018157958984, 0.8292902112007141, 0.7358490824699402, 0.717879593372345, 0.8068283796310425, 0.7744833827018738, 0.7340521216392517, 0.8014375567436218, 0.5004492402076721, 0.7951482534408569, 0.8607367277145386, 0.6927223801612854, 0.7214735150337219, 0.7610062956809998, 0.7493261694908142, 0.8337825536727905, 0.6900269389152527, 0.8391733765602112, 0.8310871720314026, 0.8589398264884949, 0.8598382472991943, 0.7879604697227478, 0.7735849022865295, 0.8580413460731506, 0.4941599369049072, 0.5283018946647644, 0.5678346753120422, 0.8265947699546814, 0.8041329979896545, 0.8562443852424622, 0.8445642590522766, 0.8553459048271179, 0.8301886916160583, 0.8742138147354126, 0.7852650284767151, 0.6073674559593201, 0.8122192025184631, 0.8670260310173035, 0.8149146437644958, 0.7654986381530762, 0.8814015984535217, 0.8697214722633362, 0.8400718569755554, 0.8463611602783203, 0.7421383857727051, 0.580413281917572, 0.8418688178062439, 0.8688229918479919, 0.8427672982215881, 0.8391733765602112, 0.8535489439964294, 0.8643306493759155, 0.866127610206604, 0.8697214722633362, 0.7026055455207825, 0.8283917307853699, 0.8310871720314026, 0.8463611602783203, 0.7565139532089233, 0.8643306493759155, 0.8176100850105286, 0.8328840732574463, 0.8724169135093689, 0.8562443852424622, 0.5498652458190918, 0.5058400630950928, 0.38185083866119385, 0.5929918885231018, 0.8373764753341675, 0.7762803435325623, 0.5166217684745789, 0.8517520427703857, 0.7196765542030334, 0.8454627394676208, 0.08535489439964294, 0.5552560687065125, 0.7385444641113281, 0.8544474244117737, 0.822102427482605, 0.8292902112007141, 0.8337825536727905, 0.8310871720314026, 0.85265052318573, 0.8679245114326477, 0.7070979475975037, 0.7053009867668152, 0.8247978687286377, 0.6397125124931335, 0.7690925598144531, 0.6765498518943787, 0.7475292086601257, 0.8580413460731506, 0.8238993883132935, 0.862533688545227, 0.7996405959129333, 0.7592093348503113, 0.6585804224014282, 0.8445642590522766, 0.8472596406936646, 0.8418688178062439, 0.7304581999778748, 0.8562443852424622, 0.8571428656578064, 0.8670260310173035, 0.8149146437644958, 0.7205750346183777, 0.8319856524467468, 0.788858950138092, 0.8032345175743103, 0.85265052318573, 0.704402506351471, 0.805031418800354, 0.8005390763282776, 0.8751122951507568, 0.7987421154975891, 0.849056601524353, 0.8418688178062439, 0.8256962895393372, 0.8077268600463867, 0.8571428656578064, 0.8472596406936646, 0.8463611602783203, 0.8194069862365723, 0.6397125124931335, 0.8256962895393372, 0.7762803435325623, 0.6729559898376465, 0.8481581211090088, 0.7358490824699402, 0.8454627394676208, 0.8319856524467468, 0.849056601524353, 0.85265052318573, 0.8535489439964294, 0.6469002962112427, 0.7816711664199829, 0.8319856524467468, 0.822102427482605, 0.8032345175743103, 0.8247978687286377, 0.8167116045951843, 0.8517520427703857, 0.862533688545227, 0.8616352081298828, 0.53998202085495, 0.627133846282959, 0.808625340461731, 0.8337825536727905, 0.7987421154975891, 0.7978436946868896, 0.7744833827018738, 0.8364779949188232, 0.8346810340881348, 0.8373764753341675, 0.8041329979896545, 0.8104223012924194, 0.8391733765602112, 0.8463611602783203, 0.8481581211090088, 0.8274932503700256, 0.805031418800354, 0.8472596406936646, 0.8553459048271179, 0.8544474244117737, 0.8553459048271179, 0.8077268600463867, 0.8436657786369324, 0.8517520427703857, 0.8571428656578064, 0.8337825536727905, 0.8544474244117737, 0.8571428656578064, 0.8265947699546814, 0.8535489439964294, 0.8535489439964294, 0.85265052318573, 0.688230037689209, 0.8589398264884949, 0.8436657786369324, 0.8580413460731506, 0.8517520427703857, 0.8544474244117737, 0.8400718569755554, 0.8589398264884949, 0.8544474244117737, 0.8517520427703857, 0.8580413460731506, 0.8598382472991943, 0.8562443852424622, 0.85265052318573, 0.8544474244117737, 0.8598382472991943, 0.8553459048271179, 0.5184186697006226, 0.8472596406936646, 0.8607367277145386, 0.8580413460731506, 0.8562443852424622, 0.8697214722633362, 0.8598382472991943, 0.8580413460731506, 0.8571428656578064, 0.8562443852424622, 0.8571428656578064, 0.8598382472991943, 0.862533688545227, 0.8562443852424622, 0.8544474244117737, 0.8589398264884949, 0.8580413460731506, 0.8652291297912598, 0.8598382472991943, 0.8598382472991943, 0.8553459048271179, 0.862533688545227, 0.8598382472991943, 0.8616352081298828, 0.8580413460731506, 0.8652291297912598, 0.8607367277145386, 0.8634321689605713, 0.866127610206604, 0.866127610206604, 0.8571428656578064, 0.8517520427703857, 0.8679245114326477, 0.8607367277145386, 0.8616352081298828, 0.8499550819396973, 0.8382749557495117, 0.8607367277145386, 0.866127610206604, 0.866127610206604, 0.8616352081298828, 0.866127610206604, 0.862533688545227, 0.866127610206604, 0.866127610206604, 0.8607367277145386, 0.862533688545227, 0.8598382472991943, 0.8598382472991943, 0.8616352081298828, 0.8688229918479919, 0.8598382472991943, 0.8616352081298828, 0.8346810340881348, 0.8607367277145386, 0.8652291297912598, 0.8598382472991943, 0.862533688545227, 0.8607367277145386, 0.862533688545227, 0.8589398264884949, 0.8634321689605713, 0.8643306493759155, 0.85265052318573, 0.8571428656578064, 0.8607367277145386, 0.8616352081298828, 0.8616352081298828, 0.862533688545227, 0.8643306493759155, 0.8544474244117737, 0.866127610206604, 0.866127610206604, 0.862533688545227, 0.8634321689605713, 0.8517520427703857, 0.8616352081298828, 0.8688229918479919, 0.8616352081298828, 0.8616352081298828, 0.862533688545227, 0.8634321689605713, 0.8670260310173035, 0.8643306493759155, 0.8643306493759155, 0.8616352081298828, 0.8616352081298828, 0.8634321689605713, 0.8607367277145386, 0.8652291297912598, 0.8634321689605713, 0.8616352081298828, 0.8562443852424622, 0.8634321689605713, 0.8589398264884949, 0.862533688545227, 0.8652291297912598, 0.8643306493759155, 0.8598382472991943, 0.8562443852424622, 0.8643306493759155, 0.8652291297912598, 0.8634321689605713, 0.8679245114326477, 0.8643306493759155, 0.8643306493759155, 0.8688229918479919, 0.8616352081298828, 0.8589398264884949, 0.8598382472991943, 0.866127610206604, 0.8643306493759155, 0.8041329979896545, 0.8068283796310425, 0.8212039470672607, 0.8652291297912598, 0.8706199526786804, 0.8679245114326477, 0.8679245114326477, 0.8670260310173035, 0.8670260310173035, 0.866127610206604, 0.8688229918479919, 0.8697214722633362, 0.8706199526786804, 0.866127610206604, 0.8670260310173035, 0.8679245114326477, 0.866127610206604, 0.8616352081298828, 0.8616352081298828, 0.8724169135093689, 0.8706199526786804, 0.8580413460731506, 0.8706199526786804, 0.8670260310173035, 0.8688229918479919, 0.8571428656578064, 0.8670260310173035, 0.8670260310173035, 0.8724169135093689, 0.8679245114326477, 0.8634321689605713, 0.862533688545227, 0.8652291297912598, 0.8724169135093689, 0.8634321689605713, 0.8715184330940247, 0.8688229918479919, 0.8643306493759155, 0.849056601524353, 0.8652291297912598, 0.8670260310173035, 0.8715184330940247, 0.8652291297912598, 0.8679245114326477, 0.8688229918479919, 0.8670260310173035, 0.8598382472991943, 0.8589398264884949, 0.8643306493759155, 0.8679245114326477, 0.8643306493759155, 0.8697214722633362, 0.8697214722633362, 0.8670260310173035, 0.866127610206604, 0.8643306493759155, 0.866127610206604, 0.8652291297912598, 0.8706199526786804, 0.8670260310173035, 0.8652291297912598, 0.866127610206604, 0.862533688545227, 0.8562443852424622, 0.8634321689605713, 0.8607367277145386, 0.8634321689605713, 0.8589398264884949, 0.8670260310173035, 0.8607367277145386, 0.866127610206604, 0.866127610206604, 0.8679245114326477, 0.8652291297912598, 0.8652291297912598, 0.8607367277145386, 0.8643306493759155, 0.8670260310173035, 0.866127610206604, 0.862533688545227, 0.866127610206604, 0.8598382472991943, 0.8643306493759155, 0.8634321689605713, 0.862533688545227, 0.8652291297912598, 0.8643306493759155, 0.8652291297912598]}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5gb1bnG309lu727ttfGlbXBYAOmxQHTCT0JpEJuCCGNcpObBiEhEHITuAkXCKGHS2JqCIQSk4RqMMZgGwy21wXcy7qv7W3eXW9flXP/ODPSSBqtZEvjHcnv73n0TNXonNHMO+/5ThlRSoEQQoh78Qx0AgghhPQPhZoQQlwOhZoQQlwOhZoQQlwOhZoQQlyOz4mDDhs2TFVXVztxaEIIyUuWLFnSpJSqstvmiFBXV1ejpqbGiUMTQkheIiJbk21j6IMQQlwOhZoQQlwOhZoQQlwOhZoQQlwOhZoQQlwOhZoQQlwOhZoQQlwOhZpkTstWYMPsgU4FIXmLIx1eyEHGwycDwW7g1raBTgkheQkdNcmcYPdAp4CQvIZCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTQghLodCTbKHUgOdAkLyEgo1yR4UakIcgUJNsgiFmhAnoFCT7EFHTYgjUKhJFqFQE+IEFGqSPeioCXEECjXJIhRqQpyAQk2yBx01IY5AoSaEEJdDoSZZhI6aECegUJPswdAHIY5AoSZZhEJNiBOkJdQicr2IrBKRlSLynIgUOZ0wkoPQURPiCCmFWkRGA/gJgKlKqWMAeAF83emEkVyEQk2IE6Qb+vABKBYRH4ASADudSxLJWeioCXGElEKtlKoD8EcA2wDsAtCmlJoVv5+IXCsiNSJS09jYmP2UkhyAQk2IE6QT+qgE8EUA4wGMAlAqIt+M308pNV0pNVUpNbWqqir7KSXuh46aEEdIJ/RxHoDNSqlGpVQAwD8BnOpsskhuQqEmxAnSEeptAKaJSImICIBzAaxxNlkkJ6GjJsQR0olRLwQwA8BSACuM70x3OF2EEEIMfOnspJT6LYDfOpwWkuvQURPiCOyZSLIIhZoQJ6BQE0KIy6FQk+zB0AchjkChJlmEQk2IE1CoSfagoybEESjUJItQqAlxAgo1yR501IQ4AoWaZBEKNSFOQKEm2YOOmhBHoFCTLEKhJsQJKNQke9BRE+IIFGqSRSjUhDgBhZpkDzpqQhyBQk2yCIWaECegUJPsQUdNiCNQqAkhxOVQqEkWoaMmxAko1CR7MPRBiCNQqAkhxOVQqEn2oKMmxBEo1CSLUKgJcQIKNckedNSEOAKFmmQRCjUhTkChJtmDjpoQR6BQkyxCoSbECdwn1B2NwK3lwKp/D3RKyL5CR02II7hPqBvX6GnN4wObDrIfUKgJcQL3CTXJXeioCXEECjXJIhRqQpzAvUJNd0YIIQDcLNQk9+DDlRBHoFCTLEKhJsQJ0hJqEakQkRkislZE1ojIKY6lSIUdOzRxGDpqQhzBl+Z+DwB4Uyl1qYgUAChxLEWhoGOHJk5DoSbECVIKtYiUAzgTwHcAQCnVB6DPsRSFA44dmjgMHTUhjpBO6GM8gEYAT4rIMhF5TERKHUtRiEKdu1CoCXGCdITaB+BEAI8opU4A0AngpvidRORaEakRkZrGxsb9TxEdde5CnSbEEdIR6h0AdiilFhrLM6CFOwal1HSl1FSl1NSqqqr9TxFj1DkMlZoQJ0gp1Eqp3QC2i8iRxqpzAax2LEV01LkLY9SEOEK6rT5+DOBZo8XHJgDfdSxFZoyaN30Owv+MECdIS6iVUssBTHU4LZowQx85Cx+uhDiC+3omstVHDkOhJsQJ3CfUjFHnLnTUhDiC+4SajpoQQmJwn1BHYtR0Z7kH/zNCnMB9Qm066nBoYNNB9h2GPghxBPcJtRmjDjk3nAhxCgo1IU7gPqE2eyayUjH3oKMmxBHcJ9QRR8321LkHhZoQJ3CfUEdi1HTUOQcdNSGO4D6hjjhqCnXuQaEmxAncJ9SRGDVDHzkHHTUhjuA+oaajzmEo1IQ4gfuEmjHq3IWOmhBHcJ9QmyEPOuochEJNiBO4T6hDDH3kLNRpQhzBfUIdZugjd6FSE+IE7hPqyBtewkA4PLBpIYQQF+A+oQ72RufpqnMLViYS4gjuFmrGqXMMCjUhTuA+oQ7RUecsdNSEOIL7hDrGUbN3Ym5BoSbECdwn1NZxqDkmdW5BR02II7hPqIM9gL9UzzP0kWNQqAlxAhcKdR9QWKbnGfrILeioCXEE9wl1qBcooKPOTSjUhDiBu4Q6HNJjfRSYjppCnVPQURPiCO4SarPFR+EgPaWjzjEo1IQ4gbuE2mxDbYY+GKPOLeioCXEEdwl10GiOxxh1jkKhJsQJXCbUPXoacdRsR51T0FET4gjuEmpTmAuMGDVDH4QQ4jKhDsbFqBn6yDHoqAlxAncJdUJlIoU6p2DogxBHSFuoRcQrIstE5DXHUhNx1EY76jBDH4QQsi+O+qcA1jiVEACWdtTs8JKT0FET4ghpCbWIjAHweQCPOZqaSGWi6agp1LkFhZoQJ0jXUd8P4EYASV9iKCLXikiNiNQ0NjbuX2oSmudRqHMKOmpCHCGlUIvIxQAalFJL+ttPKTVdKTVVKTW1qqpq/1ITjHPUFOocg0JNiBOk46hPA/AFEdkC4HkA54jIM46kJhQXo2boI7egoybEEVIKtVLqZqXUGKVUNYCvA5ijlPqmI6mJb0dNR51jUKgJcQJ3taNm87zcho6aEEfw7cvOSqn3ALznSEqAaOjDX2Is01HnFhRqQpzAZY7aqEz0FQIeP2PUuQYdNSGO4C6hDvUC4gU8XsBbQEedc1CoCXECdwl1sBfwFel5r48xakIIgSuFukDPe/x01LkGQx+EOIK7hDrUC3gL9bzXzxcH5BwUakKcwF1CHeyLddQMfeQWdNSEOILLhLonNkbN0EeOQaFOyro3gbYdA50KkqO4S6hDfdHQB5vn5R501Ml57j+A6WcPdCpIjuIuobZWJnr9fGdizkGh7pfO/RxVkhz0uFCojdCHx0dHnWvQUdvD80IyxF1CHerVHV0Adngh+QOFmmSIu4Q62Ku7jwM69MFWH7kFBckeFRroFJAcx11CHeqLOmqPj+2ocw4KtS0q6YuRCEkLdwl1TPM89kzMOeio7QnTUZPMcJlQx3d4oVDnFhRqWxj6IBniLqGO6ULuY/O8XIOO2h6GPkiGuEuog33RykQ66tyA4pwahj5IhrhLqCeeDxwyRc8zRp0bxAg1RdsWPsxIhuzTq7gc57Ino/MclClHsIgQBckexqhJhrjLUVuho84N6KhTw9AHyRCXCzXbUecUdNT2sDKRZIh7hZqhjxyBjjolDH2QDHGvUHM86txAMUadEjpqkiHuFWo2z8sR6KhTwhg1yRD3CrXXr51ImG7E1dBRp4aOmmSIe4XaY7QcpKt2OXTUKaFQkwxxr1B7/Xp6MMWpV8wAdq8c6FT0T9sOYMGf7LfRUdvD0AfJEHd1eLFiDnd6MDjq9nrgniOiy7e2DVxaUvH3rwP1K4CjvwyUj2Y76nSgoyYZ4l5HbYY+DgZHXbdkoFOQPl1NeipirLDGqA94anIDNs8jGeJeoT6YQh+9ewc6Beljtm03p3TUqWHog2SIe4XaYwj1wRD6aNsRnTfz7VZM0Yk8QCnOKWHsnmSIe4U64qjzvHdiez0w53fR5cJBA5eWdDCL8Wb3fjbPSw1DHyRD3CvUB0vzvI2zY5eLBg9MOtLFdNTBXuDWcuDDhy0bKdS2sDKRZEhKoRaRsSLyroisFpFVIvLTA5GwgydGHSduhbki1D16OvfO6DY6ansYoyYZko6jDgK4QSl1FIBpAH4oIkc5myxEm+eZQt26Ddi5zPGfPeDEDzxVVD4w6UgXsxjf12G38YAmJWdg6INkSEqhVkrtUkotNebbAawBMNrphEUdtRELvX8KMP1sx3/2gGMK9XGX66nX7ZWJRnr7uhK30VHbw9AHyZB9ilGLSDWAEwAstNl2rYjUiEhNY2Nj5ikzX3Kb72NSm8XiC/8XGDvNfmjXxY8Dq18+sOlKhik6ARuhpqO2h6EPkiFpC7WIlAF4CcB1SqmEhr9KqelKqalKqalVVVWZpywS+shzoTZDOx6vdtN2N/XrPwNe/NaBTVcq+joT19FR28PzQjIkLaEWET+0SD+rlPqns0ky8B0kQm06aI9fi3WuvCzBTqjpqO1hjJpkSDqtPgTA4wDWKKXudT5JBqajDvYesJ8cECJC7dOfTIS6aw+w+pXspCsVdqEPOkd7GPogGZKOoz4NwJUAzhGR5cbncw6nK7HVR75i3sTZEOq/fQl48UqguyU7aesPOur0YWUiyZCUo+cppd4HIKn2yzoRoc53Rx0AIIDHo4U6k56Yuz7W0+5WoLgyK8lLCh11+jD0QTLEvT0Tk1Um5tsbX8LBaJO8TBx10HKeehwaJtVauqGjTh86apIh7hVqX5LQR751KQ8Ho93lMxFqawcUp4Taely7Di901PYwRk0yxFVC/a0nFuGZj7bqhWSVifkWsw6HsiPUof1w1J3NwDOXAp1N6e1vHeXPrsMLsYeOmmSIq4R62bYWbGwwnFqkw0ueO+pQQDfLAwyhjnNf6brU/RHqRX8BNr4NLHo0vf2tQs0OL+lDoSYZ4iqhLi3woavPbK7mBSCJlYn5NuxpOBgdg9rjTXwQpVuCsO6XrlBHWpx409t/b110nh1e0oehD5IhrnpnYkmhF519xkUtosMfCZWJeeaorTFqrz8x9JFufvfHUZutESTN53Xbdl3S8RYkqUwkttBRkwxxn6PutQiVrzC2NQOQhzHqFJWJ6fbM7E+olQJ62xO/YwpIukK9dxcweKSu6LULfeTCf/P+fQd+3BQ2zyMZ4iqhLinwoqvPclF7/TaOOh9DH/3EqNMN9cSEPlpjty17BrhjDNC0Me639zH0EegCCgZpV21XmZgLLnv2rQd+3BSGPkiGuEqoSwt9cUJdaBOjzgHXti/EtKO2Getjfxx1vGCufU1Pm9bFro846jSFOtijSzlePxCwEeX+XtIb6Aa2fpje7xwIDmR7fIY+SIa4SqhLCrzo7LMIldef/60+4kMf8fm1CnB/lXXW/QLdsduShTjClvqAdAj2Ar4iHaO2K9nYhVdMXr8BePIioGVLer/lNHtqD9xvUahJhrhKqHWM2uKofYVagKzuJ98cdSgu9KFCsYJsFcT+8m5u8xVFX5NlEjlenCDHv6g2Faaj9hXZb+9PqM3u7dnsjNO1B2irS72fHa3bspeOVFCoSYa4SqiLExx1ga5MtLrovIxRm47aCIG0bo1ut4pof4JqbiscnNxRx7dztr6oNh1MR11QYr+9v9BH5Dez+P/dMwm4bx/eCmd9AB7IeLo1Rs0mjGQ/cJVQlxbqykRlXsxmZaLVSebb+NTx7agB4IHjotvTzbu5rchGqE2Bjnfa5nfSFmrDUReUJm4Tb/+O2gyv9BodmkJBYNavgfbd6f22Hf0N2LXrE+24rVjzafvOR4ewOmq6a7IfuEqoSwp8CIUVeoPGxWxWJsa4yvwKfXR092B5XQdau/qiztpKKM3ShLlf4WAgGO+oDaEOxAm12cQu7dCH4aj9No66aHByoX7pamD3Cj1v7rPpXWDBQ8DMX6b32/3RsCa21yQA/OUM4Mm40XitD6reLAh163adt/jzGo+1eR5bgJD9wFVCXVqgHWWk5YdZmWgVqDwLfexqaUdXEPiwttleqMNJHPWaV2Ob28U46njhMB11nICbzjtdRx3oBvxF9o66cLB2qXZCtOIf0XlTqCOx6iyEAv5vGnDf0dFl86HVuCZ2v2w76jdv0nnbOLv//WJCH3TUZN9xlVCXFGqh6jQ7vfgK9c0VU/zPL0ftRxhBGO3HbR11ktLEC98E/jQ1cT9bR22+kDaJo44PiTz3DeD5KxLTEolR2wh10WA9jRfA+46JXTaF2vxtv82xTJo2AhvfSb49GclE2JrPbAh1uqJrjUuz8wvZD1wl1BXFOla7p9MQHV8RsHMp8Ni50Z3yrHmeTwyhDoQAr0WoTRdmFeeOer0cWWcRAHNdUXmiIEdCH3GdVExHHR/6WPd6tO21FTNGbRf6KDSE2hr+aK7V3c6t9Bnbu41OOf5iYPN8YO0bicf8v5OBZ76SfgWcecxkFYVWR52N0Ee6MPRBMsRVQj2qohgAsKvNEJDSYXraviu607446s3zdKWSi/EhhBC8uuu8tZ2z6fis+X3iQuCuaqCrOfFAkdBHuY7rh23EId4570voIxzSD8mkjrpcT63N7+xCAqaQd9TrqQjw14uB5y/XywunA69eZ/ymUbJK99Vidx1q/EY6jjoLrT7MB0iqtxCxMpFkiKuEerQh1HWtxg1VNiJxp32JUf/1El2p5GJ8CCEIjw59WJ3wgyfqcSni3W5fB7D4scQDWUMfQKwomU46vjWIKZrpVCaaYp7MUZcM0VOrqNq16DB/s7NRT+MFc+YvgCVPxq6z6yTTX8/CpKEPa4y6nxYq+0oqd84YNckQVwl1RYkfxX4vdrYagmIn1HkWo/YghCC8aO8JxnbL7moClvwV+Me3E7807+7EdZHQhyHUARuhtoq3UkBHg7E+iSPcvRJ4eJp+wYD53WSOusQo/Vjdvp0TjnfU1lCJNcQR7EWkg461XXlke3wTRINAd6xQxxwzy60+TFLFuxn6SGTxY8ALVwLLnh3olOQErhJqEcGoiqL+hTrdGHW6LRkGGAlroW7t7kt0ly2b0z9QqE+3ZTbdrlXITCcd6AHe+R9g3Zu6c0rQJvRhFZJZt+iWExtmRfZ5YVmDvVCbL9O1tl2OHxwKAHqMTjGNxrgjVpGzOv6OeqC4Qs/v2ZR4nGShi649sSJs7YQTKRUU6+831wJ3jQfqV9kfKxWmO+6v/bh1v/j5A0n9KqD23YH5bTtevwFY8wrw8n8B7fUDnRrX4yqhBoBxQ0qwucm4CW0ddVAPt5kKuziuCxEVQAhetHUFbDqqpMnuFcD8e7Rz8+vwUYyjNkWtswGYf69uUma9OawxVqvoWM+h4UYXbu+yD32YA0ulctTtu4COxmi9g1XYOyxpqn03Gt7Y8oEOo8T0LEziYruaY0Xc+pox01GXDtPfr3kC6N4DfPx84nH2bIo+tLpbY0MtbXX6/JkllVRCHRP6GCBH/cipwN++5M6ekfEVziQB1wn10aPKsaGhAz2BUNSlWdn0HnDvJGDD27Hrw2F9EXbt0T3erHFNFxc3JRxCUHmwbU8XMOiQ1F+48l+xy0oBfz49umwK9evX62k4HBWSLe8DUFoQO4z4sb80eftiU0TrV0YeIr0osHfUwR6goEyLs1JA04ZoKwwAOPLzwJSv6Ztyt1HBW1Qee5M2rY/Ov/oToNeomKx9B7jnSF1cXvQo8MED/Tjq5tj489u/AZ66WKffFOpBh+g8ffxcNM+v/xyYcZUOITXXAg+eoB9+PW26kvK9O6LHvO8o4J4jouc1ZejDOnZLFq/FcBh46xagbkn637FWzKcj2j1pDAuwr5gmYrjR9j3b464E+4A9+1AaTcaBbBmUAle94QUApowpRyissHrXXpw49jDg7JuBY74KlA0H7hynm44BwLqZwMTzo198+gv6php7MrD4US0UJj1t0cquxvXAm78ELnsq2lJhAPEoHfrY0NCBtuP+E+UeH/DWr3SvzJOuAY78LPD+/frdhgAw7MjYA8S7Vp8h1Jvn6Rti4Z+j4SLTAXY0RB11xbjYykSrOzRfvfXhnyKDKvXCj76eLhTEZ6SnDSgeolt6LHkqUbyGT9YPkRUvAtsX6XXjTgHWvxndpyGugwoAjD9T5wUAlj8L7Fym58eenLgvkOiozWaGT39JX0fmd3csjrr/7Yu0cAPA8ElA6XA9v/5N4NDT9PxHjwCf+k5sD0gzrLJhtn7YBbr1dFBcSVClWZkYDgHbPgTGTottqpmMdW/o/2b1K8D1K2K3te/WQlNUHjs2y/ZFwLhpwCcvAIseA475si4hXPB7XS9SVA4sfRo48Vs6RDbzF8DF9wPHX2G8dcmvr5/6VUDVJH29+AqABX8CSqv0tTbsCH0thAPAkAn62uhuASqrgaIKYNdynZap3wXe+HnsOe1p05+KcdF1fZ36vDZvBEqG6grtpvXACKONfuM6/TuDRupjz7xR/7+XPaXHTfcX6boV8ejwoHh0Xnr3Gq2kAvpa8Bn7Na7RrcXWvgYcfj5QVqX3OfZr+rx2t+hrOdCjz8OIo4z+Hn3AsInAUV9Kf4z3NHGdUB8/VsclF23egxPHVQJn36Q3KBUdGc5bCKx/S1+Iq/6pnZY5OpvpGKwCsOZVYPIlWqzf/g1QO0e32z3eaBIW7NV//ooZQONa4JxfH6DcRoUaAJbsaMM5ky/RQj3uZODC2/VOh54G3GbEa+NLGStmxC5bY9P/utb+bSYd9dGxqSurtcPt7dBOOVkxfst8AFqoW0adgREnXatveuOmq29swIiSIdGb0EyeHIkpah0w8YJoKWfunUD5WH0zWzEF+dPXAFsXAA2rgFEnRNebIg3o7SbFQ3QIAwBeukqLCgSoPl2ne9SJwPaPos0fDz1NC5z5W4uNl/sOGgnM+X30uHVLgKeMbuh97YkDQJmx8707gN8Pj66fdLEWDgCoPkM/LE0evwCoPFRfx0XlwNCJ+rzvqNFi0bROd3zyFmghLK7UvzPyOL2ufZcu6YSD0f+wbRvwty/rDkIqpF1wslYt8ZXTHzygpyvjriNrhfVr1+mYsgoZPVA7sxDCEf2gLhgEvP3f+jpt266vw0CnzrfHp6et25NXHluP5y+O7Svwj+9kmEYA62dG580SWH8MGgUc/ZXMfzcO1wn1iMFFOGrkYMxeXY/vn3VYdIMI8I0XdIz1pGt0z7w7xiChC3Jno36ixxej37kNOP1nugMNoG/Cw87RFRqzfg2cfn20eOvxA1VHACOm6D9+1i36xjviIn3zFw7SxXoV1uIfCgDL/64fABffp5+mnU26SHfoqfoGE9H7iSf6tK1bitLwXpQWFaCo14O56xpxzqRjgC9Pjy0tWMeLNkMbJjN/EbtcfYZ2GvUrY0V6ymXRrtw9rfoGnXghMOEsfTHeMVoLwwijOHrmjcC8PyT8Pz2qAK0BP0Z87m4dLjCE+dlVAVx//HjIruVa/A1RfjcwGZU3vIcxlSWxzr1rDzBkfOzBa98BIMDn7tZCOuvXQJklHFQ6XFcwNq3X/+eIY4Br3gW2LQCe/mJ0v+XP6jDMZU8ZDnckcPdhej8AGDMVqByvTcDh5+uSw5hPA1MuBe6fosWjrMq+EjMdrJ2FFjyop8OPAiacresTWrZqcQX0cm+7dpoqrK+VyvFaoAJdusVL1SQd8iscrNNVVqVDVlMu1Q/At/9bu+Kxn9ZmpnCwjsOXj9WusXmj7lT0mZuBhrX6AVE6VKdp3Uz9nzeu1Wmoq9HnuaAEqDhUu++tH2qXKR7tdoM9wKRL9AO+oFSXBCZeoB+WZnv7vi7ttLta9H9WVA40rNaljrIRwOhP6QfWIcfoUsTeOmDk8bo04vFr0Tav9cPO1ent69IPqPIx+rN1gRbzQ6bo/6q7RR/j8HO186+do//7gjL9YAkbQwirkD7XBWU6P16/Pt+hgP4vSoboe3TIBF0CHzxK38t7NmnH7C+OhgsHjdQuu6BU/3e9e9Mf330fEOVA5cLUqVNVTU3Nfn//vrfX48E5G1Bzy3kYWlZov9Pql4FV/9JP5eO+Dix/Toc0hhwGfHOGjjFWnxFxgvYI9musibIRRtM2pS/uQFdUhOxeyFtcqYtse3fpi8Icj6NTN4+bUXQp3hr1A6yqa8P7vzwHHo/NH/3MpTr8cWubLuqt+pcujse3rLi1Tccun/p8VJgA4L8+0mNiWM/Jj42H1kMnJv7eDxboSrx5d+sb0yjmT+55An/9z8/gpPFDdB7qluCK6fOxMDwZNb86BxWdm7SAzr8HePd2/CJwLa78wS04dkyFvrhn3wYs+osW4+Ov0Odx8Ghg9m+1qB1+HvDNl/RNs2g6MPV7wO2HRPMW6NbuMdAFfOVRoMoIBbVu1zfLmld1qenUHwFnWh5ib/8m6h5vqdfFYTv2bNZFeI9X35gbZmnhHHmsFvBN7wEejy7VdezWIgpox9uyVQtPsE9fA03rtXiNnaZvbvMBHejRIjfm0/qmVsqRmzsnCHRrgR08aqBTMuCIyBKl1FTbbW4U6pV1bbj4offxh0uPxdemjk3/i+31WhC9Pi0ApVX6Sd3TBlRN1k/p+pXaSXz8nI5XDR6pWzEEe7QT31Gji5d9nUBhmX66D5mg42im82har92Kv0jf2OLRoRVfkY7RqrC+UYcerh2TKeRFFdoRmOd8xFF4aEk3lnuOwSWnnYDrXliOZ68+GacdPiwxb6Gg/m68wGyYrR8E4YAuTUy+JLpt+yKdno4G4JL79U2xfaF2n2f9EvjMr/R+S5824sVvAStf0ufsh4uizeOUAt68CTe+H8KLoc9g+pWfwgVHR51u9U263uCt687EkYcMiqz/zh+fw/ymUvzlWyfjvKNsWvDE07RB56U0Lv/NtVrkKqtTH8NMr53wNawB9u7UjosQl9GfULsu9AEAR48ajDGVxZhRs2PfhNpaiVNmxAzNYhKgi1qVRjdjU6TiGXtS/78x+eL+t084K3U6LcxbsQA+jwcXHXMIKl/146E5G3DqYUMh8ULj9dlXME08L/nBx54Umx9/MTD+LO2kh1rCSicaL3sdNlE70XhEgM/ehRfnakFu7bZvy16/tydGqJsLxyKENjR2pNmmfdhE+/XWtKZDMnc6fLL+EJJjuK55HqA7vnz3tPFYtGUP5q5vHOjkOEpfMIwCnwdFfi9uvGgSPtq0By8s3o5QWGHmil0IhtLrIBEOK/zvG2uwvj5Fm16RfRc+I50mdS2xFTuFPn0Z1e/tsV3f2O6ezke3vrIKT3+4ZaCTQcg+4UqhBoArTh6Hw4eX4ZczPtGdQfKUXkOoAeA/pgGGbYkAAAzzSURBVI7FtAlD8NtXVuHGGZ/gB88uxaPz02sPWtfajenzNuF7Ty12JJ3dgWgt/1urYsfwKPLr2GtDnCD3BEPG+hQD66cgFFb489xatHTGxv6VUnj6wy3RQbwsPPzuRizZmtjh5qkFW/Cbl1fBiZAfIU7hWqEu8ntx79eOQ1NHL67662J0mGNU5xl9oahQezyCP33jRIyuKMZLS3Xb0ic/2IyGOKcaDieKzK42vc++uNdtzV3RIWUtzF5dj9mrY7v1dhsvczh61GCs3d2OF2uiHVV6DUH+YGNTzHfae/R/9taq+owetku3teDOmWvxk+eXxayva+3Gb15ehW88ujBmfVdfEHe/tQ5ffWRBzPq9PdE0LN6S5oh8hLgA1wo1ABw7pgIPXn4Clm1vxTcfW4hPdtiMHZHj9AXDKPRG/4ZhZYX4+zXTcP5RI3D5SWPR1h3AuffOxaPzNqE3GMKOli4ce9ss/HtZ7Nu3zfFReoPphUoA4My738VZdyeO/3D10zW4+umaGNfZZbx0+Hunjce0CUPwu1dXY/ueLvQGQ+gJhFFe7MeC2ma89snOyHf2dgdwwrgKNHX04qE50Q5IK+va8LU/f5jgtDt6g7hn1roEUd/WrNvGzt/QhCZLvHtjg+5Us7mpM/qyCQCbGqMdXrbvibarjYwhA+DOmWvQnG7snGQdpRQef39zzP9DkpOWUIvIRSKyTkQ2ishNTifKyuemjMTD3zgB63a34wt/+gA/e3E5XvtkJ7bv6cqL4qs19GFySHkRHv3WVNzxlWPx+k9Ox9RDK3H7G2twwX3zcM4f56KjN4jrXliOB2ZvwCc7WhEOK9RZROj9DU2Rc6OUwu2vr8ZLS3YgZHHipktv7wliZV10DOkuy1vgP9gYHbfDDH2UFvpwx1eOhQjwxYc/wO2v696EPz7ncEw9tBI3vPgxHnmvFrvautHeE8S0CUPx1RPH4LH3N+Pn//gYq3a24YkPNmPRlj24/oXl2NESvVH/vawOD83ZiCse/wjrdkdj7Vuao8J76p1z8PLyOvQFw6i1CPL5987Fy8vr0NUXRG1jtFfkxQ+9j0feq0VXXzAi1N8+5VCsqGvDeffOxR/eXIuPNjXHxOCJ82xu6sTvXluN7z+zD93fD2JSNs8TES+A9QDOB7ADwGIAlyulVif7TqbN8+xo7wnggdkb8PRHWyM31bCyAkwZXY5DyotRUeJHZYkfFcUFqCjxo7zYjwKfB16PwCMCr0eMeUSWrVOPB/Cayx6BVxLXJ7TEyALH3TYLXzx+FP7ni8f0u9/c9Y24d9Y6fLyjDWMqizFuSAkW1DZHzkNThw5hjK4oRl1rN6qHluDIQwahvNiPF2t0GKW82I9PV1diTGUJegIhPL9Yhy/8XsHJ44diQlUpvB7Bkx9sifzulNHlmDJGd7X/+8JtePp7J+HMI6qwob4dt726Gu8b4Y4HLz8Bpx02FD/8+1J8tCk60NKNFx2Jq0+fgPtmr8ej8zYhGFbwCBBWgNcjCIUVJgwrRfWwUmxt7kRtYyeK/B70BMKYOLwMR4wYhHX17QiGwrjrq8fit6+swtrd7Sgv1kPi9gRDuOurx+KeWeuwvr4DBV4P+owK2OeumYY/z63F3PWNKPZ7Iw+bRb86Fy1dAdwxcw3mb2hCKKxQUuDFoUNLccK4CowcXITiAi9GVxRjcLEfIkAwpDC42I+yQh/8Xn09+DweYyrweo2psd5sCt8bDKMnEEJvMAwRYPigJO23DzJmLNmBn/9D9ybecufnBzg17iCjdtQicgqAW5VSFxrLNwOAUuqOZN9xQqhN+oJhrN29Fx9vb8Xy7W1YtbMNTR19aO3qQ9AmdptNRJAg4B5D6M3tEtlXLPORI0TmxVhfv7cX15wxHrd8Pq57chIa9vbA7/WgsrQATR29mL+hEfPWN2FTYweOH1uBmz47GW+s2IV/L6/DrrYebGvuQmWpH7+4cBIWbmrGxztasau1B+29QQwq9GHmdWfg0XmbsHx7KzY1dqK9Nwi/V/DvH56G99Y1Yt76Rqyrb0erEY54+/ozMXFEtAleXWs35qypx6WfGoti4+XEW5o68a9ldVi6rQU3XjgpIvR7OvvwxopdmL2mHt8+pRoTR5Th5eU7sWpnGzY1dmJrcxeuOn08rjp9PF6o2Y6aLS3Y2NCOHS3d+PIJo3H3ZcehLxjG/A2NeGPFbmzb04lTJgzFzy44EoFQGAs37cHc9Q1Yuq0Vx4wajNuMh9+SrS14eXkddrR0o7zYj3suOy7SqWhvTwAf1TZj/oYm1DZ2YGVdG/b2OFcfUuD1AMZ14hGJXDMeYyZ+nb5exLbFYfwq+30kZpu+7mJ3TOY/+jte6v36p6UrgDajmeegIh9KC3zwWjp6WY8ZM4/Efay/Zc1bTBrS8Fjp2LBUZm1ISQFe/P4paRzJ9tgZCfWlAC5SSl1tLF8J4GSl1I/i9rsWwLUAMG7cuE9t3Woz2LuDKKXQ2RdCa1cfWo2LoC8URjisEAorhJVCKAyElIJSel38+nBkObo+bNlXKYWQzXrz91UkLYC5pOej6wEV6e9i9sv49qnVmDxysCPnJRgKI6yQEF5p7wlAARhc5I9Z39EbRDAURkVJQcL67r4QqgYl6SmaBZRStjdCyHDhTpRo7OgNhtDVG8JOI3yjFODzCtq6AujsCyIUVgga/30wrBAKhWOXjSkAFPk9KPJ5UWiUEhrbe/W1ofQ1ZF4f5jxgXa8QVskGuYtdabdP5DpLei1Gt6U4fLJVtuHHdO3SieMqEQwrbGvuRFdfCGG7NNnPRkN7Mev637c/0kpzGjsNKvLhzq8em87REjggHV6UUtMBTAe0o87WcdNFRFBW6ENZoQ9jbEZHPVjxee2rIQbFCbRJWaH9JWGeWydJJsReuy71DlLo86LQ50VlacIYgYQMCOlUJtYBsHYPHGOsI4QQcgBIR6gXA5goIuNFpADA1wG84myyCCGEmKQsyyqlgiLyIwBvAfACeEIptZ8vmSOEELKvpBV0VEq9AeANh9NCCCHEBlf3TCSEEEKhJoQQ10OhJoQQl0OhJoQQl+PIq7hEpBHA/nZNHAagKeVe+QXzfHDAPB8c7G+eD1VKVdltcESoM0FEapJ1o8xXmOeDA+b54MCJPDP0QQghLodCTQghLseNQj19oBMwADDPBwfM88FB1vPsuhg1IYSQWNzoqAkhhFigUBNCiMtxjVAP5At0nUREnhCRBhFZaVk3RETeFpENxrTSWC8i8qBxDj4RkRMHLuX7j4iMFZF3RWS1iKwSkZ8a6/M23yJSJCKLRORjI8+3GevHi8hCI28vGEMFQ0QKjeWNxvbqgUx/JoiIV0SWichrxnJe51lEtojIChFZLiI1xjpHr21XCLXxAt2HAXwWwFEALheR9F4i6H6eAnBR3LqbALyjlJoI4B1jGdD5n2h8rgXwyAFKY7YJArhBKXUUgGkAfmj8n/mc714A5yiljgNwPICLRGQagLsA3KeUOhxAC4CrjP2vAtBirL/P2C9X+SmANZblgyHPn1FKHW9pL+3sta2MdwgO5AfAKQDesizfDODmgU5XFvNXDWClZXkdgJHG/EgA64z5v0C/4T1hv1z+AHgZ+i32B0W+AZQAWArgZOgeaj5jfeQ6hx7f/RRj3mfsJwOd9v3I6xhDmM4B8Br0O2LzPc9bAAyLW+fote0KRw1gNIDtluUdxrp8ZYRSapcxvxvACGM+786DUbw9AcBC5Hm+jRDAcgANAN4GUAugVSllvtbcmq9Ino3tbQCGHtgUZ4X7AdwIIGwsD0X+51kBmCUiS4yXegMOX9vOvq2UpEQppUQkL9tIikgZgJcAXKeU2mt9eW0+5lspFQJwvIhUAPgXgEkDnCRHEZGLATQopZaIyNkDnZ4DyOlKqToRGQ7gbRFZa93oxLXtFkd9sL1At15ERgKAMW0w1ufNeRARP7RIP6uU+qexOu/zDQBKqVYA70IX+ytExDRE1nxF8mxsLwfQfICTmimnAfiCiGwB8Dx0+OMB5HeeoZSqM6YN0A/kk+Dwte0WoT7YXqD7CoBvG/Pfho7hmuu/ZdQUTwPQZilO5QyirfPjANYope61bMrbfItIleGkISLF0DH5NdCCfamxW3yezXNxKYA5yghi5gpKqZuVUmOUUtXQ9+wcpdQVyOM8i0ipiAwy5wFcAGAlnL62Bzowbwmyfw7Aeui43i0DnZ4s5us5ALsABKDjU1dBx+XeAbABwGwAQ4x9Bbr1Sy2AFQCmDnT69zPPp0PH8T4BsNz4fC6f8w3gWADLjDyvBPAbY/0EAIsAbATwDwCFxvoiY3mjsX3CQOchw/yfDeC1fM+zkbePjc8qU6ucvrbZhZwQQlyOW0IfhBBCkkChJoQQl0OhJoQQl0OhJoQQl0OhJoQQl0OhJoQQl0OhJoQQl/P/+N52K0/QMsYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2Iq1o930PGb"
      },
      "source": [
        "print(hist_s.history)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(hist_s.history[\"loss\"])\n",
        "plt.plot(hist_s.history[\"val_loss\"])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(hist_s.history[\"accuracy\"])\n",
        "plt.plot(hist_s.history[\"val_accuracy\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvIt3tKbQTvR"
      },
      "source": [
        "simple_model_file = 'simple_model.h5'\n",
        "tf.keras.models.save_model(model_simple, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_0.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_0, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_1.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_1, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_2.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_2, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_3.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_3, simple_model_file,\n",
        "                        include_optimizer=False)\n",
        "simple_model_file = 'pruned_4.h5'\n",
        "tf.keras.models.save_model(new_pruned_model_4, simple_model_file,\n",
        "                        include_optimizer=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMk2Xta67CAS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31rZ1O2-GTeP"
      },
      "source": [
        "model1=Model(model_simple.input, model_simple.output)\n",
        "model1=model_simple.layers[2].output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsEBn52OGmxn"
      },
      "source": [
        "out1=model1.predicte(X_test_50[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRzESRc2QQ22"
      },
      "source": [
        "#Quatisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjloLyrDQPSE"
      },
      "source": [
        "def quantModel(model, pathx):\n",
        "  model_file=\"q_temp.h5\"\n",
        "  tf.keras.models.save_model(model, model_file,\n",
        "                        include_optimizer=False)\n",
        "  converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(model_file)\n",
        "\n",
        "  converter.optimizations = [tf.compat.v1.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "\n",
        "  tflite_quant_model = converter.convert()\n",
        "\n",
        "  tflite_quant_model_file = pathx\n",
        "  with open(tflite_quant_model_file, 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "\n",
        "\n",
        "def eval_model(lite_file, x_test, y_test):\n",
        "  interpreter = tf.compat.v1.lite.Interpreter(model_path=str(lite_file))\n",
        "  interpreter.allocate_tensors()\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "  total_seen = 0\n",
        "  num_correct = 0\n",
        "  for img, label in zip(x_test, y_test):\n",
        "    inp = img.reshape((1, 50, 50, 3))\n",
        "    total_seen += 1\n",
        "    interpreter.set_tensor(input_index, inp)\n",
        "    interpreter.invoke()\n",
        "    predictions = interpreter.get_tensor(output_index)\n",
        "    if np.argmax(predictions) == np.argmax(label):\n",
        "      num_correct += 1\n",
        "  return float(num_correct) / float(total_seen)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1ARvf9eQNgT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a670e67-aafd-4542-efb1-96f24c469f2a"
      },
      "source": [
        "quantModel(model_simple, \"lite_simple.tflite\")\n",
        "quantModel(new_pruned_model_0, \"lite_0.tflite\")\n",
        "quantModel(new_pruned_model_1, \"lite_1.tflite\")\n",
        "quantModel(new_pruned_model_2, \"lite_2.tflite\")\n",
        "quantModel(new_pruned_model_3, \"lite_3.tflite\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:1488: set_learning_phase (from tensorflow.python.keras.backend) is deprecated and will be removed after 2020-10-11.\n",
            "Instructions for updating:\n",
            "Simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp8qujgfo0/assets\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8qujgfo0/variables/variables\n",
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n",
            "INFO:tensorflow:input tensors info: \n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_input\n",
            "INFO:tensorflow: tensor name: serving_default_conv2d_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n",
            "INFO:tensorflow:output tensors info: \n",
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense\n",
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8qujgfo0/variables/variables\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py:275: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/convert_to_constants.py:854: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplrv08e5z/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmplrv08e5z/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmplrv08e5z/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmplrv08e5z/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_4_input\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_4_input\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_4_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_4_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_6\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmplrv08e5z/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmplrv08e5z/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi05n6vnm/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi05n6vnm/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpi05n6vnm/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpi05n6vnm/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_8_input\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_8_input\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_8_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_8_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_7\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpi05n6vnm/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmpi05n6vnm/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3lwmqydp/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3lwmqydp/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp3lwmqydp/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp3lwmqydp/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_12_input\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_12_input\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_12_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_12_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp3lwmqydp/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp3lwmqydp/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprrgydc82/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprrgydc82/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmprrgydc82/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmprrgydc82/variables/variables\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The given SavedModel MetaGraphDef contains SignatureDefs with the following keys: {'__saved_model_init_op', 'serving_default'}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_16_input\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: conv2d_16_input\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_16_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: serving_default_conv2d_16_input:0, shape: (-1, 50, 50, 3), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:output tensors info: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Tensor's key in saved_model's tensor_map: dense_9\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow: tensor name: StatefulPartitionedCall:0, shape: (-1, 13), type: DT_FLOAT\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmprrgydc82/variables/variables\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmprrgydc82/variables/variables\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JekF4M_6Tjvu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "477683ba-78ef-49df-d74a-52f91951ab78"
      },
      "source": [
        "print(eval_model(\"lite_simple.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_0.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_1.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_2.tflite\", X_test_50, y_test))\n",
        "print(eval_model(\"lite_3.tflite\", X_test_50, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8831985624438454\n",
            "0.8616352201257862\n",
            "0.862533692722372\n",
            "0.7762803234501348\n",
            "0.7232704402515723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ7iMwBaz-Xh"
      },
      "source": [
        "#FLOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t07A-D4k0ByB"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "def get_flops(model):\n",
        "  model_file=\"for_flops.h5\"\n",
        "  tf.keras.models.save_model(model, model_file,\n",
        "                        include_optimizer=False)\n",
        "  run_meta = tf.compat.v1.RunMetadata()\n",
        "  with tf.compat.v1.Session(graph=tf.Graph()) as sess:\n",
        "    tf.compat.v1.keras.backend.set_session(sess)\n",
        "    net = load_model(model_file)\n",
        "    x=np.ones([50,50,3])\n",
        "    x_placeholder =  tf.compat.v1.placeholder(tf.float32, shape=(None,50,50,3))\n",
        "    y = net(x_placeholder)\n",
        "\n",
        "\n",
        "    #opts = tf.profiler.ProfileOptionBuilder.float_operation()\n",
        "    opts=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation() \n",
        "    flops = tf.compat.v1.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    opts = tf.compat.v1.profiler.ProfileOptionBuilder.trainable_variables_parameter()    \n",
        "    params = tf.compat.v1.profiler.profile(sess.graph, run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    return flops.total_float_ops, params.total_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60m97cTo5j9l"
      },
      "source": [
        "compter=ModelProfiler()\n",
        "w_n,w_p=compter.cuntPrunedWith(new_pruned_model)\n",
        "print(w_n+w_p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjqcW2G1eNS"
      },
      "source": [
        "s=get_flops(model_simple)\n",
        "p0=get_flops(new_pruned_model_0)\n",
        "p1=get_flops(new_pruned_model_1)\n",
        "p2=get_flops(new_pruned_model_2)\n",
        "p3=get_flops(new_pruned_model_3)\n",
        "p4=get_flops(new_pruned_model_4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXTLVCCl3SoF"
      },
      "source": [
        "print(s)\n",
        "print(p0)\n",
        "print(p1)\n",
        "print(p2)\n",
        "print(p3)\n",
        "print(p4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSwUoSoVMLjR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "84c8c9d4-cdeb-43ee-f1da-19423852eef6"
      },
      "source": [
        "def printsize(f_model):\n",
        "  print(\"Size of the model: %.2f Mb\" \n",
        "      % (os.path.getsize(f_model) / float(2**20)))\n",
        "\n",
        "printsize(\"simple_model.h5\")\n",
        "printsize(\"pruned_0.h5\")\n",
        "printsize(\"pruned_1.h5\")\n",
        "printsize(\"pruned_2.h5\")\n",
        "printsize(\"pruned_3.h5\")\n",
        "printsize(\"pruned_4.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the model: 2.93 Mb\n",
            "Size of the model: 0.23 Mb\n",
            "Size of the model: 0.17 Mb\n",
            "Size of the model: 0.11 Mb\n",
            "Size of the model: 0.08 Mb\n",
            "Size of the model: 0.05 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVfPLQxi3mH7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "47cc15fe-0252-41f3-b2ea-6f7fb1cd04f8"
      },
      "source": [
        "def printsize(f_model):\n",
        "  print(\"Size of the model: %.2f Mb\" \n",
        "      % (os.path.getsize(f_model) / float(2**20)))\n",
        "\n",
        "printsize(\"lite_simple.tflite\")\n",
        "printsize(\"lite_0.tflite\")\n",
        "printsize(\"lite_1.tflite\")\n",
        "printsize(\"lite_2.tflite\")\n",
        "printsize(\"lite_3.tflite\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of the model: 0.73 Mb\n",
            "Size of the model: 0.06 Mb\n",
            "Size of the model: 0.04 Mb\n",
            "Size of the model: 0.03 Mb\n",
            "Size of the model: 0.02 Mb\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}